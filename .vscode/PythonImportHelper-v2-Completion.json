[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "torch.backends.cudnn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.backends.cudnn",
        "description": "torch.backends.cudnn",
        "detail": "torch.backends.cudnn",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Net",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "Net",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "scipy.linalg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "linear_sum_assignment",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "tensorrt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorrt",
        "description": "tensorrt",
        "detail": "tensorrt",
        "documentation": {}
    },
    {
        "label": "common",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "common",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils.data_processing",
        "description": "utils.data_processing",
        "isExtraImport": true,
        "detail": "utils.data_processing",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils.draw",
        "description": "utils.draw",
        "isExtraImport": true,
        "detail": "utils.draw",
        "documentation": {}
    },
    {
        "label": "build_tracker",
        "importPath": "deep_sort",
        "description": "deep_sort",
        "isExtraImport": true,
        "detail": "deep_sort",
        "documentation": {}
    },
    {
        "label": "build_tracker",
        "importPath": "deep_sort",
        "description": "deep_sort",
        "isExtraImport": true,
        "detail": "deep_sort",
        "documentation": {}
    },
    {
        "label": "build_tracker",
        "importPath": "deep_sort",
        "description": "deep_sort",
        "isExtraImport": true,
        "detail": "deep_sort",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "isExtraImport": true,
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "isExtraImport": true,
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "isExtraImport": true,
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "isExtraImport": true,
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "queue",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "queue",
        "description": "queue",
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "BaseHTTPRequestHandler",
        "importPath": "http.server",
        "description": "http.server",
        "isExtraImport": true,
        "detail": "http.server",
        "documentation": {}
    },
    {
        "label": "HTTPServer",
        "importPath": "http.server",
        "description": "http.server",
        "isExtraImport": true,
        "detail": "http.server",
        "documentation": {}
    },
    {
        "label": "ThreadingMixIn",
        "importPath": "socketserver",
        "description": "socketserver",
        "isExtraImport": true,
        "detail": "socketserver",
        "documentation": {}
    },
    {
        "label": "pytrt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytrt",
        "description": "pytrt",
        "detail": "pytrt",
        "documentation": {}
    },
    {
        "label": "append",
        "importPath": "numpy.lib.function_base",
        "description": "numpy.lib.function_base",
        "isExtraImport": true,
        "detail": "numpy.lib.function_base",
        "documentation": {}
    },
    {
        "label": "ctypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ctypes",
        "description": "ctypes",
        "detail": "ctypes",
        "documentation": {}
    },
    {
        "label": "pycuda.driver",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycuda.driver",
        "description": "pycuda.driver",
        "detail": "pycuda.driver",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "pycuda.autoinit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycuda.autoinit",
        "description": "pycuda.autoinit",
        "detail": "pycuda.autoinit",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "expit",
        "importPath": "scipy.special",
        "description": "scipy.special",
        "isExtraImport": true,
        "detail": "scipy.special",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "EasyDict",
        "importPath": "easydict",
        "description": "easydict",
        "isExtraImport": true,
        "detail": "easydict",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "isExtraImport": true,
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "isExtraImport": true,
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "isExtraImport": true,
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "TrtYOLO",
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "isExtraImport": true,
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "isExtraImport": true,
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "TrtYOLO",
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "isExtraImport": true,
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "isExtraImport": true,
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "isExtraImport": true,
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "importPath": "utils.camera",
        "description": "utils.camera",
        "isExtraImport": true,
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "Camera",
        "importPath": "utils.camera",
        "description": "utils.camera",
        "isExtraImport": true,
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "importPath": "utils.camera",
        "description": "utils.camera",
        "isExtraImport": true,
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "Camera",
        "importPath": "utils.camera",
        "description": "utils.camera",
        "isExtraImport": true,
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_window",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "set_display",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_fps",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "open_window",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "set_display",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_fps",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "BBoxVisualization",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "BBoxVisualization",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "isExtraImport": true,
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "isExtraImport": true,
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "features = torch.load(\"features.pth\")\nqf = features[\"qf\"]\nql = features[\"ql\"]\ngf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "qf",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "qf = features[\"qf\"]\nql = features[\"ql\"]\ngf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "ql",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "ql = features[\"ql\"]\ngf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "gf",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "gf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "gl",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "gl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "scores",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "scores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "res",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "res = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "top1correct",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "top1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "Extractor",
        "kind": 6,
        "importPath": "deep_sort.deep.feature_extractor",
        "description": "deep_sort.deep.feature_extractor",
        "peekOfCode": "class Extractor(object):\n    def __init__(self, model_path, use_cuda=True):\n        self.net = Net(reid=True)\n        self.device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\n        state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)['net_dict']\n        self.net.load_state_dict(state_dict)\n        print(\"Loading weights from {}... Done!\".format(model_path))\n        self.net.to(self.device)\n        self.size = (64, 128)\n        self.norm = transforms.Compose([",
        "detail": "deep_sort.deep.feature_extractor",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "deep_sort.deep.model",
        "description": "deep_sort.deep.model",
        "peekOfCode": "class BasicBlock(nn.Module):\n    def __init__(self, c_in, c_out,is_downsample=False):\n        super(BasicBlock,self).__init__()\n        self.is_downsample = is_downsample\n        if is_downsample:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=2, padding=1, bias=False)\n        else:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(c_out)\n        self.relu = nn.ReLU(True)",
        "detail": "deep_sort.deep.model",
        "documentation": {}
    },
    {
        "label": "Net",
        "kind": 6,
        "importPath": "deep_sort.deep.model",
        "description": "deep_sort.deep.model",
        "peekOfCode": "class Net(nn.Module):\n    def __init__(self, num_classes=751 ,reid=False):\n        super(Net,self).__init__()\n        # 3 128 64\n        self.conv = nn.Sequential(\n            nn.Conv2d(3,64,3,stride=1,padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(32,32,3,stride=1,padding=1),\n            # nn.BatchNorm2d(32),",
        "detail": "deep_sort.deep.model",
        "documentation": {}
    },
    {
        "label": "make_layers",
        "kind": 2,
        "importPath": "deep_sort.deep.model",
        "description": "deep_sort.deep.model",
        "peekOfCode": "def make_layers(c_in,c_out,repeat_times, is_downsample=False):\n    blocks = []\n    for i in range(repeat_times):\n        if i ==0:\n            blocks += [BasicBlock(c_in,c_out, is_downsample=is_downsample),]\n        else:\n            blocks += [BasicBlock(c_out,c_out),]\n    return nn.Sequential(*blocks)\nclass Net(nn.Module):\n    def __init__(self, num_classes=751 ,reid=False):",
        "detail": "deep_sort.deep.model",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "deep_sort.deep.original_model",
        "description": "deep_sort.deep.original_model",
        "peekOfCode": "class BasicBlock(nn.Module):\n    def __init__(self, c_in, c_out,is_downsample=False):\n        super(BasicBlock,self).__init__()\n        self.is_downsample = is_downsample\n        if is_downsample:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=2, padding=1, bias=False)\n        else:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(c_out)\n        self.relu = nn.ReLU(True)",
        "detail": "deep_sort.deep.original_model",
        "documentation": {}
    },
    {
        "label": "Net",
        "kind": 6,
        "importPath": "deep_sort.deep.original_model",
        "description": "deep_sort.deep.original_model",
        "peekOfCode": "class Net(nn.Module):\n    def __init__(self, num_classes=625 ,reid=False):\n        super(Net,self).__init__()\n        # 3 128 64\n        self.conv = nn.Sequential(\n            nn.Conv2d(3,32,3,stride=1,padding=1),\n            nn.BatchNorm2d(32),\n            nn.ELU(inplace=True),\n            nn.Conv2d(32,32,3,stride=1,padding=1),\n            nn.BatchNorm2d(32),",
        "detail": "deep_sort.deep.original_model",
        "documentation": {}
    },
    {
        "label": "make_layers",
        "kind": 2,
        "importPath": "deep_sort.deep.original_model",
        "description": "deep_sort.deep.original_model",
        "peekOfCode": "def make_layers(c_in,c_out,repeat_times, is_downsample=False):\n    blocks = []\n    for i in range(repeat_times):\n        if i ==0:\n            blocks += [BasicBlock(c_in,c_out, is_downsample=is_downsample),]\n        else:\n            blocks += [BasicBlock(c_out,c_out),]\n    return nn.Sequential(*blocks)\nclass Net(nn.Module):\n    def __init__(self, num_classes=625 ,reid=False):",
        "detail": "deep_sort.deep.original_model",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "parser = argparse.ArgumentParser(description=\"Train on market1501\")\nparser.add_argument(\"--data-dir\",default='data',type=str)\nparser.add_argument(\"--no-cuda\",action=\"store_true\")\nparser.add_argument(\"--gpu-id\",default=0,type=int)\nargs = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loader",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "args = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loader\nroot = args.data_dir\nquery_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "device = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loader\nroot = args.data_dir\nquery_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "root = args.data_dir\nquery_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "query_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "query_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "gallery_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "gallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False\n)",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\ngalleryloader = torch.utils.data.DataLoader(",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "queryloader",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "queryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\ngalleryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(gallery_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\n# net definition\nnet = Net(reid=True)",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "galleryloader",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "galleryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(gallery_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\n# net definition\nnet = Net(reid=True)\nassert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\nprint('Loading from checkpoint/ckpt.t7')\ncheckpoint = torch.load(\"./checkpoint/ckpt.t7\")\nnet_dict = checkpoint['net_dict']",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "net = Net(reid=True)\nassert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\nprint('Loading from checkpoint/ckpt.t7')\ncheckpoint = torch.load(\"./checkpoint/ckpt.t7\")\nnet_dict = checkpoint['net_dict']\nnet.load_state_dict(net_dict, strict=False)\nnet.eval()\nnet.to(device)\n# compute features\nquery_features = torch.tensor([]).float()",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "checkpoint",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\nnet_dict = checkpoint['net_dict']\nnet.load_state_dict(net_dict, strict=False)\nnet.eval()\nnet.to(device)\n# compute features\nquery_features = torch.tensor([]).float()\nquery_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "net_dict",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "net_dict = checkpoint['net_dict']\nnet.load_state_dict(net_dict, strict=False)\nnet.eval()\nnet.to(device)\n# compute features\nquery_features = torch.tensor([]).float()\nquery_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "query_features",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "query_features = torch.tensor([]).float()\nquery_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "query_labels",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "query_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))\n    for idx,(inputs,labels) in enumerate(galleryloader):",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "gallery_features",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "gallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))\n    for idx,(inputs,labels) in enumerate(galleryloader):\n        inputs = inputs.to(device)",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "gallery_labels",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "gallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))\n    for idx,(inputs,labels) in enumerate(galleryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "features = {\n    \"qf\": query_features,\n    \"ql\": query_labels,\n    \"gf\": gallery_features,\n    \"gl\": gallery_labels\n}\ntorch.save(features,\"features.pth\")",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0\n    total = 0\n    interval = args.interval\n    start = time.time()\n    for idx, (inputs, labels) in enumerate(trainloader):",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0.\n    correct = 0\n    total = 0\n    start = time.time()\n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(testloader):\n            inputs, labels = inputs.to(device), labels.to(device)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "draw_curve",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)\n    ax0.plot(x_epoch, record['train_loss'], 'bo-', label='train')\n    ax0.plot(x_epoch, record['test_loss'], 'ro-', label='val')\n    ax1.plot(x_epoch, record['train_err'], 'bo-', label='train')",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "lr_decay",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def lr_decay():\n    global optimizer\n    for params in optimizer.param_groups:\n        params['lr'] *= 0.1\n        lr = params['lr']\n        print(\"Learning rate adjusted to {}\".format(lr))\ndef main():\n    for epoch in range(start_epoch, start_epoch+40):\n        train_loss, train_err = train(epoch)\n        test_loss, test_err = test(epoch)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def main():\n    for epoch in range(start_epoch, start_epoch+40):\n        train_loss, train_err = train(epoch)\n        test_loss, test_err = test(epoch)\n        draw_curve(epoch, train_loss, train_err, test_loss, test_err)\n        if (epoch+1)%20==0:\n            lr_decay()\nif __name__ == '__main__':\n    main()",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "parser = argparse.ArgumentParser(description=\"Train on market1501\")\nparser.add_argument(\"--data-dir\",default='data',type=str)\nparser.add_argument(\"--no-cuda\",action=\"store_true\")\nparser.add_argument(\"--gpu-id\",default=0,type=int)\nparser.add_argument(\"--lr\",default=0.1, type=float)\nparser.add_argument(\"--interval\",'-i',default=20,type=int)\nparser.add_argument('--resume', '-r',action='store_true')\nargs = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "args = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loading\nroot = args.data_dir\ntrain_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "device = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loading\nroot = args.data_dir\ntrain_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "root = args.data_dir\ntrain_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "train_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "train_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "test_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "test_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "transform_train",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "transform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "transform_test",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "transform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntrainloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(train_dir, transform=transform_train),\n    batch_size=64,shuffle=True\n)\ntestloader = torch.utils.data.DataLoader(",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "trainloader",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "trainloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(train_dir, transform=transform_train),\n    batch_size=64,shuffle=True\n)\ntestloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(test_dir, transform=transform_test),\n    batch_size=64,shuffle=True\n)\nnum_classes = len(trainloader.dataset.classes)\n# net definition",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "testloader",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "testloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(test_dir, transform=transform_test),\n    batch_size=64,shuffle=True\n)\nnum_classes = len(trainloader.dataset.classes)\n# net definition\nstart_epoch = 0\nnet = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "num_classes",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "num_classes = len(trainloader.dataset.classes)\n# net definition\nstart_epoch = 0\nnet = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\n    print('Loading from checkpoint/ckpt.t7')\n    checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\n    # import ipdb; ipdb.set_trace()\n    net_dict = checkpoint['net_dict']",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "start_epoch",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "start_epoch = 0\nnet = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\n    print('Loading from checkpoint/ckpt.t7')\n    checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\n    # import ipdb; ipdb.set_trace()\n    net_dict = checkpoint['net_dict']\n    net.load_state_dict(net_dict)\n    best_acc = checkpoint['acc']",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "net = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\n    print('Loading from checkpoint/ckpt.t7')\n    checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\n    # import ipdb; ipdb.set_trace()\n    net_dict = checkpoint['net_dict']\n    net.load_state_dict(net_dict)\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), args.lr, momentum=0.9, weight_decay=5e-4)\nbest_acc = 0.\n# train function for each epoch\ndef train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "optimizer = torch.optim.SGD(net.parameters(), args.lr, momentum=0.9, weight_decay=5e-4)\nbest_acc = 0.\n# train function for each epoch\ndef train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0\n    total = 0",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "best_acc",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "best_acc = 0.\n# train function for each epoch\ndef train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0\n    total = 0\n    interval = args.interval",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "x_epoch",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "x_epoch = []\nrecord = {'train_loss':[], 'train_err':[], 'test_loss':[], 'test_err':[]}\nfig = plt.figure()\nax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "record",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "record = {'train_loss':[], 'train_err':[], 'test_loss':[], 'test_err':[]}\nfig = plt.figure()\nax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "fig = plt.figure()\nax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "ax0",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "ax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)\n    ax0.plot(x_epoch, record['train_loss'], 'bo-', label='train')",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "ax1",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "ax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)\n    ax0.plot(x_epoch, record['train_loss'], 'bo-', label='train')\n    ax0.plot(x_epoch, record['test_loss'], 'ro-', label='val')",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "Detection",
        "kind": 6,
        "importPath": "deep_sort.sort.detection",
        "description": "deep_sort.sort.detection",
        "peekOfCode": "class Detection(object):\n    \"\"\"\n    This class represents a bounding box detection in a single image.\n    Parameters\n    ----------\n    tlwh : array_like\n        Bounding box in format `(x, y, w, h)`.\n    confidence : float\n        Detector confidence score.\n    feature : array_like",
        "detail": "deep_sort.sort.detection",
        "documentation": {}
    },
    {
        "label": "iou",
        "kind": 2,
        "importPath": "deep_sort.sort.iou_matching",
        "description": "deep_sort.sort.iou_matching",
        "peekOfCode": "def iou(bbox, candidates):\n    \"\"\"Computer intersection over union.\n    Parameters\n    ----------\n    bbox : ndarray\n        A bounding box in format `(top left x, top left y, width, height)`.\n    candidates : ndarray\n        A matrix of candidate bounding boxes (one per row) in the same format\n        as `bbox`.\n    Returns",
        "detail": "deep_sort.sort.iou_matching",
        "documentation": {}
    },
    {
        "label": "iou_cost",
        "kind": 2,
        "importPath": "deep_sort.sort.iou_matching",
        "description": "deep_sort.sort.iou_matching",
        "peekOfCode": "def iou_cost(tracks, detections, track_indices=None,\n             detection_indices=None):\n    \"\"\"An intersection over union distance metric.\n    Parameters\n    ----------\n    tracks : List[deep_sort.track.Track]\n        A list of tracks.\n    detections : List[deep_sort.detection.Detection]\n        A list of detections.\n    track_indices : Optional[List[int]]",
        "detail": "deep_sort.sort.iou_matching",
        "documentation": {}
    },
    {
        "label": "KalmanFilter",
        "kind": 6,
        "importPath": "deep_sort.sort.kalman_filter",
        "description": "deep_sort.sort.kalman_filter",
        "peekOfCode": "class KalmanFilter(object):\n    \"\"\"\n    A simple Kalman filter for tracking bounding boxes in image space.\n    The 8-dimensional state space\n        x, y, a, h, vx, vy, va, vh\n    contains the bounding box center position (x, y), aspect ratio a, height h,\n    and their respective velocities.\n    Object motion follows a constant velocity model. The bounding box location\n    (x, y, a, h) is taken as direct observation of the state space (linear\n    observation model).",
        "detail": "deep_sort.sort.kalman_filter",
        "documentation": {}
    },
    {
        "label": "chi2inv95",
        "kind": 5,
        "importPath": "deep_sort.sort.kalman_filter",
        "description": "deep_sort.sort.kalman_filter",
        "peekOfCode": "chi2inv95 = {\n    1: 3.8415,\n    2: 5.9915,\n    3: 7.8147,\n    4: 9.4877,\n    5: 11.070,\n    6: 12.592,\n    7: 14.067,\n    8: 15.507,\n    9: 16.919}",
        "detail": "deep_sort.sort.kalman_filter",
        "documentation": {}
    },
    {
        "label": "min_cost_matching",
        "kind": 2,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "def min_cost_matching(\n        distance_metric, max_distance, tracks, detections, track_indices=None,\n        detection_indices=None):\n    \"\"\"Solve linear assignment problem.\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should\n        return the NxM dimensional cost matrix, where element (i, j) is the",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "matching_cascade",
        "kind": 2,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "def matching_cascade(\n        distance_metric, max_distance, cascade_depth, tracks, detections,\n        track_indices=None, detection_indices=None):\n    \"\"\"Run matching cascade.\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should\n        return the NxM dimensional cost matrix, where element (i, j) is the",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "gate_cost_matrix",
        "kind": 2,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "def gate_cost_matrix(\n        kf, cost_matrix, tracks, detections, track_indices, detection_indices,\n        gated_cost=INFTY_COST, only_position=False):\n    \"\"\"Invalidate infeasible entries in cost matrix based on the state\n    distributions obtained by Kalman filtering.\n    Parameters\n    ----------\n    kf : The Kalman filter.\n    cost_matrix : ndarray\n        The NxM dimensional cost matrix, where N is the number of track indices",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "INFTY_COST",
        "kind": 5,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "INFTY_COST = 1e+5\ndef min_cost_matching(\n        distance_metric, max_distance, tracks, detections, track_indices=None,\n        detection_indices=None):\n    \"\"\"Solve linear assignment problem.\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "NearestNeighborDistanceMetric",
        "kind": 6,
        "importPath": "deep_sort.sort.nn_matching",
        "description": "deep_sort.sort.nn_matching",
        "peekOfCode": "class NearestNeighborDistanceMetric(object):\n    \"\"\"\n    A nearest neighbor distance metric that, for each target, returns\n    the closest distance to any sample that has been observed so far.\n    Parameters\n    ----------\n    metric : str\n        Either \"euclidean\" or \"cosine\".\n    matching_threshold: float\n        The matching threshold. Samples with larger distance are considered an",
        "detail": "deep_sort.sort.nn_matching",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "kind": 2,
        "importPath": "deep_sort.sort.preprocessing",
        "description": "deep_sort.sort.preprocessing",
        "peekOfCode": "def non_max_suppression(boxes, max_bbox_overlap, scores=None):\n    \"\"\"Suppress overlapping detections.\n    Original code from [1]_ has been adapted to include confidence score.\n    .. [1] http://www.pyimagesearch.com/2015/02/16/\n           faster-non-maximum-suppression-python/\n    Examples\n    --------\n        >>> boxes = [d.roi for d in detections]\n        >>> scores = [d.confidence for d in detections]\n        >>> indices = non_max_suppression(boxes, max_bbox_overlap, scores)",
        "detail": "deep_sort.sort.preprocessing",
        "documentation": {}
    },
    {
        "label": "TrackState",
        "kind": 6,
        "importPath": "deep_sort.sort.track",
        "description": "deep_sort.sort.track",
        "peekOfCode": "class TrackState:\n    \"\"\"\n    Enumeration type for the single target track state. Newly created tracks are\n    classified as `tentative` until enough evidence has been collected. Then,\n    the track state is changed to `confirmed`. Tracks that are no longer alive\n    are classified as `deleted` to mark them for removal from the set of active\n    tracks.\n    \"\"\"\n    Tentative = 1\n    Confirmed = 2",
        "detail": "deep_sort.sort.track",
        "documentation": {}
    },
    {
        "label": "Track",
        "kind": 6,
        "importPath": "deep_sort.sort.track",
        "description": "deep_sort.sort.track",
        "peekOfCode": "class Track:\n    \"\"\"\n    A single target track with state space `(x, y, a, h)` and associated\n    velocities, where `(x, y)` is the center of the bounding box, `a` is the\n    aspect ratio and `h` is the height.\n    Parameters\n    ----------\n    mean : ndarray\n        Mean vector of the initial state distribution.\n    covariance : ndarray",
        "detail": "deep_sort.sort.track",
        "documentation": {}
    },
    {
        "label": "Tracker",
        "kind": 6,
        "importPath": "deep_sort.sort.tracker",
        "description": "deep_sort.sort.tracker",
        "peekOfCode": "class Tracker:\n    \"\"\"\n    This is the multi-target tracker.\n    Parameters\n    ----------\n    metric : nn_matching.NearestNeighborDistanceMetric\n        A distance metric for measurement-to-track association.\n    max_age : int\n        Maximum number of missed misses before a track is deleted.\n    n_init : int",
        "detail": "deep_sort.sort.tracker",
        "documentation": {}
    },
    {
        "label": "DeepSort",
        "kind": 6,
        "importPath": "deep_sort.deep_sort",
        "description": "deep_sort.deep_sort",
        "peekOfCode": "class DeepSort(object):\n    def __init__(self, model_path, max_dist=0.2, min_confidence=0.3, nms_max_overlap=1.0, max_iou_distance=0.7, max_age=70, n_init=3, nn_budget=100, use_cuda=True):\n        self.min_confidence = min_confidence\n        self.nms_max_overlap = nms_max_overlap\n        self.extractor = Extractor(model_path, use_cuda=use_cuda)\n        max_cosine_distance = max_dist\n        nn_budget = 100\n        metric = NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n        self.tracker = Tracker(metric, max_iou_distance=max_iou_distance, max_age=max_age, n_init=n_init)\n    def update(self, bbox_xywh, confidences, ori_img):",
        "detail": "deep_sort.deep_sort",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "deep_sort.deep_sort",
        "description": "deep_sort.deep_sort",
        "peekOfCode": "__all__ = ['DeepSort']\nclass DeepSort(object):\n    def __init__(self, model_path, max_dist=0.2, min_confidence=0.3, nms_max_overlap=1.0, max_iou_distance=0.7, max_age=70, n_init=3, nn_budget=100, use_cuda=True):\n        self.min_confidence = min_confidence\n        self.nms_max_overlap = nms_max_overlap\n        self.extractor = Extractor(model_path, use_cuda=use_cuda)\n        max_cosine_distance = max_dist\n        nn_budget = 100\n        metric = NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n        self.tracker = Tracker(metric, max_iou_distance=max_iou_distance, max_age=max_age, n_init=n_init)",
        "detail": "deep_sort.deep_sort",
        "documentation": {}
    },
    {
        "label": "Tracker",
        "kind": 6,
        "importPath": "tracker.tracker",
        "description": "tracker.tracker",
        "peekOfCode": "class Tracker():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)\n        #---tensorrt----#\n        self.engine = get_engine(engine_file_path)\n        self.context = self.engine.create_execution_context()\n        self.inputs, self.outputs, self.bindings, self.stream = common.allocate_buffers(self.engine)\n        # ---tensorrt----#",
        "detail": "tracker.tracker",
        "documentation": {}
    },
    {
        "label": "get_engine",
        "kind": 2,
        "importPath": "tracker.tracker",
        "description": "tracker.tracker",
        "peekOfCode": "def get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)",
        "detail": "tracker.tracker",
        "documentation": {}
    },
    {
        "label": "TRT_LOGGER",
        "kind": 5,
        "importPath": "tracker.tracker",
        "description": "tracker.tracker",
        "peekOfCode": "TRT_LOGGER = trt.Logger()\ndef get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args",
        "detail": "tracker.tracker",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "kind": 6,
        "importPath": "tracker.tracker_tiny",
        "description": "tracker.tracker_tiny",
        "peekOfCode": "class Tracker_tiny():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)\n        #---tensorrt----#\n        self.engine = get_engine(engine_file_path)\n        self.context = self.engine.create_execution_context()\n        self.inputs, self.outputs, self.bindings, self.stream = common.allocate_buffers(self.engine)\n        # ---tensorrt----#",
        "detail": "tracker.tracker_tiny",
        "documentation": {}
    },
    {
        "label": "get_engine",
        "kind": 2,
        "importPath": "tracker.tracker_tiny",
        "description": "tracker.tracker_tiny",
        "peekOfCode": "def get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker_tiny():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)",
        "detail": "tracker.tracker_tiny",
        "documentation": {}
    },
    {
        "label": "TRT_LOGGER",
        "kind": 5,
        "importPath": "tracker.tracker_tiny",
        "description": "tracker.tracker_tiny",
        "peekOfCode": "TRT_LOGGER = trt.Logger()\ndef get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker_tiny():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args",
        "detail": "tracker.tracker_tiny",
        "documentation": {}
    },
    {
        "label": "Camera",
        "kind": 6,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "class Camera():\n    \"\"\"Camera class which supports reading images from theses video sources:\n    1. Image (jpg, png, etc.) file, repeating indefinitely\n    2. Video file\n    3. RTSP (IP CAM)\n    4. USB webcam\n    5. Jetson onboard camera\n    \"\"\"\n    def __init__(self, args):\n        self.args = args",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--image', type=str, default=None,\n                        help='image file name, e.g. dog.jpg')\n    parser.add_argument('--video', type=str, default=None,\n                        help='video file name, e.g. traffic.mp4')\n    parser.add_argument('--video_looping', action='store_true',\n                        help='loop around the video file [False]')\n    parser.add_argument('--rtsp', type=str, default=None,\n                        help=('RTSP H.264 stream, e.g. '",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_cam_rtsp",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def open_cam_rtsp(uri, width, height, latency):\n    \"\"\"Open an RTSP URI (IP CAM).\"\"\"\n    gst_elements = str(subprocess.check_output('gst-inspect-1.0'))\n    if 'omxh264dec' in gst_elements:\n        # Use hardware H.264 decoder on Jetson platforms\n        gst_str = ('rtspsrc location={} latency={} ! '\n                   'rtph264depay ! h264parse ! omxh264dec ! '\n                   'nvvidconv ! '\n                   'video/x-raw, width=(int){}, height=(int){}, '\n                   'format=(string)BGRx ! videoconvert ! '",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_cam_usb",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def open_cam_usb(dev, width, height):\n    \"\"\"Open a USB webcam.\"\"\"\n    if USB_GSTREAMER:\n        gst_str = ('v4l2src device=/dev/video{} ! '\n                   'video/x-raw, width=(int){}, height=(int){} ! '\n                   'videoconvert ! appsink').format(dev, width, height)\n        return cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)\n    else:\n        return cv2.VideoCapture(dev)\ndef open_cam_onboard(width, height):",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_cam_onboard",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def open_cam_onboard(width, height):\n    \"\"\"Open the Jetson onboard camera.\"\"\"\n    gst_elements = str(subprocess.check_output('gst-inspect-1.0'))\n    if 'nvcamerasrc' in gst_elements:\n        # On versions of L4T prior to 28.1, you might need to add\n        # 'flip-method=2' into gst_str below.\n        gst_str = ('nvcamerasrc ! '\n                   'video/x-raw(memory:NVMM), '\n                   'width=(int)2592, height=(int)1458, '\n                   'format=(string)I420, framerate=(fraction)30/1 ! '",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "grab_img",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def grab_img(cam):\n    \"\"\"This 'grab_img' function is designed to be run in the sub-thread.\n    Once started, this thread continues to grab a new image and put it\n    into the global 'img_handle', until 'thread_running' is set to False.\n    \"\"\"\n    while cam.thread_running:\n        _, cam.img_handle = cam.cap.read()\n        if cam.img_handle is None:\n            #logging.warning('Camera: cap.read() returns None...')\n            break",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "USB_GSTREAMER",
        "kind": 5,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "USB_GSTREAMER = True\ndef add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--image', type=str, default=None,\n                        help='image file name, e.g. dog.jpg')\n    parser.add_argument('--video', type=str, default=None,\n                        help='video file name, e.g. traffic.mp4')\n    parser.add_argument('--video_looping', action='store_true',\n                        help='loop around the video file [False]')\n    parser.add_argument('--rtsp', type=str, default=None,",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_window",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def open_window(window_name, title, width=None, height=None):\n    \"\"\"Open the display window.\"\"\"\n    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n    cv2.setWindowTitle(window_name, title)\n    if width and height:\n        cv2.resizeWindow(window_name, width, height)\ndef show_help_text(img, help_text):\n    \"\"\"Draw help text on image.\"\"\"\n    cv2.putText(img, help_text, (11, 20), cv2.FONT_HERSHEY_PLAIN, 1.0,\n                (32, 32, 32), 4, cv2.LINE_AA)",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_help_text",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def show_help_text(img, help_text):\n    \"\"\"Draw help text on image.\"\"\"\n    cv2.putText(img, help_text, (11, 20), cv2.FONT_HERSHEY_PLAIN, 1.0,\n                (32, 32, 32), 4, cv2.LINE_AA)\n    cv2.putText(img, help_text, (10, 20), cv2.FONT_HERSHEY_PLAIN, 1.0,\n                (240, 240, 240), 1, cv2.LINE_AA)\n    return img\ndef show_fps(img, fps):\n    \"\"\"Draw fps number at top-left corner of the image.\"\"\"\n    font = cv2.FONT_HERSHEY_PLAIN",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_fps",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def show_fps(img, fps):\n    \"\"\"Draw fps number at top-left corner of the image.\"\"\"\n    font = cv2.FONT_HERSHEY_PLAIN\n    line = cv2.LINE_AA\n    fps_text = 'FPS: {:.2f}'.format(fps)\n    cv2.putText(img, fps_text, (11, 20), font, 1.0, (32, 32, 32), 4, line)\n    cv2.putText(img, fps_text, (10, 20), font, 1.0, (240, 240, 240), 1, line)\n    return img\ndef set_display(window_name, full_scrn):\n    \"\"\"Set disply window to either full screen or normal.\"\"\"",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "set_display",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def set_display(window_name, full_scrn):\n    \"\"\"Set disply window to either full screen or normal.\"\"\"\n    if full_scrn:\n        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN,\n                              cv2.WINDOW_FULLSCREEN)\n    else:\n        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN,\n                              cv2.WINDOW_NORMAL)",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "MjpegHandler",
        "kind": 6,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "class MjpegHandler(BaseHTTPRequestHandler):\n    \"\"\"A simple MJPEG handler which publishes images.\"\"\"\n    def _handle_mjpeg(self):\n        global _MJPEG_QUEUE\n        img = _MJPEG_QUEUE.get()\n        self.send_response(200)\n        self.send_header(\n            'Content-type',\n            'multipart/x-mixed-replace; boundary=--jpgboundary'\n        )",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "ThreadedHTTPServer",
        "kind": 6,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "class ThreadedHTTPServer(ThreadingMixIn, HTTPServer):\n    \"\"\"Handle HTTP requests in a separate thread.\"\"\"\n    # not used...\ndef run_server(server):\n    server.serve_forever()  # this exits when server.shutdown() is called\n    server.socket.shutdown(socket.SHUT_RDWR)\n    server.socket.close()\nclass MjpegServer(object):\n    def __init__(self, init_img=None, ip='', port=8080):\n        # initialize the queue with a dummy image",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "MjpegServer",
        "kind": 6,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "class MjpegServer(object):\n    def __init__(self, init_img=None, ip='', port=8080):\n        # initialize the queue with a dummy image\n        global _MJPEG_QUEUE\n        init_img = init_img if init_img else \\\n                   np.ones((480, 640, 3), np.uint8) * 255  # all white\n        _MJPEG_QUEUE.put(init_img)\n        # create the HTTP server and run it from the child thread\n        self.server = HTTPServer((ip, port), MjpegHandler)\n        self.run_thread = threading.Thread(",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "run_server",
        "kind": 2,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "def run_server(server):\n    server.serve_forever()  # this exits when server.shutdown() is called\n    server.socket.shutdown(socket.SHUT_RDWR)\n    server.socket.close()\nclass MjpegServer(object):\n    def __init__(self, init_img=None, ip='', port=8080):\n        # initialize the queue with a dummy image\n        global _MJPEG_QUEUE\n        init_img = init_img if init_img else \\\n                   np.ones((480, 640, 3), np.uint8) * 255  # all white",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "_MJPEG_QUEUE",
        "kind": 5,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "_MJPEG_QUEUE = queue.Queue(maxsize=2)\n_SLEEP_INTERVAL = 0.1  # update JPG roughly every 0.1 second\nclass MjpegHandler(BaseHTTPRequestHandler):\n    \"\"\"A simple MJPEG handler which publishes images.\"\"\"\n    def _handle_mjpeg(self):\n        global _MJPEG_QUEUE\n        img = _MJPEG_QUEUE.get()\n        self.send_response(200)\n        self.send_header(\n            'Content-type',",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "_SLEEP_INTERVAL",
        "kind": 5,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "_SLEEP_INTERVAL = 0.1  # update JPG roughly every 0.1 second\nclass MjpegHandler(BaseHTTPRequestHandler):\n    \"\"\"A simple MJPEG handler which publishes images.\"\"\"\n    def _handle_mjpeg(self):\n        global _MJPEG_QUEUE\n        img = _MJPEG_QUEUE.get()\n        self.send_response(200)\n        self.send_header(\n            'Content-type',\n            'multipart/x-mixed-replace; boundary=--jpgboundary'",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "TrtPNet",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtPNet(object):\n    \"\"\"TrtPNet\n    Refer to mtcnn/det1_relu.prototxt for calculation of input/output\n    dimmensions of TrtPNet, as well as input H offsets (for all scales).\n    The output H offsets are merely input offsets divided by stride (2).\n    \"\"\"\n    input_h_offsets  = (0, 216, 370, 478, 556, 610, 648, 676, 696)\n    output_h_offsets = (0, 108, 185, 239, 278, 305, 324, 338, 348)\n    max_n_scales = 9\n    def __init__(self, engine):",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "TrtRNet",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtRNet(object):\n    \"\"\"TrtRNet\n    # Arguments\n        engine: path to the TensorRT engine (det2) file\n    \"\"\"\n    def __init__(self, engine):\n        self.trtnet = pytrt.PyTrtMtcnn(engine,\n                                       (3, 24, 24),\n                                       (2, 1, 1),\n                                       (4, 1, 1))",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "TrtONet",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtONet(object):\n    \"\"\"TrtONet\n    # Arguments\n        engine: path to the TensorRT engine (det3) file\n    \"\"\"\n    def __init__(self, engine):\n        self.trtnet = pytrt.PyTrtMtcnn(engine,\n                                       (3, 48, 48),\n                                       (2, 1, 1),\n                                       (4, 1, 1),",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "TrtMtcnn",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtMtcnn(object):\n    \"\"\"TrtMtcnn\"\"\"\n    def __init__(self):\n        self.pnet = TrtPNet('mtcnn/det1.engine')\n        self.rnet = TrtRNet('mtcnn/det2.engine')\n        self.onet = TrtONet('mtcnn/det3.engine')\n    def __del__(self):\n        self.onet.destroy()\n        self.rnet.destroy()\n        self.pnet.destroy()",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "convert_to_1x1",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def convert_to_1x1(boxes):\n    \"\"\"Convert detection boxes to 1:1 sizes\n    # Arguments\n        boxes: numpy array, shape (n,5), dtype=float32\n    # Returns\n        boxes_1x1\n    \"\"\"\n    boxes_1x1 = boxes.copy()\n    hh = boxes[:, 3] - boxes[:, 1] + 1.\n    ww = boxes[:, 2] - boxes[:, 0] + 1.",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "crop_img_with_padding",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def crop_img_with_padding(img, box, padding=0):\n    \"\"\"Crop a box from image, with out-of-boundary pixels padded\n    # Arguments\n        img: img as a numpy array, shape (H, W, 3)\n        box: numpy array, shape (5,) or (4,)\n        padding: integer value for padded pixels\n    # Returns\n        cropped_im: cropped image as a numpy array, shape (H, W, 3)\n    \"\"\"\n    img_h, img_w, _ = img.shape",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "nms",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def nms(boxes, threshold, type='Union'):\n    \"\"\"Non-Maximum Supression\n    # Arguments\n        boxes: numpy array [:, 0:5] of [x1, y1, x2, y2, score]'s\n        threshold: confidence/score threshold, e.g. 0.5\n        type: 'Union' or 'Min'\n    # Returns\n        A list of indices indicating the result of NMS\n    \"\"\"\n    if boxes.shape[0] == 0:",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "generate_pnet_bboxes",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def generate_pnet_bboxes(conf, reg, scale, t):\n    \"\"\"\n    # Arguments\n        conf: softmax score (face or not) of each grid\n        reg: regression values of x1, y1, x2, y2 coordinates.\n             The values are normalized to grid width (12) and\n             height (12).\n        scale: scale-down factor with respect to original image\n        t: confidence threshold\n    # Returns",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "generate_rnet_bboxes",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def generate_rnet_bboxes(conf, reg, pboxes, t):\n    \"\"\"\n    # Arguments\n        conf: softmax score (face or not) of each box\n        reg: regression values of x1, y1, x2, y2 coordinates.\n             The values are normalized to box width and height.\n        pboxes: input boxes to RNet\n        t: confidence threshold\n    # Returns\n        boxes: a numpy array of box coordinates and cooresponding",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "generate_onet_outputs",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def generate_onet_outputs(conf, reg_boxes, reg_marks, rboxes, t):\n    \"\"\"\n    # Arguments\n        conf: softmax score (face or not) of each box\n        reg_boxes: regression values of x1, y1, x2, y2\n                   The values are normalized to box width and height.\n        reg_marks: regression values of the 5 facial landmark points\n        rboxes: input boxes to ONet (already converted to 2x1)\n        t: confidence threshold\n    # Returns",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "clip_dets",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def clip_dets(dets, img_w, img_h):\n    \"\"\"Round and clip detection (x1, y1, ...) values.\n    Note we exclude the last value of 'dets' in computation since\n    it is 'conf'.\n    \"\"\"\n    dets[:, 0:-1] = np.fix(dets[:, 0:-1])\n    evens = np.arange(0, dets.shape[1]-1, 2)\n    odds  = np.arange(1, dets.shape[1]-1, 2)\n    dets[:, evens] = np.clip(dets[:, evens], 0., float(img_w-1))\n    dets[:, odds]  = np.clip(dets[:, odds], 0., float(img_h-1))",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "PIXEL_MEAN",
        "kind": 5,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "PIXEL_MEAN = 127.5\nPIXEL_SCALE = 0.0078125\ndef convert_to_1x1(boxes):\n    \"\"\"Convert detection boxes to 1:1 sizes\n    # Arguments\n        boxes: numpy array, shape (n,5), dtype=float32\n    # Returns\n        boxes_1x1\n    \"\"\"\n    boxes_1x1 = boxes.copy()",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "PIXEL_SCALE",
        "kind": 5,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "PIXEL_SCALE = 0.0078125\ndef convert_to_1x1(boxes):\n    \"\"\"Convert detection boxes to 1:1 sizes\n    # Arguments\n        boxes: numpy array, shape (n,5), dtype=float32\n    # Returns\n        boxes_1x1\n    \"\"\"\n    boxes_1x1 = boxes.copy()\n    hh = boxes[:, 3] - boxes[:, 1] + 1.",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "select_yellow_white",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def select_yellow_white(img_org):\n    #hsv_img = cv2.cvtColor(img_org, cv2.COLOR_RGB2HLS)\n    hsv_img = cv2.cvtColor(img_org, cv2.COLOR_BGR2HLS)\n    img_hsv = cv2.cvtColor(img_org, cv2.COLOR_BGR2HSV)\n    ## Gen lower mask (0-5) and upper mask (175-180) of RED\n    #these set works well\n    mask1 = cv2.inRange(img_hsv, (0,50,50), (10,255,255))\n    mask2 = cv2.inRange(img_hsv, (170,50,50), (180,255,255))\n    # mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n    # mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "perspective_transformation",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def perspective_transformation(img): \n    #IMAGE_H = 223\n    IMAGE_H = 300\n    IMAGE_W = 1280\n    src = np.float32([[0, IMAGE_H], [1207, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n    #dst = np.float32([[543, IMAGE_H], [711, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n    dst = np.float32([[569, IMAGE_H], [711, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n    #dst = np.float32([[0, IMAGE_H], [1280, IMAGE_H], [0, 0], [1280, 0]])\n    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n    img = img[550:(550+IMAGE_H), 0:IMAGE_W] #crop the image",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "get_vetices",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def get_vetices():\n    new = np.array([[(0, 570), (496, 173), (596, 168), (1278, 400),(1280,960),(0,960)]], dtype=np.int32) #for testing vid01~05 except 02\n    new = np.array([[(117, 955), (496, 473), (596, 468), (1278, 800),(1280,960)]], dtype=np.int32) # testing testingvid-04-truck.avi\n    #new = np.array([[(150, 960), (451, 620), (855, 620), (1280, 810),(1280,960)]], dtype=np.int32)\n    return new\ndef draw_dis_lines(img):\n    img = np.zeros_like(img)\n    #for speed estimation\n    cv2.line(img,(50,614),(1260,614),(0,127,255),3)\n    cv2.line(img,(50,684),(1260,684),(0,127,255),3)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "draw_dis_lines",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def draw_dis_lines(img):\n    img = np.zeros_like(img)\n    #for speed estimation\n    cv2.line(img,(50,614),(1260,614),(0,127,255),3)\n    cv2.line(img,(50,684),(1260,684),(0,127,255),3)\n    #cv2.line(img,(680,614),(680,684),(0,0,255),3)\n    #for \n    cv2.line(img,(640,960),(575,545),(255,255,255),4)  #mid point 640 960\n    cv2.line(img,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n    cv2.line(img,(586,570),(500,570),(255,255,0),4)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "region_of_interest2",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def region_of_interest2(image, vertices):\n    # defining a blank mask to start with\n    mask = np.zeros_like(image)\n    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n    if len(image.shape) > 2:\n        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n        ignore_mask_color = (255,) * channel_count\n    else:\n        ignore_mask_color = 255\n    # filling pixels inside the polygon defined by \"vertices\" with the fill color",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "filterout",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def filterout(image,vertices_polly):\n    zero = np.zeros_like(image)\n    cl = (255,255,255)\n    cv2.fillPoly(zero, vertices_polly, cl)  #BGR\n    filtered_image = cv2.bitwise_and(image, zero)\n    #filtered_image = cv2.bitwise_and(image, mask)\n    return filtered_image\n#god\ndef filterout2(image,vertice,mask):\n    zero = np.zeros_like(image)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "filterout2",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def filterout2(image,vertice,mask):\n    zero = np.zeros_like(image)\n    cl = (255,255,255)\n    cv2.fillPoly(zero, vertice, cl)  #BGR\n    #filtered_image = cv2.bitwise_and(image, zero)\n    filtered_image = cv2.bitwise_and(image, zero)\n    return filtered_image\ndef average_slope_intercept (image, lines):\n    left = []\n    right =[]",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "average_slope_intercep",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def average_slope_intercept (image, lines):\n    left = []\n    right =[]\n    lane = []\n    for line in lines :\n        x1, y1, x2, y2 = line.reshape(4)\n        parameters = np.polyfit((x1,x2),(y1,y2),1)\n        #print(\"parameterssssssssssssss\",parameters)\n        try:\n            slope, intercept = parameters",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "make_coordinates",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def make_coordinates(image, line_parameters):\n    slope, intercept = line_parameters\n    y1 = image.shape[0]\n    y2 = int(y1*(3/5)) #0.6 little bit too short to show the whole profile of vehicle to track\n    #y2 = int(y1*(0.5))\n    #y2 = int(y1*(1/5))  #stretch the line ->very long\n    x1 = int((y1-intercept)/slope)\n    x2 = int((y2-intercept)/slope)\n    return np.array([x1, y1, x2, y2])\n#append left or right lane when missing one  default:missing right lane",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "make_coordinates_append",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def make_coordinates_append(image, line_parameters,left = False):\n    slope, intercept = line_parameters\n    y1 = image.shape[0]\n    y2 = int(y1*(3/5)) #0.6 little bit too short to show the whole profile of vehicle to track\n    #y2 = int(y1*(0.5))\n    #y2 = int(y1*(1/5))  #stretch the line ->very long\n    x1 = int((y1-intercept)/slope)\n    x2 = int((y2-intercept)/slope)\n    apd = np.array([x1+1100, y1, x2+140, y2])\n    return np.array([x1+1100, y1, x2+140, y2]) if left == False else np.array([x1-1100, y1, x2-140, y2])",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "canny",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def canny(frame):\n    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    #reduce noise using gaussian filter \n    blur=cv2.GaussianBlur(gray, (5,5) , 0) #apply 5*5 kernal\n    #Canny edge detection cv2.Canny(image , low_threshold , high_threshold), threshold: \n    canny = cv2.Canny(blur , 50 , 150)\n    return canny\n#for lines without averaging it    \ndef draw_lines1(image , lines):\n    line_image = np.zeros_like(image)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "draw_lines1",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def draw_lines1(image , lines):\n    line_image = np.zeros_like(image)\n    if lines is not None :\n        #print(\"linessssssssss\",lines)\n        for line in lines :\n            #print(\"#####\",line)\n            x1 , y1 , x2 , y2 = line.reshape(4)\n            cv2.line(line_image, (int(x1),int(y1)), (int(x2),int(y2)), (0,255,0), 10)\n    return line_image\ndef draw_lines2(image , lines):",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "draw_lines2",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def draw_lines2(image , lines):\n    line_image = np.zeros_like(image)\n    #print(lines,\"lines in drawwwwwww\")\n    if lines is not None :\n        try:\n            for x1 , y1 , x2 , y2 in lines :\n            #cv2.line(line_image, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0), 10)\n                #print(x1,y1,x2,y2,\"draw arg.............................\")\n                if x1 + y1 + x2 + y2 > 100000000 :\n                    print(\"the value of lines are tooooo big ( in draw_lines2()  )\")",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "lane_detection",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def lane_detection(frame):\n    vertices_polly = np.array([[(0, 0), (0, 0), (0, 0), (0, 0)]], dtype=np.int32)\n    yellow_white = select_yellow_white(frame)\n    cannyresult = canny(yellow_white)\n    #cannyresult = canny(frame)\n    #get the right vertice automatically\n    vertice = get_vetices(frame)\n    cropped_image , mask = region_of_interest2(cannyresult,vertice)\n    lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n    #print(\"lines\\n\",lines)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "framenum",
        "kind": 5,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "framenum = -1\ndef lane_detection(frame):\n    vertices_polly = np.array([[(0, 0), (0, 0), (0, 0), (0, 0)]], dtype=np.int32)\n    yellow_white = select_yellow_white(frame)\n    cannyresult = canny(yellow_white)\n    #cannyresult = canny(frame)\n    #get the right vertice automatically\n    vertice = get_vetices(frame)\n    cropped_image , mask = region_of_interest2(cannyresult,vertice)\n    lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "TrtSSD",
        "kind": 6,
        "importPath": "utils.ssd",
        "description": "utils.ssd",
        "peekOfCode": "class TrtSSD(object):\n    \"\"\"TrtSSD class encapsulates things needed to run TRT SSD.\"\"\"\n    def _load_plugins(self):\n        if trt.__version__[0] < '7':\n            ctypes.CDLL(\"ssd/libflattenconcat.so\")\n        trt.init_libnvinfer_plugins(self.trt_logger, '')\n    def _load_engine(self):\n        TRTbin = 'ssd/TRT_%s.bin' % self.model\n        with open(TRTbin, 'rb') as f, trt.Runtime(self.trt_logger) as runtime:\n            return runtime.deserialize_cuda_engine(f.read())",
        "detail": "utils.ssd",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "kind": 2,
        "importPath": "utils.ssd_classes",
        "description": "utils.ssd_classes",
        "peekOfCode": "def get_cls_dict(model):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if model == 'coco':\n        cls_list = COCO_CLASSES_LIST\n    elif model == 'egohands':\n        cls_list = EGOHANDS_CLASSES_LIST\n    else:\n        raise ValueError('Bad model name')\n    return {i: n for i, n in enumerate(cls_list)}",
        "detail": "utils.ssd_classes",
        "documentation": {}
    },
    {
        "label": "COCO_CLASSES_LIST",
        "kind": 5,
        "importPath": "utils.ssd_classes",
        "description": "utils.ssd_classes",
        "peekOfCode": "COCO_CLASSES_LIST = [\n    'background',  # was 'unlabeled'\n    'person',\n    'bicycle',\n    'car',\n    'motorcycle',\n    'airplane',\n    'bus',\n    'train',\n    'truck',",
        "detail": "utils.ssd_classes",
        "documentation": {}
    },
    {
        "label": "EGOHANDS_CLASSES_LIST",
        "kind": 5,
        "importPath": "utils.ssd_classes",
        "description": "utils.ssd_classes",
        "peekOfCode": "EGOHANDS_CLASSES_LIST = [\n    'background',\n    'hand',\n]\ndef get_cls_dict(model):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if model == 'coco':\n        cls_list = COCO_CLASSES_LIST\n    elif model == 'egohands':\n        cls_list = EGOHANDS_CLASSES_LIST",
        "detail": "utils.ssd_classes",
        "documentation": {}
    },
    {
        "label": "TfSSD",
        "kind": 6,
        "importPath": "utils.ssd_tf",
        "description": "utils.ssd_tf",
        "peekOfCode": "class TfSSD(object):\n    \"\"\"TfSSD class encapsulates things needed to run TensorFlow SSD.\"\"\"\n    def __init__(self, model, input_shape):\n        self.model = model\n        self.input_shape = input_shape\n        # load detection graph\n        ssd_graph = tf.Graph()\n        with ssd_graph.as_default():\n            graph_def = tf.GraphDef()\n            with tf.gfile.GFile('ssd/%s.pb' % model, 'rb') as fid:",
        "detail": "utils.ssd_tf",
        "documentation": {}
    },
    {
        "label": "BBoxVisualization",
        "kind": 6,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "class BBoxVisualization():\n    \"\"\"BBoxVisualization class implements nice drawing of boudning boxes.\n    # Arguments\n      cls_dict: a dictionary used to translate class id to its name.\n    \"\"\"\n    def __init__(self, cls_dict):\n        self.cls_dict = cls_dict\n        self.colors = gen_colors(len(cls_dict))\n    def draw_bboxes(self, img, boxes, confs, clss):\n        \"\"\"Draw detected bounding boxes on the original image.\"\"\"",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "gen_colors",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.\n    \"\"\"\n    import random\n    import colorsys",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "draw_boxed_text",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def draw_boxed_text(img, text, topleft, color):\n    \"\"\"Draw a transluent boxed text in white, overlayed on top of a\n    colored patch surrounded by a black border. FONT, TEXT_SCALE,\n    TEXT_THICKNESS and ALPHA values are constants (fixed) as defined\n    on top.\n    # Arguments\n      img: the input image as a numpy array.\n      text: the text to be drawn.\n      topleft: XY coordinate of the topleft corner of the boxed text.\n      color: color of the patch, i.e. background of the text.",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "ALPHA",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "ALPHA = 0.5\nFONT = cv2.FONT_HERSHEY_PLAIN\nTEXT_SCALE = 1.0\nTEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "FONT",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "FONT = cv2.FONT_HERSHEY_PLAIN\nTEXT_SCALE = 1.0\nTEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "TEXT_SCALE",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "TEXT_SCALE = 1.0\nTEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "TEXT_THICKNESS",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "TEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "BLACK",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "BLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.\n    \"\"\"",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "WHITE",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "WHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.\n    \"\"\"\n    import random",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "kind": 2,
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "peekOfCode": "def get_cls_dict(category_num):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if category_num == 80:\n        return {i: n for i, n in enumerate(COCO_CLASSES_LIST)}\n    else:\n        return {i: 'CLS%d' % i for i in range(category_num)}",
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "COCO_CLASSES_LIST",
        "kind": 5,
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "peekOfCode": "COCO_CLASSES_LIST = [\n    'person',\n    'bicycle',\n    'car',\n    'motorbike',\n    'aeroplane',\n    'bus',\n    'train',\n    'truck',\n    'boat',",
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "yolo_cls_to_ssd",
        "kind": 5,
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "peekOfCode": "yolo_cls_to_ssd = [\n   1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20,\n    21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n    41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n    59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79,\n    80, 81, 82, 84, 85, 86, 87, 88, 89, 90,\n]\ndef get_cls_dict(category_num):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if category_num == 80:",
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "kind": 6,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "class Tracker_tiny():\n    def __init__(self, cfg):\n        self.cfg = cfg\n        # self.args = args\n\t#\n        self.deepsort = build_tracker(cfg, use_cuda=True)\n        #\n\t#---tensorrt----#\n        # ---tensorrt----#\n        #---input info for yolov3-416------#",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "HostDeviceMem",
        "kind": 6,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "class HostDeviceMem(object):\n    \"\"\"Simple helper data class that's a little nicer to use than a 2-tuple.\"\"\"\n    def __init__(self, host_mem, device_mem):\n        self.host = host_mem\n        self.device = device_mem\n    def __str__(self):\n        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n    def __repr__(self):\n        return self.__str__()\ndef allocate_buffers(engine):",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "TrtYOLO",
        "kind": 6,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "class TrtYOLO(object):\n    \"\"\"TrtYOLO class encapsulates things needed to run TRT YOLO.\"\"\"\n    def _load_engine(self):\n        TRTbin = 'yolo/%s.trt' % self.model\n        with open(TRTbin, 'rb') as f, trt.Runtime(self.trt_logger) as runtime:\n            return runtime.deserialize_cuda_engine(f.read())\n    def __init__(self, model, input_shape, category_num=80, letter_box=False,\n                 cuda_ctx=None):\n        \"\"\"Initialize TensorRT plugins, engine and conetxt.\"\"\"\n        self.model = model",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "allocate_buffers",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def allocate_buffers(engine):\n    \"\"\"Allocates all host/device in/out buffers required for an engine.\"\"\"\n    inputs = []\n    outputs = []\n    bindings = []\n    output_idx = 0\n    stream = cuda.Stream()\n    assert 3 <= len(engine) <= 4  # expect 1 input, plus 2 or 3 outpus\n    for binding in engine:\n        size = trt.volume(engine.get_binding_shape(binding)) * \\",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "do_inference",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n    \"\"\"do_inference (for TensorRT 6.x or lower)\n    This function is generalized for multiple inputs/outputs.\n    Inputs and outputs are expected to be lists of HostDeviceMem objects.\n    \"\"\"\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n    # Run inference.\n    context.execute_async(batch_size=batch_size,\n                          bindings=bindings,",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "do_inference_v2",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def do_inference_v2(context, bindings, inputs, outputs, stream):\n    \"\"\"do_inference_v2 (for TensorRT 7.0+)\n    This function is generalized for multiple inputs/outputs for full\n    dimension networks.\n    Inputs and outputs are expected to be lists of HostDeviceMem objects.\n    \"\"\"\n    start = time.time()\n    print(\"=> time: %.4f\" %(time.time()-start))\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "get_yolo_grid_sizes",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def get_yolo_grid_sizes(model_name, h, w):\n    \"\"\"Get grid sizes (w*h) for all yolo layers in the model.\"\"\"\n    if 'yolov3' in model_name:\n        if 'tiny' in model_name:\n            return [(h // 32) * (w // 32), (h // 16) * (w // 16)]\n        else:\n            return [(h // 32) * (w // 32), (h // 16) * (w // 16), (h // 8) * (w // 8)]\n    elif 'yolov4' in model_name:\n        if 'tiny' in model_name:\n            return [(h // 32) * (w // 32), (h // 16) * (w // 16)]",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "_platform",
        "kind": 5,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "_platform = platform.system().lower()\nif _platform.startswith('windows'):\n    plugin_name = 'libyolo_layer.dll'\nelse:\n    plugin_name = 'libyolo_layer.so'\nplugin_path = os.path.join('plugins', plugin_name)\ntry:\n    ctypes.cdll.LoadLibrary(plugin_path)\nexcept OSError as e:\n    # Provide a clearer error message depending on platform",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "plugin_path",
        "kind": 5,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "plugin_path = os.path.join('plugins', plugin_name)\ntry:\n    ctypes.cdll.LoadLibrary(plugin_path)\nexcept OSError as e:\n    # Provide a clearer error message depending on platform\n    if _platform.startswith('windows'):\n        msg = (f\"ERROR: failed to load {plugin_path}.\\n\"\n               \"On Windows you need to build a TensorRT YOLO plugin DLL (e.g. libyolo_layer.dll) \"\n               \"compatible with your TensorRT version.\\n\"\n               \"Typical steps: install TensorRT, CUDA, Visual Studio Build Tools, then build the plugin with CMake/MSBuild.\\n\"",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "VideoWriter",
        "kind": 6,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "class VideoWriter:\n    def __init__(self, width, height, args, fps=24):\n        # type: (str, int, int, int) -> None\n        assert args.output_file.endswith('.mp4'), 'please specify the (.mp4) at the end '\n        # self._name = name\n        # self._height = height\n        # self._width = width\n        self.args = args\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        self.__writer = cv2.VideoWriter(args.output_file, fourcc, fps, (width, height))",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "Camera",
        "kind": 6,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "class Camera():\n    \"\"\"Camera class which supports reading images from theses video sources:\n    1. Video file\n    2. USB webcam\n    3. Jetson onboard camera\n    \"\"\"\n    def __init__(self, args):\n        self.args = args\n        self.is_opened = False\n        self.use_thread = False",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--file', dest='use_file',\n                        help='use a video file as input (remember to '\n                        'also set --filename)',\n                        action='store_true')\n    parser.add_argument('--image', dest='use_image',\n                        help='use an image file as input (remember to '\n                        'also set --filename)',\n                        action='store_true')",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "open_cam_usb",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def open_cam_usb(dev, width, height):\n    \"\"\"Open a USB webcam.\"\"\"\n    if USB_GSTREAMER:\n        gst_str = ('v4l2src device=/dev/video{} ! '\n                   'video/x-raw, width=(int){}, height=(int){} ! '\n                   'videoconvert ! appsink').format(dev, width, height)\n        return cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)\n    else:\n        return cv2.VideoCapture(dev)\ndef open_cam_onboard():",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "open_cam_onboard",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def open_cam_onboard():\n    \"\"\"Open the Jetson onboard camera.\"\"\"\n    gst_str = (\"nvarguscamerasrc ! \"\n        \"video/x-raw(memory:NVMM), \"\n        \"width=(int)1280, height=(int)720, \"\n        \"format=(string)NV12, framerate=(fraction)60/1 ! \"\n        \"nvvidconv flip-method=0 ! \"\n        \"video/x-raw, width=(int)1280, height=(int)720, format=(string)BGRx ! \"\n        \"videoconvert ! \"\n        \"video/x-raw, format=(string)BGR ! appsink\")",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "grab_img",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def grab_img(cam):\n    \"\"\"This 'grab_img' function is designed to be run in the sub-thread.\n    Once started, this thread continues to grab a new image and put it\n    into the global 'img_handle', until 'thread_running' is set to False.\n    \"\"\"\n    while cam.thread_running:\n        _, cam.img_handle = cam.cap.read()\n        if cam.img_handle is None:\n            logging.warning('grab_img(): cap.read() returns None...')\n            break",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "USB_GSTREAMER",
        "kind": 5,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "USB_GSTREAMER = True\ndef add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--file', dest='use_file',\n                        help='use a video file as input (remember to '\n                        'also set --filename)',\n                        action='store_true')\n    parser.add_argument('--image', dest='use_image',\n                        help='use an image file as input (remember to '\n                        'also set --filename)',",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "HostDeviceMem",
        "kind": 6,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "class HostDeviceMem(object):\n    def __init__(self, host_mem, device_mem):\n        self.host = host_mem\n        self.device = device_mem\n    def __str__(self):\n        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n    def __repr__(self):\n        return self.__str__()\n# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\ndef allocate_buffers(engine):",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "GiB",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def GiB(val):\n    return val * 1 << 30\ndef find_sample_data(description=\"Runs a TensorRT Python sample\", subfolder=\"\", find_files=[]):\n    '''\n    Parses sample arguments.\n    Args:\n        description (str): Description of the sample.\n        subfolder (str): The subfolder containing data relevant to this sample\n        find_files (str): A list of filenames to find. Each filename will be replaced with an absolute path.\n    Returns:",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "find_sample_data",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def find_sample_data(description=\"Runs a TensorRT Python sample\", subfolder=\"\", find_files=[]):\n    '''\n    Parses sample arguments.\n    Args:\n        description (str): Description of the sample.\n        subfolder (str): The subfolder containing data relevant to this sample\n        find_files (str): A list of filenames to find. Each filename will be replaced with an absolute path.\n    Returns:\n        str: Path of data directory.\n    Raises:",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "allocate_buffers",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def allocate_buffers(engine):\n    inputs = []\n    outputs = []\n    bindings = []\n    stream = cuda.Stream()\n    for binding in engine:\n        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n        dtype = trt.nptype(engine.get_binding_dtype(binding))\n        # Allocate host and device buffers\n        host_mem = cuda.pagelocked_empty(size, dtype)",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "do_inference",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n     start = time.time()\n     print(\"=> time: %.4f\" %(time.time()-start))\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n    # Run inference.\n    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n    # Transfer predictions back from the GPU.\n    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n    # Synchronize the stream",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "PreprocessYOLO",
        "kind": 6,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "class PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):\n        \"\"\"Initialize with the input resolution for YOLOv3, which will stay fixed in this sample.\n        Keyword arguments:\n        yolo_input_resolution -- two-dimensional tuple with the target network's (spatial)\n        input resolution in HW order\n        \"\"\"",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "PostprocessYOLO",
        "kind": 6,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "class PostprocessYOLO(object):\n    \"\"\"Class for post-processing the three outputs tensors from YOLOv3-608.\"\"\"\n    def __init__(self,\n                 yolo_masks,\n                 yolo_anchors,\n                 obj_threshold,\n                 nms_threshold,\n                 yolo_input_resolution):\n        \"\"\"Initialize with all values that will be kept when processing several frames.\n        Assuming 3 outputs of the network in the case of (large) YOLOv3.",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "load_label_categories",
        "kind": 2,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "def load_label_categories(label_file_path):\n    categories = [line.rstrip('\\n') for line in open(label_file_path)]\n    return categories\nLABEL_FILE_PATH = './configs/coco_labels.txt'\nALL_CATEGORIES = load_label_categories(LABEL_FILE_PATH)\n# Let's make sure that there are 80 classes, as expected for the COCO data set:\nCATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "LABEL_FILE_PATH",
        "kind": 5,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "LABEL_FILE_PATH = './configs/coco_labels.txt'\nALL_CATEGORIES = load_label_categories(LABEL_FILE_PATH)\n# Let's make sure that there are 80 classes, as expected for the COCO data set:\nCATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "ALL_CATEGORIES",
        "kind": 5,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "ALL_CATEGORIES = load_label_categories(LABEL_FILE_PATH)\n# Let's make sure that there are 80 classes, as expected for the COCO data set:\nCATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):\n        \"\"\"Initialize with the input resolution for YOLOv3, which will stay fixed in this sample.",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "CATEGORY_NUM",
        "kind": 5,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "CATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):\n        \"\"\"Initialize with the input resolution for YOLOv3, which will stay fixed in this sample.\n        Keyword arguments:\n        yolo_input_resolution -- two-dimensional tuple with the target network's (spatial)",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "compute_color_for_labels",
        "kind": 2,
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "peekOfCode": "def compute_color_for_labels(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the class\n    \"\"\"\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\ndef draw_boxes(img, bbox, identities=None, offset=(0,0)):\n    for i,box in enumerate(bbox):\n        x1,y1,x2,y2 = [int(i) for i in box]\n        x1 += offset[0]",
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "kind": 2,
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "peekOfCode": "def draw_boxes(img, bbox, identities=None, offset=(0,0)):\n    for i,box in enumerate(bbox):\n        x1,y1,x2,y2 = [int(i) for i in box]\n        x1 += offset[0]\n        x2 += offset[0]\n        y1 += offset[1]\n        y2 += offset[1]\n        # box text and bar\n        id = int(identities[i]) if identities is not None else 0    \n        color = compute_color_for_labels(id)",
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "palette",
        "kind": 5,
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "peekOfCode": "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\ndef compute_color_for_labels(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the class\n    \"\"\"\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\ndef draw_boxes(img, bbox, identities=None, offset=(0,0)):\n    for i,box in enumerate(bbox):\n        x1,y1,x2,y2 = [int(i) for i in box]",
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "YamlParser",
        "kind": 6,
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "peekOfCode": "class YamlParser(edict):\n    \"\"\"\n    This is yaml parser based on EasyDict.\n    \"\"\"\n    def __init__(self, cfg_dict=None, config_file=None):\n        if cfg_dict is None:\n            cfg_dict = {}\n        if config_file is not None:\n            assert(os.path.isfile(config_file))\n            with open(config_file, 'r') as fo:",
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "get_config",
        "kind": 2,
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "peekOfCode": "def get_config(config_file=None):\n    return YamlParser(config_file=config_file)\nif __name__ == \"__main__\":\n    # cfg = YamlParser(config_file=\"../configs/yolov3.yaml\")\n    cfg.merge_from_file(\"../configs/deep_sort.yaml\")\n    import ipdb; ipdb.set_trace()",
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "OpenCVYolo",
        "kind": 6,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "class OpenCVYolo:\n\t\"\"\"Simple OpenCV DNN wrapper for YOLO Darknet models.\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the TensorRT TrtYOLO.detect used by this repo.\n\t\"\"\"\n\tdef __init__(self, cfg_path, weights_path, input_shape=(416,416)):\n\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n\t\tself.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "PyTorchYolo",
        "kind": 6,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "class PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the other detectors.\n\t\"\"\"\n\tdef __init__(self, model_path, device='auto'):\n\t\tif device == 'auto':\n\t\t\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\t\tself.model = YOLO(model_path)\n\t\tself.device = device",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "append_speed",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def append_speed(ids,deque_list):\n\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n#fix bbox issues",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "compute_xc_yc",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def compute_xc_yc(out):\n\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "dra",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  \n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "ez_show",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  \n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "Distance_finder",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "motion_cord",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\ndef trajectory_extrapolation(outputs, img_shape, safety_zone):\n\t\"\"\"Extrapolate trajectories and check for future hazards.\"\"\"\n\talert = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "trajectory_extrapolation",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def trajectory_extrapolation(outputs, img_shape, safety_zone):\n\t\"\"\"Extrapolate trajectories and check for future hazards.\"\"\"\n\talert = False\n\tfor x1, y1, x2, y2, ids in outputs:\n\t\t# Simple extrapolation: assume constant velocity from recent positions\n\t\t# For demo, predict 2 seconds ahead (assuming 20 FPS, 40 frames)\n\t\tpred_x = x1 + (x2 - x1) * 2  # rough velocity\n\t\tpred_y = y1 + (y2 - y1) * 2\n\t\t# Check if predicted position is in safety zone (simplified)\n\t\tif pred_y > img_shape[0] * 0.8:  # bottom 20% as safety",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "enhanced_ttc_forecasting",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def enhanced_ttc_forecasting(dis, speed, threshold=2.0):\n\t\"\"\"Forecast TTC and alert if predicted < threshold seconds.\"\"\"\n\tif speed > 0:\n\t\tttc = dis / (speed * 1000 / 3600)  # convert to seconds\n\t\tif ttc < threshold:\n\t\t\treturn True\n\treturn False\ndef optical_flow_analysis(prev_gray, gray, bbox):\n\t\"\"\"Compute optical flow for motion vectors.\"\"\"\n\tflow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "optical_flow_analysis",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def optical_flow_analysis(prev_gray, gray, bbox):\n\t\"\"\"Compute optical flow for motion vectors.\"\"\"\n\tflow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n\t# Average flow in bbox\n\tx1, y1, x2, y2 = bbox\n\tmean_flow = np.mean(flow[y1:y2, x1:x2], axis=(0,1))\n\tmagnitude = np.linalg.norm(mean_flow)\n\tdirection = np.arctan2(mean_flow[1], mean_flow[0])  # towards camera if positive y\n\treturn magnitude > 1.0 and direction > 0  # simple threshold\ndef proactive_alert_thresholds(dis, speed, in_lane, motion_predict):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "proactive_alert_thresholds",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def proactive_alert_thresholds(dis, speed, in_lane, motion_predict):\n\t\"\"\"Adjust thresholds based on context.\"\"\"\n\tif in_lane and motion_predict:\n\t\tdanger_dist = 6.0  # lower threshold\n\t\tunsafe_dist = 12.0\n\telse:\n\t\tdanger_dist = 4.0\n\t\tunsafe_dist = 8.0\n\treturn dis <= danger_dist or (dis <= unsafe_dist and speed > 10)\ndef loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "loop_and_detect",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).\n\t\ttrt_yolo: the TRT YOLO object detector instance.\n\t\tconf_th: confidence/score threshold for object detection.\n\t\tvis: for visualization.\n\t\"\"\"\n\t# global img_final\n\tfull_scrn = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "def main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv and not args.use_pytorch:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "WINDOW_NAME",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "WINDOW_NAME = 'ProjectDemo'\nclass OpenCVYolo:\n\t\"\"\"Simple OpenCV DNN wrapper for YOLO Darknet models.\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the TensorRT TrtYOLO.detect used by this repo.\n\t\"\"\"\n\tdef __init__(self, cfg_path, weights_path, input_shape=(416,416)):\n\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tself.net",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n\t\tself.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n\t\tself.input_shape = input_shape\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\th, w = img.shape[:2]\n\t\tinp_w, inp_h = self.input_shape[1], self.input_shape[0]\n\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tself.input_shape",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tself.input_shape = input_shape\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\th, w = img.shape[:2]\n\t\tinp_w, inp_h = self.input_shape[1], self.input_shape[0]\n\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)\n\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tblob",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)\n\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tlayer_names",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tout_names",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\touts",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tclass_ids",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tconfidences",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tscores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tclass_id",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tconfidence",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcenter_x",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcenter_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tbw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tbh",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ty1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ty2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tidxs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_boxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_scores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_classes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tidxs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tidxs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tidxs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\ti",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\nclass PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\nclass PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\nclass PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the other detectors.",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\nclass PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the other detectors.\n\t\"\"\"\n\tdef __init__(self, model_path, device='auto'):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\nclass PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the other detectors.\n\t\"\"\"\n\tdef __init__(self, model_path, device='auto'):\n\t\tif device == 'auto':",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\nclass PyTorchYolo:\n\t\"\"\"PyTorch YOLO wrapper for .pt models (YOLOv5/v8 via ultralytics).\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the other detectors.\n\t\"\"\"\n\tdef __init__(self, model_path, device='auto'):\n\t\tif device == 'auto':\n\t\t\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tdevice",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\t\tself.model = YOLO(model_path)\n\t\tself.device = device\n\t\tself.model.to(self.device)\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\t# Inference with ultralytics\n\t\tresults = self.model(img, conf=conf_th, verbose=False)\n\t\t# Parse YOLOv8 results\n\t\tdetections = results[0].boxes.data.cpu().numpy()  # [x1,y1,x2,y2,conf,cls]\n\t\tboxes = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tself.model",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tself.model = YOLO(model_path)\n\t\tself.device = device\n\t\tself.model.to(self.device)\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\t# Inference with ultralytics\n\t\tresults = self.model(img, conf=conf_th, verbose=False)\n\t\t# Parse YOLOv8 results\n\t\tdetections = results[0].boxes.data.cpu().numpy()  # [x1,y1,x2,y2,conf,cls]\n\t\tboxes = []\n\t\tscores = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tself.device",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tself.device = device\n\t\tself.model.to(self.device)\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\t# Inference with ultralytics\n\t\tresults = self.model(img, conf=conf_th, verbose=False)\n\t\t# Parse YOLOv8 results\n\t\tdetections = results[0].boxes.data.cpu().numpy()  # [x1,y1,x2,y2,conf,cls]\n\t\tboxes = []\n\t\tscores = []\n\t\tclasses = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tresults",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tresults = self.model(img, conf=conf_th, verbose=False)\n\t\t# Parse YOLOv8 results\n\t\tdetections = results[0].boxes.data.cpu().numpy()  # [x1,y1,x2,y2,conf,cls]\n\t\tboxes = []\n\t\tscores = []\n\t\tclasses = []\n\t\tfor det in detections:\n\t\t\tif len(det) >= 6:\n\t\t\t\tx1, y1, x2, y2, conf, cls = det\n\t\t\t\tboxes.append([int(x1), int(y1), int(x2), int(y2)])",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tdetections",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tdetections = results[0].boxes.data.cpu().numpy()  # [x1,y1,x2,y2,conf,cls]\n\t\tboxes = []\n\t\tscores = []\n\t\tclasses = []\n\t\tfor det in detections:\n\t\t\tif len(det) >= 6:\n\t\t\t\tx1, y1, x2, y2, conf, cls = det\n\t\t\t\tboxes.append([int(x1), int(y1), int(x2), int(y2)])\n\t\t\t\tscores.append(float(conf))\n\t\t\t\tclasses.append(int(cls))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tboxes = []\n\t\tscores = []\n\t\tclasses = []\n\t\tfor det in detections:\n\t\t\tif len(det) >= 6:\n\t\t\t\tx1, y1, x2, y2, conf, cls = det\n\t\t\t\tboxes.append([int(x1), int(y1), int(x2), int(y2)])\n\t\t\t\tscores.append(float(conf))\n\t\t\t\tclasses.append(int(cls))\n\t\tif len(boxes) > 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tscores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tscores = []\n\t\tclasses = []\n\t\tfor det in detections:\n\t\t\tif len(det) >= 6:\n\t\t\t\tx1, y1, x2, y2, conf, cls = det\n\t\t\t\tboxes.append([int(x1), int(y1), int(x2), int(y2)])\n\t\t\t\tscores.append(float(conf))\n\t\t\t\tclasses.append(int(cls))\n\t\tif len(boxes) > 0:\n\t\t\tboxes = np.array(boxes, dtype=np.int32)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tclasses",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tclasses = []\n\t\tfor det in detections:\n\t\t\tif len(det) >= 6:\n\t\t\t\tx1, y1, x2, y2, conf, cls = det\n\t\t\t\tboxes.append([int(x1), int(y1), int(x2), int(y2)])\n\t\t\t\tscores.append(float(conf))\n\t\t\t\tclasses.append(int(cls))\n\t\tif len(boxes) > 0:\n\t\t\tboxes = np.array(boxes, dtype=np.int32)\n\t\t\tscores = np.array(scores, dtype=np.float32)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tboxes = np.array(boxes, dtype=np.int32)\n\t\t\tscores = np.array(scores, dtype=np.float32)\n\t\t\tclasses = np.array(classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tscores = np.array(scores, dtype=np.float32)\n\t\t\tclasses = np.array(classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tclasses = np.array(classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdesc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=False,",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=False,\n\t\t\thelp=('[yolov3|yolov3-tiny|yolov3-spp|yolov4|yolov4-tiny]-'\n\t\t\t\t\t\t'[{dimension}], where dimension could be a single '\n\t\t\t\t\t\t'number (e.g. 288, 416, 608) or WxH (e.g. 416x256)'))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=False,\n\t\t\thelp=('[yolov3|yolov3-tiny|yolov3-spp|yolov4|yolov4-tiny]-'\n\t\t\t\t\t\t'[{dimension}], where dimension could be a single '\n\t\t\t\t\t\t'number (e.g. 288, 416, 608) or WxH (e.g. 416x256)'))\n\tparser.add_argument(",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\targs = parser.parse_args()\n\treturn args\ndef append_speed(ids,deque_list):\n\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tspeed_list",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n#fix bbox issues\ndef compute_xc_yc(out):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tspd_avg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n#fix bbox issues\ndef compute_xc_yc(out):\n\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\th",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\txmin",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tymin",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\txc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tyc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  \n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\timg0",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  \n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tpol",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tFocal_Length",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdistance",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\ndef trajectory_extrapolation(outputs, img_shape, safety_zone):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\ty2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\ndef trajectory_extrapolation(outputs, img_shape, safety_zone):\n\t\"\"\"Extrapolate trajectories and check for future hazards.\"\"\"\n\talert = False\n\tfor x1, y1, x2, y2, ids in outputs:\n\t\t# Simple extrapolation: assume constant velocity from recent positions\n\t\t# For demo, predict 2 seconds ahead (assuming 20 FPS, 40 frames)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#y2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\ndef trajectory_extrapolation(outputs, img_shape, safety_zone):\n\t\"\"\"Extrapolate trajectories and check for future hazards.\"\"\"\n\talert = False\n\tfor x1, y1, x2, y2, ids in outputs:\n\t\t# Simple extrapolation: assume constant velocity from recent positions\n\t\t# For demo, predict 2 seconds ahead (assuming 20 FPS, 40 frames)\n\t\tpred_x = x1 + (x2 - x1) * 2  # rough velocity",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tx2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\ndef trajectory_extrapolation(outputs, img_shape, safety_zone):\n\t\"\"\"Extrapolate trajectories and check for future hazards.\"\"\"\n\talert = False\n\tfor x1, y1, x2, y2, ids in outputs:\n\t\t# Simple extrapolation: assume constant velocity from recent positions\n\t\t# For demo, predict 2 seconds ahead (assuming 20 FPS, 40 frames)\n\t\tpred_x = x1 + (x2 - x1) * 2  # rough velocity\n\t\tpred_y = y1 + (y2 - y1) * 2",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\talert",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\talert = False\n\tfor x1, y1, x2, y2, ids in outputs:\n\t\t# Simple extrapolation: assume constant velocity from recent positions\n\t\t# For demo, predict 2 seconds ahead (assuming 20 FPS, 40 frames)\n\t\tpred_x = x1 + (x2 - x1) * 2  # rough velocity\n\t\tpred_y = y1 + (y2 - y1) * 2\n\t\t# Check if predicted position is in safety zone (simplified)\n\t\tif pred_y > img_shape[0] * 0.8:  # bottom 20% as safety\n\t\t\talert = True\n\t\t\tbreak",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tpred_x",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tpred_x = x1 + (x2 - x1) * 2  # rough velocity\n\t\tpred_y = y1 + (y2 - y1) * 2\n\t\t# Check if predicted position is in safety zone (simplified)\n\t\tif pred_y > img_shape[0] * 0.8:  # bottom 20% as safety\n\t\t\talert = True\n\t\t\tbreak\n\treturn alert\ndef enhanced_ttc_forecasting(dis, speed, threshold=2.0):\n\t\"\"\"Forecast TTC and alert if predicted < threshold seconds.\"\"\"\n\tif speed > 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tpred_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tpred_y = y1 + (y2 - y1) * 2\n\t\t# Check if predicted position is in safety zone (simplified)\n\t\tif pred_y > img_shape[0] * 0.8:  # bottom 20% as safety\n\t\t\talert = True\n\t\t\tbreak\n\treturn alert\ndef enhanced_ttc_forecasting(dis, speed, threshold=2.0):\n\t\"\"\"Forecast TTC and alert if predicted < threshold seconds.\"\"\"\n\tif speed > 0:\n\t\tttc = dis / (speed * 1000 / 3600)  # convert to seconds",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\talert",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\talert = True\n\t\t\tbreak\n\treturn alert\ndef enhanced_ttc_forecasting(dis, speed, threshold=2.0):\n\t\"\"\"Forecast TTC and alert if predicted < threshold seconds.\"\"\"\n\tif speed > 0:\n\t\tttc = dis / (speed * 1000 / 3600)  # convert to seconds\n\t\tif ttc < threshold:\n\t\t\treturn True\n\treturn False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tttc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tttc = dis / (speed * 1000 / 3600)  # convert to seconds\n\t\tif ttc < threshold:\n\t\t\treturn True\n\treturn False\ndef optical_flow_analysis(prev_gray, gray, bbox):\n\t\"\"\"Compute optical flow for motion vectors.\"\"\"\n\tflow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n\t# Average flow in bbox\n\tx1, y1, x2, y2 = bbox\n\tmean_flow = np.mean(flow[y1:y2, x1:x2], axis=(0,1))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tflow",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tflow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n\t# Average flow in bbox\n\tx1, y1, x2, y2 = bbox\n\tmean_flow = np.mean(flow[y1:y2, x1:x2], axis=(0,1))\n\tmagnitude = np.linalg.norm(mean_flow)\n\tdirection = np.arctan2(mean_flow[1], mean_flow[0])  # towards camera if positive y\n\treturn magnitude > 1.0 and direction > 0  # simple threshold\ndef proactive_alert_thresholds(dis, speed, in_lane, motion_predict):\n\t\"\"\"Adjust thresholds based on context.\"\"\"\n\tif in_lane and motion_predict:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tmean_flow",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tmean_flow = np.mean(flow[y1:y2, x1:x2], axis=(0,1))\n\tmagnitude = np.linalg.norm(mean_flow)\n\tdirection = np.arctan2(mean_flow[1], mean_flow[0])  # towards camera if positive y\n\treturn magnitude > 1.0 and direction > 0  # simple threshold\ndef proactive_alert_thresholds(dis, speed, in_lane, motion_predict):\n\t\"\"\"Adjust thresholds based on context.\"\"\"\n\tif in_lane and motion_predict:\n\t\tdanger_dist = 6.0  # lower threshold\n\t\tunsafe_dist = 12.0\n\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tmagnitude",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tmagnitude = np.linalg.norm(mean_flow)\n\tdirection = np.arctan2(mean_flow[1], mean_flow[0])  # towards camera if positive y\n\treturn magnitude > 1.0 and direction > 0  # simple threshold\ndef proactive_alert_thresholds(dis, speed, in_lane, motion_predict):\n\t\"\"\"Adjust thresholds based on context.\"\"\"\n\tif in_lane and motion_predict:\n\t\tdanger_dist = 6.0  # lower threshold\n\t\tunsafe_dist = 12.0\n\telse:\n\t\tdanger_dist = 4.0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdirection",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdirection = np.arctan2(mean_flow[1], mean_flow[0])  # towards camera if positive y\n\treturn magnitude > 1.0 and direction > 0  # simple threshold\ndef proactive_alert_thresholds(dis, speed, in_lane, motion_predict):\n\t\"\"\"Adjust thresholds based on context.\"\"\"\n\tif in_lane and motion_predict:\n\t\tdanger_dist = 6.0  # lower threshold\n\t\tunsafe_dist = 12.0\n\telse:\n\t\tdanger_dist = 4.0\n\t\tunsafe_dist = 8.0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tdanger_dist",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tdanger_dist = 6.0  # lower threshold\n\t\tunsafe_dist = 12.0\n\telse:\n\t\tdanger_dist = 4.0\n\t\tunsafe_dist = 8.0\n\treturn dis <= danger_dist or (dis <= unsafe_dist and speed > 10)\ndef loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tunsafe_dist",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tunsafe_dist = 12.0\n\telse:\n\t\tdanger_dist = 4.0\n\t\tunsafe_dist = 8.0\n\treturn dis <= danger_dist or (dis <= unsafe_dist and speed > 10)\ndef loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).\n\t\ttrt_yolo: the TRT YOLO object detector instance.",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tdanger_dist",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tdanger_dist = 4.0\n\t\tunsafe_dist = 8.0\n\treturn dis <= danger_dist or (dis <= unsafe_dist and speed > 10)\ndef loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).\n\t\ttrt_yolo: the TRT YOLO object detector instance.\n\t\tconf_th: confidence/score threshold for object detection.\n\t\tvis: for visualization.",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tunsafe_dist",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tunsafe_dist = 8.0\n\treturn dis <= danger_dist or (dis <= unsafe_dist and speed > 10)\ndef loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).\n\t\ttrt_yolo: the TRT YOLO object detector instance.\n\t\tconf_th: confidence/score threshold for object detection.\n\t\tvis: for visualization.\n\t\"\"\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tfull_scrn",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tfull_scrn = False\n\tfps = 0.0\n\ttic = time.time()\n\tstart_time = time.time()  # For total processing time\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tfps",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tfps = 0.0\n\ttic = time.time()\n\tstart_time = time.time()  # For total processing time\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\ttic",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\ttic = time.time()\n\tstart_time = time.time()  # For total processing time\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tstart_time",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tstart_time = time.time()  # For total processing time\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tf",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tm",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tn",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tcls",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tframenumber",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tspeed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tk",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#tic",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\ttime_start",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdis_start",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tpts",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tpt",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#h_ls",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tw_list",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tcar_spd",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tmoto_spd",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\thistory",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\thistory = {}  # for drawing trajectory paths\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tused",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tprev_status",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tprev_status = None\n\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tlanedetection",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tlanedetection = not args.disable_lane_detection  # Disable for speedup if flagged\n\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tputtext_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tputtext_deer = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tputtext_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tbad",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tmotion_predict",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdrw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tavg_spd_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tavg_spd_moto = \"still appending\"\n\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):\n\t\tos.makedirs('output')",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tavg_spd_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tavg_spd_deer = \"still appending\"\n\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):\n\t\tos.makedirs('output')\n\texisting_runs = [d for d in os.listdir('output') if d.startswith('run_') and os.path.isdir(os.path.join('output', d))]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tdeer_speed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tdeer_speed = 0\n\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):\n\t\tos.makedirs('output')\n\texisting_runs = [d for d in os.listdir('output') if d.startswith('run_') and os.path.isdir(os.path.join('output', d))]\n\tif existing_runs:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tx_dir",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tx_dir = []\n\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):\n\t\tos.makedirs('output')\n\texisting_runs = [d for d in os.listdir('output') if d.startswith('run_') and os.path.isdir(os.path.join('output', d))]\n\tif existing_runs:\n\t\trun_nums = [int(d.split('_')[1]) for d in existing_runs if d.split('_')[1].isdigit()]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\ty_dir",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\ty_dir = []\n\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):\n\t\tos.makedirs('output')\n\texisting_runs = [d for d in os.listdir('output') if d.startswith('run_') and os.path.isdir(os.path.join('output', d))]\n\tif existing_runs:\n\t\trun_nums = [int(d.split('_')[1]) for d in existing_runs if d.split('_')[1].isdigit()]\n\t\tnext_num = max(run_nums) + 1 if run_nums else 1",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tprev_gray",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tprev_gray = None  # For optical flow\n\t# Create incremental output folder\n\timport os\n\tif not os.path.exists('output'):\n\t\tos.makedirs('output')\n\texisting_runs = [d for d in os.listdir('output') if d.startswith('run_') and os.path.isdir(os.path.join('output', d))]\n\tif existing_runs:\n\t\trun_nums = [int(d.split('_')[1]) for d in existing_runs if d.split('_')[1].isdigit()]\n\t\tnext_num = max(run_nums) + 1 if run_nums else 1\n\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\texisting_runs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\texisting_runs = [d for d in os.listdir('output') if d.startswith('run_') and os.path.isdir(os.path.join('output', d))]\n\tif existing_runs:\n\t\trun_nums = [int(d.split('_')[1]) for d in existing_runs if d.split('_')[1].isdigit()]\n\t\tnext_num = max(run_nums) + 1 if run_nums else 1\n\telse:\n\t\tnext_num = 1\n\toutput_dir = f'output/run_{next_num:03d}'\n\tos.makedirs(output_dir)\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\trun_nums",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\trun_nums = [int(d.split('_')[1]) for d in existing_runs if d.split('_')[1].isdigit()]\n\t\tnext_num = max(run_nums) + 1 if run_nums else 1\n\telse:\n\t\tnext_num = 1\n\toutput_dir = f'output/run_{next_num:03d}'\n\tos.makedirs(output_dir)\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tnext_num",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tnext_num = max(run_nums) + 1 if run_nums else 1\n\telse:\n\t\tnext_num = 1\n\toutput_dir = f'output/run_{next_num:03d}'\n\tos.makedirs(output_dir)\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tnext_num",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tnext_num = 1\n\toutput_dir = f'output/run_{next_num:03d}'\n\tos.makedirs(output_dir)\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\toutput_dir",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\toutput_dir = f'output/run_{next_num:03d}'\n\tos.makedirs(output_dir)\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#width",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#height",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#size",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tfourcc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MPEG-4 codec\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#out",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\tif framenumber % args.skip_frames != 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#out2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\tif framenumber % args.skip_frames != 0:\n\t\t\tcontinue  # Skip this frame for speedup",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tout",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tout = cv2.VideoWriter(os.path.join(output_dir, 'line_vis.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\tif framenumber % args.skip_frames != 0:\n\t\t\tcontinue  # Skip this frame for speedup\n\t\t#mylcd = I2C_LCD_driver.lcd()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tout1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tout1 = cv2.VideoWriter(os.path.join(output_dir, 'final_res.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\tif framenumber % args.skip_frames != 0:\n\t\t\tcontinue  # Skip this frame for speedup\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tout2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tout2 = cv2.VideoWriter(os.path.join(output_dir, 'combo.mp4'), fourcc, 20.0, (args.input_width, args.input_height))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\tif framenumber % args.skip_frames != 0:\n\t\t\tcontinue  # Skip this frame for speedup\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t#out1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\tif framenumber % args.skip_frames != 0:\n\t\t\tcontinue  # Skip this frame for speedup\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#mylcd",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak\n\t\timg = cv2.resize(img, (args.input_width, args.input_height))\n\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # For optical flow\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak\n\t\timg = cv2.resize(img, (args.input_width, args.input_height))\n\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # For optical flow\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg = cv2.resize(img, (args.input_width, args.input_height))\n\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # For optical flow\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tgray",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # For optical flow\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\ttim",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tpol",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\toriginal_image",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#input_cropped",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tadd_trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#add_trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#yellow_white",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#cannyresult",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#frame_for_dis",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tcannyresult",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#fix road disappear issue ->works well",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tvertice",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tlines",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tlines",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t#avg_lines",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tleft_avg_lines",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2\n\t\t\telif left == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2\n\t\t\telif right == True:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tright_avg_lines",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2\n\t\t\telif left == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2\n\t\t\telif right == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#vertices_polly",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t#vertices_polly = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32)\n\t\t\t\tif xr1 - xl1 < 900:\n\t\t\t\t\txr1 = xl1 + 1100\n\t\t\t\tif (xr2+5)-(xl2-5) < 130:\n\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\txr1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\txr1 = xl1 + 1100\n\t\t\t\tif (xr2+5)-(xl2-5) < 130:\n\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\t# lane variables missing; continue without lane extension\n\t\t\t\tpass",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\txl2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\t# lane variables missing; continue without lane extension\n\t\t\t\tpass\n\t\telse:\n\t\t\t# fallback lane geometry when detection fails",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tvertices_polly",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\t# lane variables missing; continue without lane extension\n\t\t\t\tpass\n\t\telse:\n\t\t\t# fallback lane geometry when detection fails\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n\t\t                         [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tvertices_polly_unextd",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\t# lane variables missing; continue without lane extension\n\t\t\t\tpass\n\t\telse:\n\t\t\t# fallback lane geometry when detection fails\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n\t\t                         [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tavg_lane",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n\t\t                         [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tvertices_polly",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg_zero",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tcolor_polly",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tline_image_not_avg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t# vertices polygon used for masking",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tline_image",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t# vertices polygon used for masking\n\t\t\tif lanedetection == True:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tline_visualize",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t# vertices polygon used for masking\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#line_visualize",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t# vertices polygon used for masking\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tgod",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tgod = filterout2(img,vertice,mask)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t# vertices polygon used for masking\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t# vertices polygon used for masking\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#img",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\t# vertices not defined; using unfiltered image\n\t\t\tpass\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#img",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\t# vertices not defined; using unfiltered image\n\t\t\tpass\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t#god",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\t# vertices not defined; using unfiltered image\n\t\t\tpass\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t# combo image and non-averaged overlays",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t#filtered",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\t# vertices not defined; using unfiltered image\n\t\t\tpass\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t# combo image and non-averaged overlays\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered = god\n\t\t\t# vertices not defined; using unfiltered image\n\t\t\tpass\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t# combo image and non-averaged overlays\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tnormal_result",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t# combo image and non-averaged overlays\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tpass  # Banner will show SAFE\n\t\t\t#img0 = np.zeros_like(img_better_look)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tcombo_image",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t# combo image and non-averaged overlays\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tpass  # Banner will show SAFE\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg_notavg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tpass  # Banner will show SAFE\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tim0",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tpass  # Banner will show SAFE\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img0",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''\n\t\tyolov4 + Tensorrt\n\t\t'''\n\t\t# boxes, confs, clss = detector.detect(img, conf_th) ## for region",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''\n\t\tyolov4 + Tensorrt\n\t\t'''\n\t\t# boxes, confs, clss = detector.detect(img, conf_th) ## for region\n\t\tboxes, confs, clss = detector.detect(original_image, conf_th)\n\t\t# Apply additional NMS to avoid duplicate bounding boxes",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tidxs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tidxs = cv2.dnn.NMSBoxes(boxes.tolist(), confs.tolist(), 0.55, 0.4)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_confs = []\n\t\t\tfiltered_clss = []\n\t\t\tfor i in idxs.flatten():\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_confs.append(confs[i])\n\t\t\t\tfiltered_clss.append(clss[i])\n\t\t\tboxes = np.array(filtered_boxes)\n\t\t\tconfs = np.array(filtered_confs)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_boxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered_boxes = []\n\t\t\tfiltered_confs = []\n\t\t\tfiltered_clss = []\n\t\t\tfor i in idxs.flatten():\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_confs.append(confs[i])\n\t\t\t\tfiltered_clss.append(clss[i])\n\t\t\tboxes = np.array(filtered_boxes)\n\t\t\tconfs = np.array(filtered_confs)\n\t\t\tclss = np.array(filtered_clss)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_confs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered_confs = []\n\t\t\tfiltered_clss = []\n\t\t\tfor i in idxs.flatten():\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_confs.append(confs[i])\n\t\t\t\tfiltered_clss.append(clss[i])\n\t\t\tboxes = np.array(filtered_boxes)\n\t\t\tconfs = np.array(filtered_confs)\n\t\t\tclss = np.array(filtered_clss)\n\t\tif args.no_deepsort:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_clss",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfiltered_clss = []\n\t\t\tfor i in idxs.flatten():\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_confs.append(confs[i])\n\t\t\t\tfiltered_clss.append(clss[i])\n\t\t\tboxes = np.array(filtered_boxes)\n\t\t\tconfs = np.array(filtered_confs)\n\t\t\tclss = np.array(filtered_clss)\n\t\tif args.no_deepsort:\n\t\t\t# Draw raw detections without tracking",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tboxes = np.array(filtered_boxes)\n\t\t\tconfs = np.array(filtered_confs)\n\t\t\tclss = np.array(filtered_clss)\n\t\tif args.no_deepsort:\n\t\t\t# Draw raw detections without tracking\n\t\t\timg_better_look = vis.draw_bboxes(img_better_look, boxes, confs, clss)\n\t\t\toutputs = np.zeros((0, 5), dtype=np.float32)  # Empty outputs to skip tracked drawing\n\t\telse:\n\t\t\t# Use DeepSORT tracking\n\t\t\t# compute width and height of bboxs",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tconfs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tconfs = np.array(filtered_confs)\n\t\t\tclss = np.array(filtered_clss)\n\t\tif args.no_deepsort:\n\t\t\t# Draw raw detections without tracking\n\t\t\timg_better_look = vis.draw_bboxes(img_better_look, boxes, confs, clss)\n\t\t\toutputs = np.zeros((0, 5), dtype=np.float32)  # Empty outputs to skip tracked drawing\n\t\telse:\n\t\t\t# Use DeepSORT tracking\n\t\t\t# compute width and height of bboxs\n\t\t\toutput = boxes",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tclss",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tclss = np.array(filtered_clss)\n\t\tif args.no_deepsort:\n\t\t\t# Draw raw detections without tracking\n\t\t\timg_better_look = vis.draw_bboxes(img_better_look, boxes, confs, clss)\n\t\t\toutputs = np.zeros((0, 5), dtype=np.float32)  # Empty outputs to skip tracked drawing\n\t\telse:\n\t\t\t# Use DeepSORT tracking\n\t\t\t# compute width and height of bboxs\n\t\t\toutput = boxes\n\t\t\tw = output[:,[2]] - output[:,[0]]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\timg_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\timg_better_look = vis.draw_bboxes(img_better_look, boxes, confs, clss)\n\t\t\toutputs = np.zeros((0, 5), dtype=np.float32)  # Empty outputs to skip tracked drawing\n\t\telse:\n\t\t\t# Use DeepSORT tracking\n\t\t\t# compute width and height of bboxs\n\t\t\toutput = boxes\n\t\t\tw = output[:,[2]] - output[:,[0]]\n\t\t\th = output[:,[3]] - output[:,[1]]\n\t\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t\t#print(xc,yc,\"center\")",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\toutputs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\toutputs = np.zeros((0, 5), dtype=np.float32)  # Empty outputs to skip tracked drawing\n\t\telse:\n\t\t\t# Use DeepSORT tracking\n\t\t\t# compute width and height of bboxs\n\t\t\toutput = boxes\n\t\t\tw = output[:,[2]] - output[:,[0]]\n\t\t\th = output[:,[3]] - output[:,[1]]\n\t\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t\t#print(xc,yc,\"center\")\n\t\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\toutput",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\toutput = boxes\n\t\t\tw = output[:,[2]] - output[:,[0]]\n\t\t\th = output[:,[3]] - output[:,[1]]\n\t\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t\t#print(xc,yc,\"center\")\n\t\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\t\toutputs = tracker.run(img, boxes, confs)\n\t\t# Predictive checks after outputs is defined\n\t\tif args.enable_trajectory_extrapolation and len(outputs) > 0:\n\t\t\tif trajectory_extrapolation(outputs, img.shape, pol):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tw = output[:,[2]] - output[:,[0]]\n\t\t\th = output[:,[3]] - output[:,[1]]\n\t\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t\t#print(xc,yc,\"center\")\n\t\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\t\toutputs = tracker.run(img, boxes, confs)\n\t\t# Predictive checks after outputs is defined\n\t\tif args.enable_trajectory_extrapolation and len(outputs) > 0:\n\t\t\tif trajectory_extrapolation(outputs, img.shape, pol):\n\t\t\t\tcv2.putText(img_better_look, \"Trajectory Alert!\", (50, 200), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\th",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\th = output[:,[3]] - output[:,[1]]\n\t\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t\t#print(xc,yc,\"center\")\n\t\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\t\toutputs = tracker.run(img, boxes, confs)\n\t\t# Predictive checks after outputs is defined\n\t\tif args.enable_trajectory_extrapolation and len(outputs) > 0:\n\t\t\tif trajectory_extrapolation(outputs, img.shape, pol):\n\t\t\t\tcv2.putText(img_better_look, \"Trajectory Alert!\", (50, 200), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)\n\t\t# if prev_gray is not None and args.enable_optical_flow and len(outputs) > 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\t\toutputs = tracker.run(img, boxes, confs)\n\t\t# Predictive checks after outputs is defined\n\t\tif args.enable_trajectory_extrapolation and len(outputs) > 0:\n\t\t\tif trajectory_extrapolation(outputs, img.shape, pol):\n\t\t\t\tcv2.putText(img_better_look, \"Trajectory Alert!\", (50, 200), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)\n\t\t# if prev_gray is not None and args.enable_optical_flow and len(outputs) > 0:\n\t\t# \tfor x1,y1,x2,y2,ids in outputs:\n\t\t# \t\tif optical_flow_analysis(prev_gray, gray, (int(x1),int(y1),int(x2),int(y2))):\n\t\t# \t\t\tcv2.putText(img_better_look, \"Optical Flow Alert!\", (50, 250), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\toutputs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\toutputs = tracker.run(img, boxes, confs)\n\t\t# Predictive checks after outputs is defined\n\t\tif args.enable_trajectory_extrapolation and len(outputs) > 0:\n\t\t\tif trajectory_extrapolation(outputs, img.shape, pol):\n\t\t\t\tcv2.putText(img_better_look, \"Trajectory Alert!\", (50, 200), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)\n\t\t# if prev_gray is not None and args.enable_optical_flow and len(outputs) > 0:\n\t\t# \tfor x1,y1,x2,y2,ids in outputs:\n\t\t# \t\tif optical_flow_analysis(prev_gray, gray, (int(x1),int(y1),int(x2),int(y2))):\n\t\t# \t\t\tcv2.putText(img_better_look, \"Optical Flow Alert!\", (50, 250), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)\n\t\t# \t\t\tbreak",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tprev_gray",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tprev_gray = gray\n\t\tif args.no_deepsort:\n\t\t\t# Draw paths for raw detections\n\t\t\tfor i, (x1,y1,x2,y2) in enumerate(boxes):\n\t\t\t\txc = int((x1 + x2)/2)\n\t\t\t\tyc = int((y1 + y2)/2)\n\t\t\t\tids = i  # dummy id per detection\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\txc = int((x1 + x2)/2)\n\t\t\t\tyc = int((y1 + y2)/2)\n\t\t\t\tids = i  # dummy id per detection\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))\n\t\t\t\tif len(history[ids]) > 1:\n\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor j in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[j-1], points[j], (0,255,0), 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tyc = int((y1 + y2)/2)\n\t\t\t\tids = i  # dummy id per detection\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))\n\t\t\t\tif len(history[ids]) > 1:\n\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor j in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[j-1], points[j], (0,255,0), 2)\n\t\t\t\t# Draw ID for raw detection",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tids",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tids = i  # dummy id per detection\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))\n\t\t\t\tif len(history[ids]) > 1:\n\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor j in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[j-1], points[j], (0,255,0), 2)\n\t\t\t\t# Draw ID for raw detection\n\t\t\t\tcv2.putText(img_better_look, f\"ID: {i}\", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\thistory[ids]",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))\n\t\t\t\tif len(history[ids]) > 1:\n\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor j in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[j-1], points[j], (0,255,0), 2)\n\t\t\t\t# Draw ID for raw detection\n\t\t\t\tcv2.putText(img_better_look, f\"ID: {i}\", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tpoints",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor j in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[j-1], points[j], (0,255,0), 2)\n\t\t\t\t# Draw ID for raw detection\n\t\t\t\tcv2.putText(img_better_look, f\"ID: {i}\", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#img_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tclss",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tcls",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tcls",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :\n\t\t\t#print(xc,\"xc\")\n\t\t\t#outputs.astype(int)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t#f",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :\n\t\t\t#print(xc,\"xc\")\n\t\t\t#outputs.astype(int)\n\t\t\t#print(\"before x1 y1......\",outputs)\n\t\t\tfor x1,y1,x2,y2,ids in outputs:\n\t\t\t\t# Draw bounding box",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txmin",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\txmin = x1\n\t\t\t\tymin = y2\n\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tymin",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tymin = y2\n\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\th",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\th",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tlow_mid",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tlow_left",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcenter",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#cent",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw_tim",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#xc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t# Add to history for path drawing",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#yc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t# Add to history for path drawing\n\t\t\t\tif ids not in history:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tx_res_yc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t# Add to history for path drawing\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tx_res_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t# Add to history for path drawing\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tpol",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t# Add to history for path drawing\n\t\t\t\tif ids not in history:\n\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))\n\t\t\t\t# Draw the trajectory path",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\thistory[ids]",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\thistory[ids] = deque(maxlen=50)\n\t\t\t\thistory[ids].append((xc, yc))\n\t\t\t\t# Draw the trajectory path\n\t\t\t\tif len(history[ids]) > 1:\n\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor i in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[i-1], points[i], (0,255,0), 2)\n\t\t\t\t# Draw predicted path arrow\n\t\t\t\tif not args.no_deepsort and hasattr(tracker, 'tracks'):\n\t\t\t\t\tfor track in tracker.tracks:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tpoints",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tpoints = list(history[ids])\n\t\t\t\t\tfor i in range(1, len(points)):\n\t\t\t\t\t\tcv2.line(img_better_look, points[i-1], points[i], (0,255,0), 2)\n\t\t\t\t# Draw predicted path arrow\n\t\t\t\tif not args.no_deepsort and hasattr(tracker, 'tracks'):\n\t\t\t\t\tfor track in tracker.tracks:\n\t\t\t\t\t\tif track.track_id == ids and track.is_confirmed():\n\t\t\t\t\t\t\tkf = track.kalman_filter\n\t\t\t\t\t\t\tvel_x = kf.x[4]\n\t\t\t\t\t\t\tvel_y = kf.x[5]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tkf",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tkf = track.kalman_filter\n\t\t\t\t\t\t\tvel_x = kf.x[4]\n\t\t\t\t\t\t\tvel_y = kf.x[5]\n\t\t\t\t\t\t\tvel_mag = (vel_x**2 + vel_y**2)**0.5\n\t\t\t\t\t\t\tif vel_mag > 0:\n\t\t\t\t\t\t\t\tdir_x = vel_x / vel_mag\n\t\t\t\t\t\t\t\tdir_y = vel_y / vel_mag\n\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tvel_x",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tvel_x = kf.x[4]\n\t\t\t\t\t\t\tvel_y = kf.x[5]\n\t\t\t\t\t\t\tvel_mag = (vel_x**2 + vel_y**2)**0.5\n\t\t\t\t\t\t\tif vel_mag > 0:\n\t\t\t\t\t\t\t\tdir_x = vel_x / vel_mag\n\t\t\t\t\t\t\t\tdir_y = vel_y / vel_mag\n\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tvel_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tvel_y = kf.x[5]\n\t\t\t\t\t\t\tvel_mag = (vel_x**2 + vel_y**2)**0.5\n\t\t\t\t\t\t\tif vel_mag > 0:\n\t\t\t\t\t\t\t\tdir_x = vel_x / vel_mag\n\t\t\t\t\t\t\t\tdir_y = vel_y / vel_mag\n\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tvel_mag",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tvel_mag = (vel_x**2 + vel_y**2)**0.5\n\t\t\t\t\t\t\tif vel_mag > 0:\n\t\t\t\t\t\t\t\tdir_x = vel_x / vel_mag\n\t\t\t\t\t\t\t\tdir_y = vel_y / vel_mag\n\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdir_x",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdir_x = vel_x / vel_mag\n\t\t\t\t\t\t\t\tdir_y = vel_y / vel_mag\n\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1\n\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdir_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdir_y = vel_y / vel_mag\n\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1\n\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tarrow_length",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tarrow_length = 50  # fixed length for visibility\n\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1\n\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tpred_center",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tpred_center = (xc + dir_x * arrow_length, yc + dir_y * arrow_length)\n\t\t\t\t\t\t\t\tcv2.arrowedLine(img_better_look, (xc, yc), tuple(map(int, pred_center)), (0,255,255), 3, tipLength=0.3)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1\n\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#cent",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))\n\t\t\t\t\tif abs(pt[ids][j][1] - pt[ids][j-1][1]) < 10 :\n\t\t\t\t\t\t#print(\"in abs!!!!!!\",(pt[ids][j-1]) , (pt[ids][j]))\n\t\t\t\t\t\tcv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\tif len(pt[ids]) > 5:\n\t\t\t\t\t\tif j%5 == 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#cent",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))\n\t\t\t\t\tif abs(pt[ids][j][1] - pt[ids][j-1][1]) < 10 :\n\t\t\t\t\t\t#print(\"in abs!!!!!!\",(pt[ids][j-1]) , (pt[ids][j]))\n\t\t\t\t\t\tcv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\tif len(pt[ids]) > 5:\n\t\t\t\t\t\tif j%5 == 0:\n\t\t\t\t\t\t\t#motion = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#motion",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t#motion = True\n\t\t\t\t\t\t\t#x_dir_avg = np.average(x_dir)\n\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#x_dir_avg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t#x_dir_avg = np.average(x_dir)\n\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#y_dir_avg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#parameters_avg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tx_dirr",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\ty_dirr",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\t\tdrw = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t#x_dirr",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t\t# polyfit succeeded\n\t\t\t\t\t\t\texcept np.linalg.LinAlgError:\n\t\t\t\t\t\t\t\tdrw = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\ty_dirr",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t\t# polyfit succeeded\n\t\t\t\t\t\t\texcept np.linalg.LinAlgError:\n\t\t\t\t\t\t\t\tdrw = False\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tparameters",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t\t# polyfit succeeded\n\t\t\t\t\t\t\texcept np.linalg.LinAlgError:\n\t\t\t\t\t\t\t\tdrw = False\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t\t# polyfit succeeded\n\t\t\t\t\t\t\texcept np.linalg.LinAlgError:\n\t\t\t\t\t\t\t\tdrw = False\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdrw = False\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx_res_y2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tmotion_predict",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#x1,y1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#x2,y2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):\n\t\t\t\t\t#print(\"len(w_list[ids]) :\",len(w_list[ids]),\"; i :\",i)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img_trans",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):\n\t\t\t\t\t#print(\"len(w_list[ids]) :\",len(w_list[ids]),\"; i :\",i)\n\t\t\t\t\t#print(\"k in for loop\",k)\n\t\t\t\t\t#i+=2",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\twidth_curr",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\twidth_curr = w_list[ids][i][0]\n\t\t\t\t\tif i%5 ==0 and k+1 <= i and len(w_list[ids]) > 5:  #sample every 3 points\n\t\t\t\t\t\t#print(\"k in if statement\",k)\n\t\t\t\t\t\twidth_1 = (w_list[ids][k-1][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\twidth_1 = (w_list[ids][k-1][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\t# computed time_passed and width difference for speed estimation\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"deer\":",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\t# computed time_passed and width difference for speed estimation\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#width_curr",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\t# computed time_passed and width difference for speed estimation\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_passed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\t# computed time_passed and width difference for speed estimation\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\t\tdis_deer =  Distance_finder(100,width_curr)/100",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\t# computed time_passed and width difference for speed estimation\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\t\tdis_deer =  Distance_finder(100,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\t# computed time_passed and width difference for speed estimation\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\t\tdis_deer =  Distance_finder(100,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_deer2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\t\tdis_deer =  Distance_finder(100,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_deer1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\t\tdis_deer =  Distance_finder(100,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tputtext_deer = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_deer =  Distance_finder(100,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average deer speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_diff_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average deer speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"deer speed\",car_spd)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdeer_speed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average deer speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"deer speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"deer speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_deer)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average deer speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"deer speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"deer speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_deer)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"deer speed {int(deer_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tavg_spd_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average deer speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"deer speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"deer speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_deer)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"deer speed {int(deer_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike\n\t\t\t\t\t\t\tif name == \"motorbike\" or name ==\"\":\n\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tputtext_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average deer speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"deer speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"deer speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_deer)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"deer speed {int(deer_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike\n\t\t\t\t\t\t\tif name == \"motorbike\" or name ==\"\":\n\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_diff_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tmoto_speed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tavg_spd",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tputtext_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"deer\":",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_passed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"deer\":\n\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_deer)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_deer2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tdis_deer2 = Distance_finder(100,width_2)/100\n\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_deer)\n\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\tputtext_deer = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_deer1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tdis_deer1 = Distance_finder(100,width_1)/100\n\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_deer)\n\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_diff_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tdis_diff_deer = abs(dis_deer2 - dis_deer1)\n\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_deer)\n\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdeer_speed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tdeer_speed = (dis_diff_deer/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(deer_speed)\n\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_deer)\n\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tavg_spd_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tavg_spd_deer = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_deer != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_deer)\n\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_deer = int(avg_spd_deer)\n\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tputtext_deer",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tputtext_deer = True\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_deer == True and  avg_spd_deer != \"still appending\" and deer_speed != 0 and avg_spd_deer != 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_deer == True and  avg_spd_deer != \"still appending\" and deer_speed != 0 and avg_spd_deer != 0:\n\t\t\t\t\tdeer_imptim_avg = round(dis_deer/(avg_spd_deer*1000/3600),2)               \n\t\t\t\t\tdeer_imptim = round(dis_deer/(deer_speed*1000/3600),2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tputtext_moto",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_deer == True and  avg_spd_deer != \"still appending\" and deer_speed != 0 and avg_spd_deer != 0:\n\t\t\t\t\tdeer_imptim_avg = round(dis_deer/(avg_spd_deer*1000/3600),2)               \n\t\t\t\t\tdeer_imptim = round(dis_deer/(deer_speed*1000/3600),2)\n\t\t\t\t\t# cv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h Collision time {deer_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#k",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_deer == True and  avg_spd_deer != \"still appending\" and deer_speed != 0 and avg_spd_deer != 0:\n\t\t\t\t\tdeer_imptim_avg = round(dis_deer/(avg_spd_deer*1000/3600),2)               \n\t\t\t\t\tdeer_imptim = round(dis_deer/(deer_speed*1000/3600),2)\n\t\t\t\t\t# cv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h Collision time {deer_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t# cv2.putText(img_better_look, f\"deer speed {int(deer_speed)} km/h  Collision time {deer_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tk",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_deer == True and  avg_spd_deer != \"still appending\" and deer_speed != 0 and avg_spd_deer != 0:\n\t\t\t\t\tdeer_imptim_avg = round(dis_deer/(avg_spd_deer*1000/3600),2)               \n\t\t\t\t\tdeer_imptim = round(dis_deer/(deer_speed*1000/3600),2)\n\t\t\t\t\t# cv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h Collision time {deer_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t# cv2.putText(img_better_look, f\"deer speed {int(deer_speed)} km/h  Collision time {deer_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdeer_imptim_avg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tdeer_imptim_avg = round(dis_deer/(avg_spd_deer*1000/3600),2)               \n\t\t\t\t\tdeer_imptim = round(dis_deer/(deer_speed*1000/3600),2)\n\t\t\t\t\t# cv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h Collision time {deer_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t# cv2.putText(img_better_look, f\"deer speed {int(deer_speed)} km/h  Collision time {deer_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"deer speed {int(deer_speed)} km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif deer_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif deer_imptim_avg < 0.75 and motion_predict == True:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdeer_imptim",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tdeer_imptim = round(dis_deer/(deer_speed*1000/3600),2)\n\t\t\t\t\t# cv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h Collision time {deer_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t# cv2.putText(img_better_look, f\"deer speed {int(deer_speed)} km/h  Collision time {deer_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"average deer speed {avg_spd_deer} km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"deer speed {int(deer_speed)} km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif deer_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif deer_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif deer_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\t\tif args.enable_ttc_forecasting and deer_speed > 0:\n\t\t\t\t\t\tif enhanced_ttc_forecasting(dis_deer, deer_speed):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif deer_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\t\tif args.enable_ttc_forecasting and deer_speed > 0:\n\t\t\t\t\t\tif enhanced_ttc_forecasting(dis_deer, deer_speed):\n\t\t\t\t\t\t\tcv2.putText(img_better_look, \"TTC Forecast Alert!\", (50, 300), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,255,0), 2)       ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\t\tif args.enable_ttc_forecasting and deer_speed > 0:\n\t\t\t\t\t\tif enhanced_ttc_forecasting(dis_deer, deer_speed):\n\t\t\t\t\t\t\tcv2.putText(img_better_look, \"TTC Forecast Alert!\", (50, 300), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,255,0), 2)       \n\t\t\t\tif cls == \"deer\":\n\t\t\t\t\tdis = Distance_finder(100,w)//100",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\t\tif args.enable_ttc_forecasting and deer_speed > 0:\n\t\t\t\t\t\tif enhanced_ttc_forecasting(dis_deer, deer_speed):\n\t\t\t\t\t\t\tcv2.putText(img_better_look, \"TTC Forecast Alert!\", (50, 300), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,255,0), 2)       \n\t\t\t\tif cls == \"deer\":\n\t\t\t\t\tdis = Distance_finder(100,w)//100\n\t\t\t\t\tdis = int(dis)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\t\tif args.enable_ttc_forecasting and deer_speed > 0:\n\t\t\t\t\t\tif enhanced_ttc_forecasting(dis_deer, deer_speed):\n\t\t\t\t\t\t\tcv2.putText(img_better_look, \"TTC Forecast Alert!\", (50, 300), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,255,0), 2)       \n\t\t\t\tif cls == \"deer\":\n\t\t\t\t\tdis = Distance_finder(100,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tdis = Distance_finder(100,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args.enable_proactive_thresholds:\n\t\t\t\t\t\t\tif proactive_alert_thresholds(dis, deer_speed, True, motion_predict):\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} proactive alert -> DANGER\")",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args.enable_proactive_thresholds:\n\t\t\t\t\t\t\tif proactive_alert_thresholds(dis, deer_speed, True, motion_predict):\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} proactive alert -> DANGER\")\n\t\t\t\t\t\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} proactive alert -> DANGER\")\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} proactive alert -> DANGER\")\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=deer dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_start",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_start",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tused",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_end",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_end",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tprint(\"time",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"deer speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"deer speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\t# placeholder for additional deer logic\n\t\t\t\t\t\tpass",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tbad",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"deer speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\t# placeholder for additional deer logic\n\t\t\t\t\t\tpass\n\t\t\t\t\t#f.insert(0,(xc,yc))\n\t\t\t\t\t#print(\"deer center list :  \",f)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"deer speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\t# placeholder for additional deer logic\n\t\t\t\t\t\tpass\n\t\t\t\t\t#f.insert(0,(xc,yc))\n\t\t\t\t\t#print(\"deer center list :  \",f)\n\t\t\t\t# -- distance-based alerts (configurable thresholds)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tif cls == \"deer\":\n\t\t\t\t\t\t\tif 'dis' in locals():\n\t\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tif cls == \"deer\":\n\t\t\t\t\t\t\tif 'dis' in locals():\n\t\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tused",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_end",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_end",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tprint(\"time",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tbad",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :\n\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :\n\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr                           ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr                           \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"time start {time_start}  time end {time_end}\",  (100, 500), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t#m.insert(0,(xc,yc))\n\t\t\t\t\t\t\t#print(\"motorbike center list:  \",m)\n\t\t\t\t'''\n\t\t\t\tsafety zone\n\t\t\t\t=============",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#unsafe",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#unsafe = True\n\t\t\t\t\tprint(\"satis1\")\n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img1 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img1 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tunsafe",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:\n\t\t\t\t\t#mylcd.lcd_display_string(\"dangerous!\",  2,3)\n\t\t\t\t\t#buzz(unsafe_v)\n\t\t\t\t\tprint(\"satis3\")",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:\n\t\t\t\t\t#mylcd.lcd_display_string(\"dangerous!\",  2,3)\n\t\t\t\t\t#buzz(unsafe_v)\n\t\t\t\t\tprint(\"satis3\")\n\t\t\t\t\t#danger = True #dangerous\n\t\t\t\t\t#unsafe = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#danger",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#danger = True #dangerous\n\t\t\t\t\t#unsafe = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"dangerous!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr\n\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#unsafe",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#unsafe = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"dangerous!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr\n\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img3",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdanger",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tunsafe",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img4",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tbbox_xyxy",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tidentities",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\timg_final",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timgx",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\treal_result",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\toverlay",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\talpha",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_w",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_h",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tx1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ty1",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tx2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ty2",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tstatus_text",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\t# cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tcolor",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\t# cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus_text",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\t# cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\t# cv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcolor",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\t# cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\t# cv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner\n\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus_text",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\t# cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\t# cv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner\n\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX\n\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcolor",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\t# cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\t# cv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner\n\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX\n\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfont",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX\n\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)\n\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\t# cv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfont_scale",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)\n\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\t# cv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tthickness",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)\n\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\t# cv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear\n\t\ttry:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_x",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\t# cv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear\n\t\ttry:\n\t\t\tif danger_v:\n\t\t\t\tstatus = 'DANGER'",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\t# cv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear\n\t\ttry:\n\t\t\tif danger_v:\n\t\t\t\tstatus = 'DANGER'\n\t\t\telif unsafe_v:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tstatus = 'DANGER'\n\t\t\telif unsafe_v:\n\t\t\t\tstatus = 'MEDIUM'\n\t\t\telse:\n\t\t\t\tstatus = 'SAFE'\n\t\t\tif status != prev_status:\n\t\t\t\tprint(f\"[ALERT] frame={framenumber} status={status} unsafe_v={unsafe_v} danger_v={danger_v}\")\n\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tstatus = 'MEDIUM'\n\t\t\telse:\n\t\t\t\tstatus = 'SAFE'\n\t\t\tif status != prev_status:\n\t\t\t\tprint(f\"[ALERT] frame={framenumber} status={status} unsafe_v={unsafe_v} danger_v={danger_v}\")\n\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass\n\t\t# Add center flashing alert for danger\n\t\t# if danger_v:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tstatus = 'SAFE'\n\t\t\tif status != prev_status:\n\t\t\t\tprint(f\"[ALERT] frame={framenumber} status={status} unsafe_v={unsafe_v} danger_v={danger_v}\")\n\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass\n\t\t# Add center flashing alert for danger\n\t\t# if danger_v:\n\t\t# \t# Flash by alternating color\n\t\t# \tflash_color = (0, 0, 255) if (framenumber // 10) % 2 == 0 else (255, 255, 255)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tprev_status",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass\n\t\t# Add center flashing alert for danger\n\t\t# if danger_v:\n\t\t# \t# Flash by alternating color\n\t\t# \tflash_color = (0, 0, 255) if (framenumber // 10) % 2 == 0 else (255, 255, 255)\n\t\t# \tcv2.putText(img_better_look, \"DANGER!\", (320, 240), cv2.FONT_HERSHEY_DUPLEX, 2.0, flash_color, 5, cv2.LINE_AA)\n\t\t# \tprint(f\"[ALERT] Center danger alert displayed frame={framenumber}\")\n\t\t# Draw status banner (smaller + right-aligned)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tbanner_w",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tbanner_w = 140\n\t\tbanner_h = 30\n\t\tbanner_x = img.shape[1] - banner_w - 20\n\t\tbanner_y = 20\n\t\tif danger_v:\n\t\t\tbanner_color = (0, 0, 255)  # Red\n\t\t\tstatus_text = \"DANGER\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tbanner_h",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tbanner_h = 30\n\t\tbanner_x = img.shape[1] - banner_w - 20\n\t\tbanner_y = 20\n\t\tif danger_v:\n\t\t\tbanner_color = (0, 0, 255)  # Red\n\t\t\tstatus_text = \"DANGER\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tbanner_x",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tbanner_x = img.shape[1] - banner_w - 20\n\t\tbanner_y = 20\n\t\tif danger_v:\n\t\t\tbanner_color = (0, 0, 255)  # Red\n\t\t\tstatus_text = \"DANGER\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tbanner_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tbanner_y = 20\n\t\tif danger_v:\n\t\t\tbanner_color = (0, 0, 255)  # Red\n\t\t\tstatus_text = \"DANGER\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_color",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tbanner_color = (0, 0, 255)  # Red\n\t\t\tstatus_text = \"DANGER\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telse:\n\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tstatus_text",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tstatus_text = \"DANGER\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telse:\n\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_color",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ttext_color = (255, 255, 255)\n\t\telif unsafe_v:\n\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telse:\n\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_color",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tbanner_color = (0, 165, 255)  # Orange\n\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telse:\n\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside\n\t\tcv2.rectangle(img_better_look, (banner_x, banner_y), (banner_x + banner_w, banner_y + banner_h), banner_color, -1)\n\t\ttext_y = banner_y + int(banner_h * 0.7)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tstatus_text",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tstatus_text = \"MEDIUM\"\n\t\t\ttext_color = (255, 255, 255)\n\t\telse:\n\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside\n\t\tcv2.rectangle(img_better_look, (banner_x, banner_y), (banner_x + banner_w, banner_y + banner_h), banner_color, -1)\n\t\ttext_y = banner_y + int(banner_h * 0.7)\n\t\tcv2.putText(img_better_look, status_text, (banner_x + 10, text_y), cv2.FONT_HERSHEY_COMPLEX, 0.8, text_color, 2)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_color",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ttext_color = (255, 255, 255)\n\t\telse:\n\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside\n\t\tcv2.rectangle(img_better_look, (banner_x, banner_y), (banner_x + banner_w, banner_y + banner_h), banner_color, -1)\n\t\ttext_y = banner_y + int(banner_h * 0.7)\n\t\tcv2.putText(img_better_look, status_text, (banner_x + 10, text_y), cv2.FONT_HERSHEY_COMPLEX, 0.8, text_color, 2)\n\t\tout.write(line_visualize)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_color",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tbanner_color = (0, 255, 0)  # Green\n\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside\n\t\tcv2.rectangle(img_better_look, (banner_x, banner_y), (banner_x + banner_w, banner_y + banner_h), banner_color, -1)\n\t\ttext_y = banner_y + int(banner_h * 0.7)\n\t\tcv2.putText(img_better_look, status_text, (banner_x + 10, text_y), cv2.FONT_HERSHEY_COMPLEX, 0.8, text_color, 2)\n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tstatus_text",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tstatus_text = \"SAFE\"\n\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside\n\t\tcv2.rectangle(img_better_look, (banner_x, banner_y), (banner_x + banner_w, banner_y + banner_h), banner_color, -1)\n\t\ttext_y = banner_y + int(banner_h * 0.7)\n\t\tcv2.putText(img_better_look, status_text, (banner_x + 10, text_y), cv2.FONT_HERSHEY_COMPLEX, 0.8, text_color, 2)\n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_color",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\ttext_color = (0, 0, 0)\n\t\t# draw rectangle at banner origin and place text aligned vertically inside\n\t\tcv2.rectangle(img_better_look, (banner_x, banner_y), (banner_x + banner_w, banner_y + banner_h), banner_color, -1)\n\t\ttext_y = banner_y + int(banner_h * 0.7)\n\t\tcv2.putText(img_better_look, status_text, (banner_x + 10, text_y), cv2.FONT_HERSHEY_COMPLEX, 0.8, text_color, 2)\n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\ttext_y",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\ttext_y = banner_y + int(banner_h * 0.7)\n\t\tcv2.putText(img_better_look, status_text, (banner_x + 10, text_y), cv2.FONT_HERSHEY_COMPLEX, 0.8, text_color, 2)\n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)\n\t\t####\n\t\t#cv2.imshow(\"normal lanedetection without extended\",normal_result)\n\t\t#cv2.imshow(\"combo img\",combo_image)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\ttoc",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\ttoc = time.time()\n\t\tcurr_fps = 1.0 / (toc - tic)\n\t\t# calculate an exponentially decaying average of fps number\n\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tcurr_fps",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tcurr_fps = 1.0 / (toc - tic)\n\t\t# calculate an exponentially decaying average of fps number\n\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tfps",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\n\t# Processing complete\n\ttotal_time = time.time() - start_time",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\ttic",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\n\t# Processing complete\n\ttotal_time = time.time() - start_time\n\tif hasattr(detector, 'device'):",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tkey",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\n\t# Processing complete\n\ttotal_time = time.time() - start_time\n\tif hasattr(detector, 'device'):\n\t\tprint(f\"Processing complete. Device used: {detector.device}. Total time: {total_time:.2f} seconds\")",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tfull_scrn",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\n\t# Processing complete\n\ttotal_time = time.time() - start_time\n\tif hasattr(detector, 'device'):\n\t\tprint(f\"Processing complete. Device used: {detector.device}. Total time: {total_time:.2f} seconds\")\n\telse:\n\t\tprint(f\"Processing complete. Total time: {total_time:.2f} seconds\")\ndef main():\n\targs = parse_args()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\ttotal_time",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\ttotal_time = time.time() - start_time\n\tif hasattr(detector, 'device'):\n\t\tprint(f\"Processing complete. Device used: {detector.device}. Total time: {total_time:.2f} seconds\")\n\telse:\n\t\tprint(f\"Processing complete. Total time: {total_time:.2f} seconds\")\ndef main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    ",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv and not args.use_pytorch:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):\n\t\t\traise SystemExit('ERROR: file (yolo/%s.trt) not found!' % args.model)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tcfg",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv and not args.use_pytorch:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):\n\t\t\traise SystemExit('ERROR: file (yolo/%s.trt) not found!' % args.model)\n\tcam = Camera(args)\n\tif not cam.isOpened():",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tcam",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tcam = Camera(args)\n\tif not cam.isOpened():\n\t\traise SystemExit('ERROR: failed to open camera!')\n\t########    \n\ttracker = Tracker_tiny(cfg) \n\t########\n\tif args.use_pytorch:\n\t\t# For custom PyTorch model, assume class 0 is deer\n\t\tcls_dict = {0: 'deer'}\n\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\ttracker",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\ttracker = Tracker_tiny(cfg) \n\t########\n\tif args.use_pytorch:\n\t\t# For custom PyTorch model, assume class 0 is deer\n\t\tcls_dict = {0: 'deer'}\n\telse:\n\t\tcls_dict = get_cls_dict(args.category_num)\n\tif args.use_pytorch:\n\t\t# Use PyTorch YOLO\n\t\tdetector = PyTorchYolo(args.pytorch_model)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tcls_dict",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tcls_dict = {0: 'deer'}\n\telse:\n\t\tcls_dict = get_cls_dict(args.category_num)\n\tif args.use_pytorch:\n\t\t# Use PyTorch YOLO\n\t\tdetector = PyTorchYolo(args.pytorch_model)\n\telif args.use_opencv:\n\t\t# Default input shape for OpenCV YOLO\n\t\th = w = 416\n\t\t# Use OpenCV DNN fallback on CPU",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tcls_dict",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tcls_dict = get_cls_dict(args.category_num)\n\tif args.use_pytorch:\n\t\t# Use PyTorch YOLO\n\t\tdetector = PyTorchYolo(args.pytorch_model)\n\telif args.use_opencv:\n\t\t# Default input shape for OpenCV YOLO\n\t\th = w = 416\n\t\t# Use OpenCV DNN fallback on CPU\n\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tdetector = PyTorchYolo(args.pytorch_model)\n\telif args.use_opencv:\n\t\t# Default input shape for OpenCV YOLO\n\t\th = w = 416\n\t\t# Use OpenCV DNN fallback on CPU\n\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\th",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\th = w = 416\n\t\t# Use OpenCV DNN fallback on CPU\n\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\t\telse:\n\t\t\th = w = int(yolo_dim)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tyolo_dim",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\t\telse:\n\t\t\th = w = int(yolo_dim)\n\t\tif h % 32 != 0 or w % 32 != 0:\n\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\tdim_split",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\t\telse:\n\t\t\th = w = int(yolo_dim)\n\t\tif h % 32 != 0 or w % 32 != 0:\n\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\t\th",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\t\th = w = int(yolo_dim)\n\t\tif h % 32 != 0 or w % 32 != 0:\n\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=args.confidence_threshold, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\ttrt_yolo",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=args.confidence_threshold, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=args.confidence_threshold, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "\tvis",
        "kind": 5,
        "importPath": "deer",
        "description": "deer",
        "peekOfCode": "\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=args.confidence_threshold, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "deer",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "simple_yolo",
        "description": "simple_yolo",
        "peekOfCode": "model = YOLO(\"deer.pt\")\n# 2. Set the path to your video file\nVIDEO_PATH = \"deer/1.mp4\"  # <-- IMPORTANT: Change this\n# 3. (Optional) Print the model's class names to find the 'deer' ID\n# This helps you verify the class ID. In this model, 'deer' is typically class 0.\nprint(\"Model classes:\", model.names)\nDEER_CLASS_ID = 0  # Assuming 'deer' is class 0, adjust if model.names shows differently\n# --- End Configuration ---\n# Open the video file\ncap = cv2.VideoCapture(VIDEO_PATH)",
        "detail": "simple_yolo",
        "documentation": {}
    },
    {
        "label": "VIDEO_PATH",
        "kind": 5,
        "importPath": "simple_yolo",
        "description": "simple_yolo",
        "peekOfCode": "VIDEO_PATH = \"deer/1.mp4\"  # <-- IMPORTANT: Change this\n# 3. (Optional) Print the model's class names to find the 'deer' ID\n# This helps you verify the class ID. In this model, 'deer' is typically class 0.\nprint(\"Model classes:\", model.names)\nDEER_CLASS_ID = 0  # Assuming 'deer' is class 0, adjust if model.names shows differently\n# --- End Configuration ---\n# Open the video file\ncap = cv2.VideoCapture(VIDEO_PATH)\n# Check if video opened successfully\nif not cap.isOpened():",
        "detail": "simple_yolo",
        "documentation": {}
    },
    {
        "label": "DEER_CLASS_ID",
        "kind": 5,
        "importPath": "simple_yolo",
        "description": "simple_yolo",
        "peekOfCode": "DEER_CLASS_ID = 0  # Assuming 'deer' is class 0, adjust if model.names shows differently\n# --- End Configuration ---\n# Open the video file\ncap = cv2.VideoCapture(VIDEO_PATH)\n# Check if video opened successfully\nif not cap.isOpened():\n    print(f\"Error: Could not open video file {VIDEO_PATH}\")\n    exit()\n# Loop through the video frames\nwhile cap.isOpened():",
        "detail": "simple_yolo",
        "documentation": {}
    },
    {
        "label": "cap",
        "kind": 5,
        "importPath": "simple_yolo",
        "description": "simple_yolo",
        "peekOfCode": "cap = cv2.VideoCapture(VIDEO_PATH)\n# Check if video opened successfully\nif not cap.isOpened():\n    print(f\"Error: Could not open video file {VIDEO_PATH}\")\n    exit()\n# Loop through the video frames\nwhile cap.isOpened():\n    # Read a frame from the video\n    success, frame = cap.read()\n    if success:",
        "detail": "simple_yolo",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "OpenCVYolo",
        "kind": 6,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "class OpenCVYolo:\n\t\"\"\"Simple OpenCV DNN wrapper for YOLO Darknet models.\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the TensorRT TrtYOLO.detect used by this repo.\n\t\"\"\"\n\tdef __init__(self, cfg_path, weights_path, input_shape=(416,416)):\n\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n\t\tself.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "append_speed",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def append_speed(ids,deque_list):\n\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n\t\t#sys.exit()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "compute_xc_yc",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def compute_xc_yc(out):\n\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "dra",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "ez_show",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "Distance_finder",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "motion_cord",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "loop_and_detect",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def loop_and_detect(cam, detector, tracker, conf_th, vis, args=None):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).\n\t\ttrt_yolo: the TRT YOLO object detector instance.\n\t\tconf_th: confidence/score threshold for object detection.\n\t\tvis: for visualization.\n\t\"\"\"\n\t# global img_final\n\tfull_scrn = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "WINDOW_NAME",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "WINDOW_NAME = 'ProjectDemo'\nclass OpenCVYolo:\n\t\"\"\"Simple OpenCV DNN wrapper for YOLO Darknet models.\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the TensorRT TrtYOLO.detect used by this repo.\n\t\"\"\"\n\tdef __init__(self, cfg_path, weights_path, input_shape=(416,416)):\n\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tself.net",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n\t\tself.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n\t\tself.input_shape = input_shape\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\th, w = img.shape[:2]\n\t\tinp_w, inp_h = self.input_shape[1], self.input_shape[0]\n\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tself.input_shape",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tself.input_shape = input_shape\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\th, w = img.shape[:2]\n\t\tinp_w, inp_h = self.input_shape[1], self.input_shape[0]\n\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)\n\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tblob",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)\n\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tlayer_names",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tout_names",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\touts",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tclass_ids",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tconfidences",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tscores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tclass_id",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tconfidence",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcenter_x",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcenter_y",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tbw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tbh",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ty1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ty2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_boxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_scores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_classes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\ti",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdesc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=False,",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=False,\n\t\t\thelp=('[yolov3|yolov3-tiny|yolov3-spp|yolov4|yolov4-tiny]-'\n\t\t\t\t\t\t'[{dimension}], where dimension could be a single '\n\t\t\t\t\t\t'number (e.g. 288, 416, 608) or WxH (e.g. 416x256)'))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=False,\n\t\t\thelp=('[yolov3|yolov3-tiny|yolov3-spp|yolov4|yolov4-tiny]-'\n\t\t\t\t\t\t'[{dimension}], where dimension could be a single '\n\t\t\t\t\t\t'number (e.g. 288, 416, 608) or WxH (e.g. 416x256)'))\n\tparser.add_argument(",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\targs = parser.parse_args()\n\treturn args\ndef append_speed(ids,deque_list):\n\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tspeed_list",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n\t\t#sys.exit()\n#fix bbox issues",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tspd_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n\t\t#sys.exit()\n#fix bbox issues\ndef compute_xc_yc(out):\n\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\txmin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tymin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\txc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tyc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\timg0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tpol",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tFocal_Length",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdistance",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ty2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)\n#    width = output[:,[2]] - output[:,[0]]\n#    height = output[:,[3]] - output[:,[1]]\n#    width = width/2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#y2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)\n#    width = output[:,[2]] - output[:,[0]]\n#    height = output[:,[3]] - output[:,[1]]\n#    width = width/2\n#    height = height/2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tx2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)\n#    width = output[:,[2]] - output[:,[0]]\n#    height = output[:,[3]] - output[:,[1]]\n#    width = width/2\n#    height = height/2\n#    xmin = xc - width",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tfull_scrn",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tfull_scrn = False\n\tfps = 0.0\n\ttic = time.time()\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tfps",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tfps = 0.0\n\ttic = time.time()\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ttic",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ttic = time.time()\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tf",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tm",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tn",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tframenumber",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tk",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#tic",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ttime_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdis_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tpts",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tpt",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#h_ls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tw_list",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcar_spd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tmoto_spd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdanger_v = False\n\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tused",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tused = False\n\t# previous status to avoid spamming logs every frame\n\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tprev_status",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tprev_status = None\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tlanedetection",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tputtext_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tputtext_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tbad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tmotion_predict",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdrw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tx_dir",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ty_dir",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#width",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#height",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#size",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tfourcc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#out",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#out2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tout",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tout = cv2.VideoWriter('line_vis.mp4', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tout1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tout1 = cv2.VideoWriter('final_res.mp4', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tout2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tout2 = cv2.VideoWriter('combo.mp4', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#out1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#mylcd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak\n\t\timg = cv2.resize(img, (1280, 960))\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak\n\t\timg = cv2.resize(img, (1280, 960))\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg = cv2.resize(img, (1280, 960))\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tpol",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\toriginal_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#input_cropped",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tadd_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#add_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#yellow_white",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#cannyresult",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#frame_for_dis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcannyresult",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tvertice",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tlines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tlines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#avg_lines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tleft_avg_lines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2\n\t\t\telif left == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2\n\t\t\telif right == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tright_avg_lines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2\n\t\t\telif left == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2\n\t\t\telif right == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#vertices_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#vertices_polly = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32)\n\t\t\t\tif xr1 - xl1 < 900:\n\t\t\t\t\txr1 = xl1 + 1100\n\t\t\t\tif (xr2+5)-(xl2-5) < 130:\n\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\txr1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\txr1 = xl1 + 1100\n\t\t\t\tif (xr2+5)-(xl2-5) < 130:\n\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\txl2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:\n\t\t\tprint(\"default avg_lines(not detecting lanes)\")\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tvertices_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:\n\t\t\tprint(\"default avg_lines(not detecting lanes)\")\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n                                 [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tvertices_polly_unextd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:\n\t\t\tprint(\"default avg_lines(not detecting lanes)\")\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n                                 [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tavg_lane",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n                                 [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tvertices_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_zero",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcolor_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tline_image_not_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tline_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tline_visualize",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#line_visualize",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tgod",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#god",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#filtered",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tnormal_result",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcombo_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#combo_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_notavg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tim0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''\n\t\tyolov4 + Tensorrt\n\t\t'''\n\t\tboxes, confs, clss = detector.detect(img, conf_th)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''\n\t\tyolov4 + Tensorrt\n\t\t'''\n\t\tboxes, confs, clss = detector.detect(img, conf_th)\n\t\t#yolo_init = boxes\n\t\t#img0 = ez_show(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#yolo_init",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#yolo_init = boxes\n\t\t#img0 = ez_show(img)\n\t\t#img0 = cv2.addWeighted(img0,0.7,img,1,1)\n\t\t'''\n\t\tobject tracking by DeepSort\n\t\t'''\n\t\t#compute width and height of bboxs\n\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img0 = ez_show(img)\n\t\t#img0 = cv2.addWeighted(img0,0.7,img,1,1)\n\t\t'''\n\t\tobject tracking by DeepSort\n\t\t'''\n\t\t#compute width and height of bboxs\n\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img0 = cv2.addWeighted(img0,0.7,img,1,1)\n\t\t'''\n\t\tobject tracking by DeepSort\n\t\t'''\n\t\t#compute width and height of bboxs\n\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\toutput",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")\n\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")\n\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")\n\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\toutputs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tclss",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tcls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tcls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :\n\t\t\t#print(xc,\"xc\")\n\t\t\t#outputs.astype(int)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#f",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :\n\t\t\t#print(xc,\"xc\")\n\t\t\t#outputs.astype(int)\n\t\t\t#print(\"before x1 y1......\",outputs)\n\t\t\tfor x1,y1,x2,y2,ids in outputs:\n\t\t\t\txmin = x1",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txmin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\txmin = x1\n\t\t\t\tymin = y2\n\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tymin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tymin = y2\n\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tlow_mid",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tlow_left",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcenter",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#cent",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw_tim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#xc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#yc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tx_res_yc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")\n\t\t\t\tprint(\"w_list:\\n\",w_list,\"\\n\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tx_res_y",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")\n\t\t\t\tprint(\"w_list:\\n\",w_list,\"\\n\")\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tpol",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")\n\t\t\t\tprint(\"w_list:\\n\",w_list,\"\\n\")\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#cent",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))\n\t\t\t\t\tif abs(pt[ids][j][1] - pt[ids][j-1][1]) < 10 :\n\t\t\t\t\t\t#print(\"in abs!!!!!!\",(pt[ids][j-1]) , (pt[ids][j]))\n\t\t\t\t\t\tcv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\tif len(pt[ids]) > 5:\n\t\t\t\t\t\tif j%5 == 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#cent",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))\n\t\t\t\t\tif abs(pt[ids][j][1] - pt[ids][j-1][1]) < 10 :\n\t\t\t\t\t\t#print(\"in abs!!!!!!\",(pt[ids][j-1]) , (pt[ids][j]))\n\t\t\t\t\t\tcv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\tif len(pt[ids]) > 5:\n\t\t\t\t\t\tif j%5 == 0:\n\t\t\t\t\t\t\t#motion = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#motion",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#motion = True\n\t\t\t\t\t\t\t#x_dir_avg = np.average(x_dir)\n\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#x_dir_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#x_dir_avg = np.average(x_dir)\n\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#y_dir_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#parameters_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tx_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\ty_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t#x_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\ty_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tparameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx_res_y2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tmotion_predict",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#x1,y1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#x2,y2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):\n\t\t\t\t\t#print(\"len(w_list[ids]) :\",len(w_list[ids]),\"; i :\",i)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):\n\t\t\t\t\t#print(\"len(w_list[ids]) :\",len(w_list[ids]),\"; i :\",i)\n\t\t\t\t\t#print(\"k in for loop\",k)\n\t\t\t\t\t#i+=2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\twidth_curr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\twidth_curr = w_list[ids][i][0]\n\t\t\t\t\tif i%5 ==0 and k+1 <= i and len(w_list[ids]) > 5:  #sample every 3 points\n\t\t\t\t\t\t#print(\"k in if statement\",k)\n\t\t\t\t\t\twidth_1 = (w_list[ids][k-1][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_1 = (w_list[ids][k-1][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#width_curr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_passed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_car2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_car1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_diff_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tcar_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {int(car_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {int(car_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike\n\t\t\t\t\t\t\tif name == \"motorbike\" or name ==\"\":\n\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tputtext_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {int(car_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike\n\t\t\t\t\t\t\tif name == \"motorbike\" or name ==\"\":\n\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_diff_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tmoto_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tavg_spd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tputtext_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_passed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_car2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_car1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_diff_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tcar_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tputtext_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_moto1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_moto2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_diff_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tmoto_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tputtext_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#k",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tk",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 1.25 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcar_imptim_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcar_imptim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tmoto_imptim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tmoto_imptim_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args is not None:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args is not None:\n\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= danger({args.danger_dist}) -> DANGER\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t# immediate threshold check per-object to ensure flags are set\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args is not None:\n\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=car dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tused",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tprint(\"time",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\t# placeholder for additional car logic\n\t\t\t\t\t\tpass",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tbad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\t# placeholder for additional car logic\n\t\t\t\t\t\tpass\n\t\t\t\t\t#f.insert(0,(xc,yc))\n\t\t\t\t\t#print(\"car center lsit :  \",f)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\t# placeholder for additional car logic\n\t\t\t\t\t\tpass\n\t\t\t\t\t#f.insert(0,(xc,yc))\n\t\t\t\t\t#print(\"car center lsit :  \",f)\n\t\t\t\tif cls == \"motorbike\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = Distance_finder(85,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tprint(\"distance\",dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr \n\t\t\t\t\t# immediate threshold check for motorbike\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args is not None:\n\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tprint(\"distance\",dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr \n\t\t\t\t\t# immediate threshold check for motorbike\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif args is not None:\n\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= danger({args.danger_dist}) -> DANGER\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t# -- distance-based alerts (configurable thresholds)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= danger({args.danger_dist}) -> DANGER\")\n\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t# -- distance-based alerts (configurable thresholds)\n\t\t\t\ttry:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t# -- distance-based alerts (configurable thresholds)\n\t\t\t\ttry:\n\t\t\t\t\tif args is not None:\n\t\t\t\t\t\t# if we have a detected class and distance, override/augment warning state\n\t\t\t\t\t\tif cls == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\t\t\tprint(f\"[DBG] frame={framenumber} id={ids} class=motorbike dis={dis} <= unsafe({args.unsafe_dist}) -> MEDIUM\")\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tpass\n\t\t\t\t# -- distance-based alerts (configurable thresholds)\n\t\t\t\ttry:\n\t\t\t\t\tif args is not None:\n\t\t\t\t\t\t# if we have a detected class and distance, override/augment warning state\n\t\t\t\t\t\tif cls == \"car\":\n\t\t\t\t\t\t\tif 'dis' in locals():",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tif cls == \"motorbike\":\n\t\t\t\t\t\t\tif 'dis' in locals():\n\t\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tif cls == \"motorbike\":\n\t\t\t\t\t\t\tif 'dis' in locals():\n\t\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tif cls == \"motorbike\":\n\t\t\t\t\t\t\tif 'dis' in locals():\n\t\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tif cls == \"motorbike\":\n\t\t\t\t\t\t\tif 'dis' in locals():\n\t\t\t\t\t\t\t\tif dis <= args.danger_dist:\n\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\t\t\t\telif dis <= args.unsafe_dist:\n\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tdanger_v = False\n\t\t\t\texcept Exception:\n\t\t\t\t\t# ignore any thresholding errors\n\t\t\t\t\tpass\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tused",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tprint(\"time",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tbad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :\n\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :\n\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr                           ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr                           \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"time start {time_start}  time end {time_end}\",  (100, 500), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t#m.insert(0,(xc,yc))\n\t\t\t\t\t\t\t#print(\"motorbike center list:  \",m)\n\t\t\t\t'''\n\t\t\t\tsafety zone\n\t\t\t\t=============",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#unsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#unsafe = True\n\t\t\t\t\tprint(\"satis1\")\n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img1 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img1 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tunsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:\n\t\t\t\t\t#mylcd.lcd_display_string(\"dangerous!\",  2,3)\n\t\t\t\t\t#buzz(unsafe_v)\n\t\t\t\t\tprint(\"satis3\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:\n\t\t\t\t\t#mylcd.lcd_display_string(\"dangerous!\",  2,3)\n\t\t\t\t\t#buzz(unsafe_v)\n\t\t\t\t\tprint(\"satis3\")\n\t\t\t\t\t#danger = True #dangerous\n\t\t\t\t\t#unsafe = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#danger",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#danger = True #dangerous\n\t\t\t\t\t#unsafe = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"dangerous!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr\n\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#unsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#unsafe = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"dangerous!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr\n\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img3",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdanger",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tunsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img4",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tbbox_xyxy",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tidentities",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\timg_final",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timgx",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\treal_result",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\t# Persistent top-right status banner: SAFE / MEDIUM / DANGER\n\t\t# This is drawn every frame so the state is always visible in the window and saved video.\n\t\ttry:\n\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\toverlay",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\toverlay = img_better_look.copy()\n\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\talpha",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\talpha = 0.55\n\t\t\t# banner size and position (top-right)\n\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_w",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tbanner_w = 380\n\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tbanner_h",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tbanner_h = 70\n\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tpad = 20\n\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tx1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tx1 = img_better_look.shape[1] - banner_w - pad\n\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\ty1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\ty1 = pad\n\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tx2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tx2 = img_better_look.shape[1] - pad\n\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\ty2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\ty2 = pad + banner_h\n\t\t\t# choose color and text based on state\n\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tstatus_text",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tstatus_text = \"SAFE\"\n\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\tcv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tcolor",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tcolor = (0, 255, 0)  # green\n\t\t\tif danger_v:\n\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\tcv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus_text",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tstatus_text = \"DANGER\"\n\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\tcv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\tcv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcolor",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tcolor = (0, 0, 255)  # red\n\t\t\telif unsafe_v:\n\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\tcv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\tcv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner\n\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus_text",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tstatus_text = \"MEDIUM\"\n\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\tcv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\tcv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner\n\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX\n\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcolor",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tcolor = (0, 127, 255)  # orange\n\t\t\t# draw filled rounded rectangle (approx) on overlay\n\t\t\tcv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n\t\t\t# blend overlay\n\t\t\tcv2.addWeighted(overlay, alpha, img_better_look, 1 - alpha, 0, img_better_look)\n\t\t\t# draw text right-aligned within banner\n\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX\n\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfont",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfont = cv2.FONT_HERSHEY_DUPLEX\n\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)\n\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\tcv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfont_scale",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfont_scale = 1.2\n\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)\n\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\tcv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tthickness",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tthickness = 3\n\t\t\t(text_w, text_h), _ = cv2.getTextSize(status_text, font, font_scale, thickness)\n\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\tcv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear\n\t\ttry:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_x",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\ttext_x = x2 - 20 - text_w\n\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\tcv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear\n\t\ttry:\n\t\t\tif danger_v:\n\t\t\t\tstatus = 'DANGER'",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\ttext_y",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\ttext_y = y1 + (banner_h + text_h) // 2\n\t\t\tcv2.putText(img_better_look, status_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n\t\texcept Exception:\n\t\t\t# If overlay drawing fails for any reason, keep running without crashing\n\t\t\tpass\n\t\t# Log status changes (only when state changes) so we can debug why alerts may not appear\n\t\ttry:\n\t\t\tif danger_v:\n\t\t\t\tstatus = 'DANGER'\n\t\t\telif unsafe_v:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tstatus = 'DANGER'\n\t\t\telif unsafe_v:\n\t\t\t\tstatus = 'MEDIUM'\n\t\t\telse:\n\t\t\t\tstatus = 'SAFE'\n\t\t\tif status != prev_status:\n\t\t\t\tprint(f\"[ALERT] frame={framenumber} status={status} unsafe_v={unsafe_v} danger_v={danger_v}\")\n\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tstatus = 'MEDIUM'\n\t\t\telse:\n\t\t\t\tstatus = 'SAFE'\n\t\t\tif status != prev_status:\n\t\t\t\tprint(f\"[ALERT] frame={framenumber} status={status} unsafe_v={unsafe_v} danger_v={danger_v}\")\n\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass\n\t\t# Add center flashing alert for danger\n\t\tif danger_v:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstatus",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tstatus = 'SAFE'\n\t\t\tif status != prev_status:\n\t\t\t\tprint(f\"[ALERT] frame={framenumber} status={status} unsafe_v={unsafe_v} danger_v={danger_v}\")\n\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass\n\t\t# Add center flashing alert for danger\n\t\tif danger_v:\n\t\t\t# Flash by alternating color\n\t\t\tflash_color = (0, 0, 255) if (framenumber // 10) % 2 == 0 else (255, 255, 255)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tprev_status",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tprev_status = status\n\t\texcept Exception:\n\t\t\tpass\n\t\t# Add center flashing alert for danger\n\t\tif danger_v:\n\t\t\t# Flash by alternating color\n\t\t\tflash_color = (0, 0, 255) if (framenumber // 10) % 2 == 0 else (255, 255, 255)\n\t\t\tcv2.putText(img_better_look, \"DANGER!\", (320, 240), cv2.FONT_HERSHEY_DUPLEX, 2.0, flash_color, 5, cv2.LINE_AA)\n\t\t\tprint(f\"[ALERT] Center danger alert displayed frame={framenumber}\")\n\t\tout.write(line_visualize)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tflash_color",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tflash_color = (0, 0, 255) if (framenumber // 10) % 2 == 0 else (255, 255, 255)\n\t\t\tcv2.putText(img_better_look, \"DANGER!\", (320, 240), cv2.FONT_HERSHEY_DUPLEX, 2.0, flash_color, 5, cv2.LINE_AA)\n\t\t\tprint(f\"[ALERT] Center danger alert displayed frame={framenumber}\")\n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)\n\t\t####\n\t\t#cv2.imshow(\"normal lanedetection without extended\",normal_result)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttoc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttoc = time.time()\n\t\tcurr_fps = 1.0 / (toc - tic)\n\t\t# calculate an exponentially decaying average of fps number\n\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcurr_fps",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcurr_fps = 1.0 / (toc - tic)\n\t\t# calculate an exponentially decaying average of fps number\n\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tfps",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttic",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()\n\t########",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tkey",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfull_scrn",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):\n\t\t\traise SystemExit('ERROR: file (yolo/%s.trt) not found!' % args.model)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcfg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):\n\t\t\traise SystemExit('ERROR: file (yolo/%s.trt) not found!' % args.model)\n\tcam = Camera(args)\n\tif not cam.isOpened():",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcam",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcam = Camera(args)\n\tif not cam.isOpened():\n\t\traise SystemExit('ERROR: failed to open camera!')\n\t########    \n\ttracker = Tracker_tiny(cfg) \n\t########\n\tcls_dict = get_cls_dict(args.category_num)\n\tif args.use_opencv:\n\t\t# Default input shape for OpenCV YOLO\n\t\th = w = 416",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ttracker",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ttracker = Tracker_tiny(cfg) \n\t########\n\tcls_dict = get_cls_dict(args.category_num)\n\tif args.use_opencv:\n\t\t# Default input shape for OpenCV YOLO\n\t\th = w = 416\n\telse:\n\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcls_dict",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcls_dict = get_cls_dict(args.category_num)\n\tif args.use_opencv:\n\t\t# Default input shape for OpenCV YOLO\n\t\th = w = 416\n\telse:\n\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\th = w = 416\n\telse:\n\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\t\telse:\n\t\t\th = w = int(yolo_dim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tyolo_dim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tyolo_dim = args.model.split('-')[-1]\n\t\tif 'x' in yolo_dim:\n\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\t\telse:\n\t\t\th = w = int(yolo_dim)\n\t\tif h % 32 != 0 or w % 32 != 0:\n\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tdim_split",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tdim_split = yolo_dim.split('x')\n\t\t\tif len(dim_split) != 2:\n\t\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\t\telse:\n\t\t\th = w = int(yolo_dim)\n\t\tif h % 32 != 0 or w % 32 != 0:\n\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\tif args.use_opencv:\n\t\t# Use OpenCV DNN fallback on CPU",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\th = w = int(yolo_dim)\n\t\tif h % 32 != 0 or w % 32 != 0:\n\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\tif args.use_opencv:\n\t\t# Use OpenCV DNN fallback on CPU\n\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttrt_yolo",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tvis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis, args=args)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    }
]