[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "torch.backends.cudnn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.backends.cudnn",
        "description": "torch.backends.cudnn",
        "detail": "torch.backends.cudnn",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Net",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "Net",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "scipy.linalg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "linear_sum_assignment",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "tensorrt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorrt",
        "description": "tensorrt",
        "detail": "tensorrt",
        "documentation": {}
    },
    {
        "label": "common",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "common",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils.data_processing",
        "description": "utils.data_processing",
        "isExtraImport": true,
        "detail": "utils.data_processing",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils.draw",
        "description": "utils.draw",
        "isExtraImport": true,
        "detail": "utils.draw",
        "documentation": {}
    },
    {
        "label": "build_tracker",
        "importPath": "deep_sort",
        "description": "deep_sort",
        "isExtraImport": true,
        "detail": "deep_sort",
        "documentation": {}
    },
    {
        "label": "build_tracker",
        "importPath": "deep_sort",
        "description": "deep_sort",
        "isExtraImport": true,
        "detail": "deep_sort",
        "documentation": {}
    },
    {
        "label": "build_tracker",
        "importPath": "deep_sort",
        "description": "deep_sort",
        "isExtraImport": true,
        "detail": "deep_sort",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "isExtraImport": true,
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "isExtraImport": true,
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "isExtraImport": true,
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "queue",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "queue",
        "description": "queue",
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "BaseHTTPRequestHandler",
        "importPath": "http.server",
        "description": "http.server",
        "isExtraImport": true,
        "detail": "http.server",
        "documentation": {}
    },
    {
        "label": "HTTPServer",
        "importPath": "http.server",
        "description": "http.server",
        "isExtraImport": true,
        "detail": "http.server",
        "documentation": {}
    },
    {
        "label": "ThreadingMixIn",
        "importPath": "socketserver",
        "description": "socketserver",
        "isExtraImport": true,
        "detail": "socketserver",
        "documentation": {}
    },
    {
        "label": "pytrt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytrt",
        "description": "pytrt",
        "detail": "pytrt",
        "documentation": {}
    },
    {
        "label": "append",
        "importPath": "numpy.lib.function_base",
        "description": "numpy.lib.function_base",
        "isExtraImport": true,
        "detail": "numpy.lib.function_base",
        "documentation": {}
    },
    {
        "label": "ctypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ctypes",
        "description": "ctypes",
        "detail": "ctypes",
        "documentation": {}
    },
    {
        "label": "pycuda.driver",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycuda.driver",
        "description": "pycuda.driver",
        "detail": "pycuda.driver",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "pycuda.autoinit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycuda.autoinit",
        "description": "pycuda.autoinit",
        "detail": "pycuda.autoinit",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "expit",
        "importPath": "scipy.special",
        "description": "scipy.special",
        "isExtraImport": true,
        "detail": "scipy.special",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "EasyDict",
        "importPath": "easydict",
        "description": "easydict",
        "isExtraImport": true,
        "detail": "easydict",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "isExtraImport": true,
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "isExtraImport": true,
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "TrtYOLO",
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "isExtraImport": true,
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "isExtraImport": true,
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "importPath": "utils.camera",
        "description": "utils.camera",
        "isExtraImport": true,
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "Camera",
        "importPath": "utils.camera",
        "description": "utils.camera",
        "isExtraImport": true,
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_window",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "set_display",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_fps",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "BBoxVisualization",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "isExtraImport": true,
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "features = torch.load(\"features.pth\")\nqf = features[\"qf\"]\nql = features[\"ql\"]\ngf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "qf",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "qf = features[\"qf\"]\nql = features[\"ql\"]\ngf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "ql",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "ql = features[\"ql\"]\ngf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "gf",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "gf = features[\"gf\"]\ngl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "gl",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "gl = features[\"gl\"]\nscores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "scores",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "scores = qf.mm(gf.t())\nres = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "res",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "res = scores.topk(5, dim=1)[1][:,0]\ntop1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "top1correct",
        "kind": 5,
        "importPath": "deep_sort.deep.evaluate",
        "description": "deep_sort.deep.evaluate",
        "peekOfCode": "top1correct = gl[res].eq(ql).sum().item()\nprint(\"Acc top1:{:.3f}\".format(top1correct/ql.size(0)))",
        "detail": "deep_sort.deep.evaluate",
        "documentation": {}
    },
    {
        "label": "Extractor",
        "kind": 6,
        "importPath": "deep_sort.deep.feature_extractor",
        "description": "deep_sort.deep.feature_extractor",
        "peekOfCode": "class Extractor(object):\n    def __init__(self, model_path, use_cuda=True):\n        self.net = Net(reid=True)\n        self.device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\n        state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)['net_dict']\n        self.net.load_state_dict(state_dict)\n        print(\"Loading weights from {}... Done!\".format(model_path))\n        self.net.to(self.device)\n        self.size = (64, 128)\n        self.norm = transforms.Compose([",
        "detail": "deep_sort.deep.feature_extractor",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "deep_sort.deep.model",
        "description": "deep_sort.deep.model",
        "peekOfCode": "class BasicBlock(nn.Module):\n    def __init__(self, c_in, c_out,is_downsample=False):\n        super(BasicBlock,self).__init__()\n        self.is_downsample = is_downsample\n        if is_downsample:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=2, padding=1, bias=False)\n        else:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(c_out)\n        self.relu = nn.ReLU(True)",
        "detail": "deep_sort.deep.model",
        "documentation": {}
    },
    {
        "label": "Net",
        "kind": 6,
        "importPath": "deep_sort.deep.model",
        "description": "deep_sort.deep.model",
        "peekOfCode": "class Net(nn.Module):\n    def __init__(self, num_classes=751 ,reid=False):\n        super(Net,self).__init__()\n        # 3 128 64\n        self.conv = nn.Sequential(\n            nn.Conv2d(3,64,3,stride=1,padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(32,32,3,stride=1,padding=1),\n            # nn.BatchNorm2d(32),",
        "detail": "deep_sort.deep.model",
        "documentation": {}
    },
    {
        "label": "make_layers",
        "kind": 2,
        "importPath": "deep_sort.deep.model",
        "description": "deep_sort.deep.model",
        "peekOfCode": "def make_layers(c_in,c_out,repeat_times, is_downsample=False):\n    blocks = []\n    for i in range(repeat_times):\n        if i ==0:\n            blocks += [BasicBlock(c_in,c_out, is_downsample=is_downsample),]\n        else:\n            blocks += [BasicBlock(c_out,c_out),]\n    return nn.Sequential(*blocks)\nclass Net(nn.Module):\n    def __init__(self, num_classes=751 ,reid=False):",
        "detail": "deep_sort.deep.model",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "deep_sort.deep.original_model",
        "description": "deep_sort.deep.original_model",
        "peekOfCode": "class BasicBlock(nn.Module):\n    def __init__(self, c_in, c_out,is_downsample=False):\n        super(BasicBlock,self).__init__()\n        self.is_downsample = is_downsample\n        if is_downsample:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=2, padding=1, bias=False)\n        else:\n            self.conv1 = nn.Conv2d(c_in, c_out, 3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(c_out)\n        self.relu = nn.ReLU(True)",
        "detail": "deep_sort.deep.original_model",
        "documentation": {}
    },
    {
        "label": "Net",
        "kind": 6,
        "importPath": "deep_sort.deep.original_model",
        "description": "deep_sort.deep.original_model",
        "peekOfCode": "class Net(nn.Module):\n    def __init__(self, num_classes=625 ,reid=False):\n        super(Net,self).__init__()\n        # 3 128 64\n        self.conv = nn.Sequential(\n            nn.Conv2d(3,32,3,stride=1,padding=1),\n            nn.BatchNorm2d(32),\n            nn.ELU(inplace=True),\n            nn.Conv2d(32,32,3,stride=1,padding=1),\n            nn.BatchNorm2d(32),",
        "detail": "deep_sort.deep.original_model",
        "documentation": {}
    },
    {
        "label": "make_layers",
        "kind": 2,
        "importPath": "deep_sort.deep.original_model",
        "description": "deep_sort.deep.original_model",
        "peekOfCode": "def make_layers(c_in,c_out,repeat_times, is_downsample=False):\n    blocks = []\n    for i in range(repeat_times):\n        if i ==0:\n            blocks += [BasicBlock(c_in,c_out, is_downsample=is_downsample),]\n        else:\n            blocks += [BasicBlock(c_out,c_out),]\n    return nn.Sequential(*blocks)\nclass Net(nn.Module):\n    def __init__(self, num_classes=625 ,reid=False):",
        "detail": "deep_sort.deep.original_model",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "parser = argparse.ArgumentParser(description=\"Train on market1501\")\nparser.add_argument(\"--data-dir\",default='data',type=str)\nparser.add_argument(\"--no-cuda\",action=\"store_true\")\nparser.add_argument(\"--gpu-id\",default=0,type=int)\nargs = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loader",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "args = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loader\nroot = args.data_dir\nquery_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "device = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loader\nroot = args.data_dir\nquery_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "root = args.data_dir\nquery_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "query_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "query_dir = os.path.join(root,\"query\")\ngallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "gallery_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "gallery_dir = os.path.join(root,\"gallery\")\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False\n)",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nqueryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\ngalleryloader = torch.utils.data.DataLoader(",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "queryloader",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "queryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(query_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\ngalleryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(gallery_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\n# net definition\nnet = Net(reid=True)",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "galleryloader",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "galleryloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(gallery_dir, transform=transform),\n    batch_size=64, shuffle=False\n)\n# net definition\nnet = Net(reid=True)\nassert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\nprint('Loading from checkpoint/ckpt.t7')\ncheckpoint = torch.load(\"./checkpoint/ckpt.t7\")\nnet_dict = checkpoint['net_dict']",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "net = Net(reid=True)\nassert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\nprint('Loading from checkpoint/ckpt.t7')\ncheckpoint = torch.load(\"./checkpoint/ckpt.t7\")\nnet_dict = checkpoint['net_dict']\nnet.load_state_dict(net_dict, strict=False)\nnet.eval()\nnet.to(device)\n# compute features\nquery_features = torch.tensor([]).float()",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "checkpoint",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\nnet_dict = checkpoint['net_dict']\nnet.load_state_dict(net_dict, strict=False)\nnet.eval()\nnet.to(device)\n# compute features\nquery_features = torch.tensor([]).float()\nquery_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "net_dict",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "net_dict = checkpoint['net_dict']\nnet.load_state_dict(net_dict, strict=False)\nnet.eval()\nnet.to(device)\n# compute features\nquery_features = torch.tensor([]).float()\nquery_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "query_features",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "query_features = torch.tensor([]).float()\nquery_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "query_labels",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "query_labels = torch.tensor([]).long()\ngallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))\n    for idx,(inputs,labels) in enumerate(galleryloader):",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "gallery_features",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "gallery_features = torch.tensor([]).float()\ngallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))\n    for idx,(inputs,labels) in enumerate(galleryloader):\n        inputs = inputs.to(device)",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "gallery_labels",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "gallery_labels = torch.tensor([]).long()\nwith torch.no_grad():\n    for idx,(inputs,labels) in enumerate(queryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()\n        query_features = torch.cat((query_features, features), dim=0)\n        query_labels = torch.cat((query_labels, labels))\n    for idx,(inputs,labels) in enumerate(galleryloader):\n        inputs = inputs.to(device)\n        features = net(inputs).cpu()",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "deep_sort.deep.test",
        "description": "deep_sort.deep.test",
        "peekOfCode": "features = {\n    \"qf\": query_features,\n    \"ql\": query_labels,\n    \"gf\": gallery_features,\n    \"gl\": gallery_labels\n}\ntorch.save(features,\"features.pth\")",
        "detail": "deep_sort.deep.test",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0\n    total = 0\n    interval = args.interval\n    start = time.time()\n    for idx, (inputs, labels) in enumerate(trainloader):",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0.\n    correct = 0\n    total = 0\n    start = time.time()\n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(testloader):\n            inputs, labels = inputs.to(device), labels.to(device)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "draw_curve",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)\n    ax0.plot(x_epoch, record['train_loss'], 'bo-', label='train')\n    ax0.plot(x_epoch, record['test_loss'], 'ro-', label='val')\n    ax1.plot(x_epoch, record['train_err'], 'bo-', label='train')",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "lr_decay",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def lr_decay():\n    global optimizer\n    for params in optimizer.param_groups:\n        params['lr'] *= 0.1\n        lr = params['lr']\n        print(\"Learning rate adjusted to {}\".format(lr))\ndef main():\n    for epoch in range(start_epoch, start_epoch+40):\n        train_loss, train_err = train(epoch)\n        test_loss, test_err = test(epoch)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "def main():\n    for epoch in range(start_epoch, start_epoch+40):\n        train_loss, train_err = train(epoch)\n        test_loss, test_err = test(epoch)\n        draw_curve(epoch, train_loss, train_err, test_loss, test_err)\n        if (epoch+1)%20==0:\n            lr_decay()\nif __name__ == '__main__':\n    main()",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "parser = argparse.ArgumentParser(description=\"Train on market1501\")\nparser.add_argument(\"--data-dir\",default='data',type=str)\nparser.add_argument(\"--no-cuda\",action=\"store_true\")\nparser.add_argument(\"--gpu-id\",default=0,type=int)\nparser.add_argument(\"--lr\",default=0.1, type=float)\nparser.add_argument(\"--interval\",'-i',default=20,type=int)\nparser.add_argument('--resume', '-r',action='store_true')\nargs = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "args = parser.parse_args()\n# device\ndevice = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loading\nroot = args.data_dir\ntrain_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "device = \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\nif torch.cuda.is_available() and not args.no_cuda:\n    cudnn.benchmark = True\n# data loading\nroot = args.data_dir\ntrain_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "root = args.data_dir\ntrain_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "train_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "train_dir = os.path.join(root,\"train\")\ntest_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "test_dir",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "test_dir = os.path.join(root,\"test\")\ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "transform_train",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "transform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop((128,64),padding=4),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "transform_test",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "transform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((128,64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntrainloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(train_dir, transform=transform_train),\n    batch_size=64,shuffle=True\n)\ntestloader = torch.utils.data.DataLoader(",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "trainloader",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "trainloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(train_dir, transform=transform_train),\n    batch_size=64,shuffle=True\n)\ntestloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(test_dir, transform=transform_test),\n    batch_size=64,shuffle=True\n)\nnum_classes = len(trainloader.dataset.classes)\n# net definition",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "testloader",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "testloader = torch.utils.data.DataLoader(\n    torchvision.datasets.ImageFolder(test_dir, transform=transform_test),\n    batch_size=64,shuffle=True\n)\nnum_classes = len(trainloader.dataset.classes)\n# net definition\nstart_epoch = 0\nnet = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "num_classes",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "num_classes = len(trainloader.dataset.classes)\n# net definition\nstart_epoch = 0\nnet = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\n    print('Loading from checkpoint/ckpt.t7')\n    checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\n    # import ipdb; ipdb.set_trace()\n    net_dict = checkpoint['net_dict']",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "start_epoch",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "start_epoch = 0\nnet = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\n    print('Loading from checkpoint/ckpt.t7')\n    checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\n    # import ipdb; ipdb.set_trace()\n    net_dict = checkpoint['net_dict']\n    net.load_state_dict(net_dict)\n    best_acc = checkpoint['acc']",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "net = Net(num_classes=num_classes)\nif args.resume:\n    assert os.path.isfile(\"./checkpoint/ckpt.t7\"), \"Error: no checkpoint file found!\"\n    print('Loading from checkpoint/ckpt.t7')\n    checkpoint = torch.load(\"./checkpoint/ckpt.t7\")\n    # import ipdb; ipdb.set_trace()\n    net_dict = checkpoint['net_dict']\n    net.load_state_dict(net_dict)\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), args.lr, momentum=0.9, weight_decay=5e-4)\nbest_acc = 0.\n# train function for each epoch\ndef train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "optimizer = torch.optim.SGD(net.parameters(), args.lr, momentum=0.9, weight_decay=5e-4)\nbest_acc = 0.\n# train function for each epoch\ndef train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0\n    total = 0",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "best_acc",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "best_acc = 0.\n# train function for each epoch\ndef train(epoch):\n    print(\"\\nEpoch : %d\"%(epoch+1))\n    net.train()\n    training_loss = 0.\n    train_loss = 0.\n    correct = 0\n    total = 0\n    interval = args.interval",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "x_epoch",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "x_epoch = []\nrecord = {'train_loss':[], 'train_err':[], 'test_loss':[], 'test_err':[]}\nfig = plt.figure()\nax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "record",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "record = {'train_loss':[], 'train_err':[], 'test_loss':[], 'test_err':[]}\nfig = plt.figure()\nax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "fig = plt.figure()\nax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "ax0",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "ax0 = fig.add_subplot(121, title=\"loss\")\nax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)\n    ax0.plot(x_epoch, record['train_loss'], 'bo-', label='train')",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "ax1",
        "kind": 5,
        "importPath": "deep_sort.deep.train",
        "description": "deep_sort.deep.train",
        "peekOfCode": "ax1 = fig.add_subplot(122, title=\"top1err\")\ndef draw_curve(epoch, train_loss, train_err, test_loss, test_err):\n    global record\n    record['train_loss'].append(train_loss)\n    record['train_err'].append(train_err)\n    record['test_loss'].append(test_loss)\n    record['test_err'].append(test_err)\n    x_epoch.append(epoch)\n    ax0.plot(x_epoch, record['train_loss'], 'bo-', label='train')\n    ax0.plot(x_epoch, record['test_loss'], 'ro-', label='val')",
        "detail": "deep_sort.deep.train",
        "documentation": {}
    },
    {
        "label": "Detection",
        "kind": 6,
        "importPath": "deep_sort.sort.detection",
        "description": "deep_sort.sort.detection",
        "peekOfCode": "class Detection(object):\n    \"\"\"\n    This class represents a bounding box detection in a single image.\n    Parameters\n    ----------\n    tlwh : array_like\n        Bounding box in format `(x, y, w, h)`.\n    confidence : float\n        Detector confidence score.\n    feature : array_like",
        "detail": "deep_sort.sort.detection",
        "documentation": {}
    },
    {
        "label": "iou",
        "kind": 2,
        "importPath": "deep_sort.sort.iou_matching",
        "description": "deep_sort.sort.iou_matching",
        "peekOfCode": "def iou(bbox, candidates):\n    \"\"\"Computer intersection over union.\n    Parameters\n    ----------\n    bbox : ndarray\n        A bounding box in format `(top left x, top left y, width, height)`.\n    candidates : ndarray\n        A matrix of candidate bounding boxes (one per row) in the same format\n        as `bbox`.\n    Returns",
        "detail": "deep_sort.sort.iou_matching",
        "documentation": {}
    },
    {
        "label": "iou_cost",
        "kind": 2,
        "importPath": "deep_sort.sort.iou_matching",
        "description": "deep_sort.sort.iou_matching",
        "peekOfCode": "def iou_cost(tracks, detections, track_indices=None,\n             detection_indices=None):\n    \"\"\"An intersection over union distance metric.\n    Parameters\n    ----------\n    tracks : List[deep_sort.track.Track]\n        A list of tracks.\n    detections : List[deep_sort.detection.Detection]\n        A list of detections.\n    track_indices : Optional[List[int]]",
        "detail": "deep_sort.sort.iou_matching",
        "documentation": {}
    },
    {
        "label": "KalmanFilter",
        "kind": 6,
        "importPath": "deep_sort.sort.kalman_filter",
        "description": "deep_sort.sort.kalman_filter",
        "peekOfCode": "class KalmanFilter(object):\n    \"\"\"\n    A simple Kalman filter for tracking bounding boxes in image space.\n    The 8-dimensional state space\n        x, y, a, h, vx, vy, va, vh\n    contains the bounding box center position (x, y), aspect ratio a, height h,\n    and their respective velocities.\n    Object motion follows a constant velocity model. The bounding box location\n    (x, y, a, h) is taken as direct observation of the state space (linear\n    observation model).",
        "detail": "deep_sort.sort.kalman_filter",
        "documentation": {}
    },
    {
        "label": "chi2inv95",
        "kind": 5,
        "importPath": "deep_sort.sort.kalman_filter",
        "description": "deep_sort.sort.kalman_filter",
        "peekOfCode": "chi2inv95 = {\n    1: 3.8415,\n    2: 5.9915,\n    3: 7.8147,\n    4: 9.4877,\n    5: 11.070,\n    6: 12.592,\n    7: 14.067,\n    8: 15.507,\n    9: 16.919}",
        "detail": "deep_sort.sort.kalman_filter",
        "documentation": {}
    },
    {
        "label": "min_cost_matching",
        "kind": 2,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "def min_cost_matching(\n        distance_metric, max_distance, tracks, detections, track_indices=None,\n        detection_indices=None):\n    \"\"\"Solve linear assignment problem.\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should\n        return the NxM dimensional cost matrix, where element (i, j) is the",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "matching_cascade",
        "kind": 2,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "def matching_cascade(\n        distance_metric, max_distance, cascade_depth, tracks, detections,\n        track_indices=None, detection_indices=None):\n    \"\"\"Run matching cascade.\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should\n        return the NxM dimensional cost matrix, where element (i, j) is the",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "gate_cost_matrix",
        "kind": 2,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "def gate_cost_matrix(\n        kf, cost_matrix, tracks, detections, track_indices, detection_indices,\n        gated_cost=INFTY_COST, only_position=False):\n    \"\"\"Invalidate infeasible entries in cost matrix based on the state\n    distributions obtained by Kalman filtering.\n    Parameters\n    ----------\n    kf : The Kalman filter.\n    cost_matrix : ndarray\n        The NxM dimensional cost matrix, where N is the number of track indices",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "INFTY_COST",
        "kind": 5,
        "importPath": "deep_sort.sort.linear_assignment",
        "description": "deep_sort.sort.linear_assignment",
        "peekOfCode": "INFTY_COST = 1e+5\ndef min_cost_matching(\n        distance_metric, max_distance, tracks, detections, track_indices=None,\n        detection_indices=None):\n    \"\"\"Solve linear assignment problem.\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should",
        "detail": "deep_sort.sort.linear_assignment",
        "documentation": {}
    },
    {
        "label": "NearestNeighborDistanceMetric",
        "kind": 6,
        "importPath": "deep_sort.sort.nn_matching",
        "description": "deep_sort.sort.nn_matching",
        "peekOfCode": "class NearestNeighborDistanceMetric(object):\n    \"\"\"\n    A nearest neighbor distance metric that, for each target, returns\n    the closest distance to any sample that has been observed so far.\n    Parameters\n    ----------\n    metric : str\n        Either \"euclidean\" or \"cosine\".\n    matching_threshold: float\n        The matching threshold. Samples with larger distance are considered an",
        "detail": "deep_sort.sort.nn_matching",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "kind": 2,
        "importPath": "deep_sort.sort.preprocessing",
        "description": "deep_sort.sort.preprocessing",
        "peekOfCode": "def non_max_suppression(boxes, max_bbox_overlap, scores=None):\n    \"\"\"Suppress overlapping detections.\n    Original code from [1]_ has been adapted to include confidence score.\n    .. [1] http://www.pyimagesearch.com/2015/02/16/\n           faster-non-maximum-suppression-python/\n    Examples\n    --------\n        >>> boxes = [d.roi for d in detections]\n        >>> scores = [d.confidence for d in detections]\n        >>> indices = non_max_suppression(boxes, max_bbox_overlap, scores)",
        "detail": "deep_sort.sort.preprocessing",
        "documentation": {}
    },
    {
        "label": "TrackState",
        "kind": 6,
        "importPath": "deep_sort.sort.track",
        "description": "deep_sort.sort.track",
        "peekOfCode": "class TrackState:\n    \"\"\"\n    Enumeration type for the single target track state. Newly created tracks are\n    classified as `tentative` until enough evidence has been collected. Then,\n    the track state is changed to `confirmed`. Tracks that are no longer alive\n    are classified as `deleted` to mark them for removal from the set of active\n    tracks.\n    \"\"\"\n    Tentative = 1\n    Confirmed = 2",
        "detail": "deep_sort.sort.track",
        "documentation": {}
    },
    {
        "label": "Track",
        "kind": 6,
        "importPath": "deep_sort.sort.track",
        "description": "deep_sort.sort.track",
        "peekOfCode": "class Track:\n    \"\"\"\n    A single target track with state space `(x, y, a, h)` and associated\n    velocities, where `(x, y)` is the center of the bounding box, `a` is the\n    aspect ratio and `h` is the height.\n    Parameters\n    ----------\n    mean : ndarray\n        Mean vector of the initial state distribution.\n    covariance : ndarray",
        "detail": "deep_sort.sort.track",
        "documentation": {}
    },
    {
        "label": "Tracker",
        "kind": 6,
        "importPath": "deep_sort.sort.tracker",
        "description": "deep_sort.sort.tracker",
        "peekOfCode": "class Tracker:\n    \"\"\"\n    This is the multi-target tracker.\n    Parameters\n    ----------\n    metric : nn_matching.NearestNeighborDistanceMetric\n        A distance metric for measurement-to-track association.\n    max_age : int\n        Maximum number of missed misses before a track is deleted.\n    n_init : int",
        "detail": "deep_sort.sort.tracker",
        "documentation": {}
    },
    {
        "label": "DeepSort",
        "kind": 6,
        "importPath": "deep_sort.deep_sort",
        "description": "deep_sort.deep_sort",
        "peekOfCode": "class DeepSort(object):\n    def __init__(self, model_path, max_dist=0.2, min_confidence=0.3, nms_max_overlap=1.0, max_iou_distance=0.7, max_age=70, n_init=3, nn_budget=100, use_cuda=True):\n        self.min_confidence = min_confidence\n        self.nms_max_overlap = nms_max_overlap\n        self.extractor = Extractor(model_path, use_cuda=use_cuda)\n        max_cosine_distance = max_dist\n        nn_budget = 100\n        metric = NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n        self.tracker = Tracker(metric, max_iou_distance=max_iou_distance, max_age=max_age, n_init=n_init)\n    def update(self, bbox_xywh, confidences, ori_img):",
        "detail": "deep_sort.deep_sort",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "deep_sort.deep_sort",
        "description": "deep_sort.deep_sort",
        "peekOfCode": "__all__ = ['DeepSort']\nclass DeepSort(object):\n    def __init__(self, model_path, max_dist=0.2, min_confidence=0.3, nms_max_overlap=1.0, max_iou_distance=0.7, max_age=70, n_init=3, nn_budget=100, use_cuda=True):\n        self.min_confidence = min_confidence\n        self.nms_max_overlap = nms_max_overlap\n        self.extractor = Extractor(model_path, use_cuda=use_cuda)\n        max_cosine_distance = max_dist\n        nn_budget = 100\n        metric = NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n        self.tracker = Tracker(metric, max_iou_distance=max_iou_distance, max_age=max_age, n_init=n_init)",
        "detail": "deep_sort.deep_sort",
        "documentation": {}
    },
    {
        "label": "Tracker",
        "kind": 6,
        "importPath": "tracker.tracker",
        "description": "tracker.tracker",
        "peekOfCode": "class Tracker():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)\n        #---tensorrt----#\n        self.engine = get_engine(engine_file_path)\n        self.context = self.engine.create_execution_context()\n        self.inputs, self.outputs, self.bindings, self.stream = common.allocate_buffers(self.engine)\n        # ---tensorrt----#",
        "detail": "tracker.tracker",
        "documentation": {}
    },
    {
        "label": "get_engine",
        "kind": 2,
        "importPath": "tracker.tracker",
        "description": "tracker.tracker",
        "peekOfCode": "def get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)",
        "detail": "tracker.tracker",
        "documentation": {}
    },
    {
        "label": "TRT_LOGGER",
        "kind": 5,
        "importPath": "tracker.tracker",
        "description": "tracker.tracker",
        "peekOfCode": "TRT_LOGGER = trt.Logger()\ndef get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args",
        "detail": "tracker.tracker",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "kind": 6,
        "importPath": "tracker.tracker_tiny",
        "description": "tracker.tracker_tiny",
        "peekOfCode": "class Tracker_tiny():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)\n        #---tensorrt----#\n        self.engine = get_engine(engine_file_path)\n        self.context = self.engine.create_execution_context()\n        self.inputs, self.outputs, self.bindings, self.stream = common.allocate_buffers(self.engine)\n        # ---tensorrt----#",
        "detail": "tracker.tracker_tiny",
        "documentation": {}
    },
    {
        "label": "get_engine",
        "kind": 2,
        "importPath": "tracker.tracker_tiny",
        "description": "tracker.tracker_tiny",
        "peekOfCode": "def get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker_tiny():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args\n        self.deepsort = build_tracker(cfg, use_cuda=True)",
        "detail": "tracker.tracker_tiny",
        "documentation": {}
    },
    {
        "label": "TRT_LOGGER",
        "kind": 5,
        "importPath": "tracker.tracker_tiny",
        "description": "tracker.tracker_tiny",
        "peekOfCode": "TRT_LOGGER = trt.Logger()\ndef get_engine(engine_file_path):\n    # If a serialized engine exists, use it instead of building an engine.\n    print(\"Reading engine from file {}\".format(engine_file_path))\n    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\nclass Tracker_tiny():\n    def __init__(self, cfg, engine_file_path):\n        self.cfg = cfg\n        # self.args = args",
        "detail": "tracker.tracker_tiny",
        "documentation": {}
    },
    {
        "label": "Camera",
        "kind": 6,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "class Camera():\n    \"\"\"Camera class which supports reading images from theses video sources:\n    1. Image (jpg, png, etc.) file, repeating indefinitely\n    2. Video file\n    3. RTSP (IP CAM)\n    4. USB webcam\n    5. Jetson onboard camera\n    \"\"\"\n    def __init__(self, args):\n        self.args = args",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--image', type=str, default=None,\n                        help='image file name, e.g. dog.jpg')\n    parser.add_argument('--video', type=str, default=None,\n                        help='video file name, e.g. traffic.mp4')\n    parser.add_argument('--video_looping', action='store_true',\n                        help='loop around the video file [False]')\n    parser.add_argument('--rtsp', type=str, default=None,\n                        help=('RTSP H.264 stream, e.g. '",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_cam_rtsp",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def open_cam_rtsp(uri, width, height, latency):\n    \"\"\"Open an RTSP URI (IP CAM).\"\"\"\n    gst_elements = str(subprocess.check_output('gst-inspect-1.0'))\n    if 'omxh264dec' in gst_elements:\n        # Use hardware H.264 decoder on Jetson platforms\n        gst_str = ('rtspsrc location={} latency={} ! '\n                   'rtph264depay ! h264parse ! omxh264dec ! '\n                   'nvvidconv ! '\n                   'video/x-raw, width=(int){}, height=(int){}, '\n                   'format=(string)BGRx ! videoconvert ! '",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_cam_usb",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def open_cam_usb(dev, width, height):\n    \"\"\"Open a USB webcam.\"\"\"\n    if USB_GSTREAMER:\n        gst_str = ('v4l2src device=/dev/video{} ! '\n                   'video/x-raw, width=(int){}, height=(int){} ! '\n                   'videoconvert ! appsink').format(dev, width, height)\n        return cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)\n    else:\n        return cv2.VideoCapture(dev)\ndef open_cam_onboard(width, height):",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_cam_onboard",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def open_cam_onboard(width, height):\n    \"\"\"Open the Jetson onboard camera.\"\"\"\n    gst_elements = str(subprocess.check_output('gst-inspect-1.0'))\n    if 'nvcamerasrc' in gst_elements:\n        # On versions of L4T prior to 28.1, you might need to add\n        # 'flip-method=2' into gst_str below.\n        gst_str = ('nvcamerasrc ! '\n                   'video/x-raw(memory:NVMM), '\n                   'width=(int)2592, height=(int)1458, '\n                   'format=(string)I420, framerate=(fraction)30/1 ! '",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "grab_img",
        "kind": 2,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "def grab_img(cam):\n    \"\"\"This 'grab_img' function is designed to be run in the sub-thread.\n    Once started, this thread continues to grab a new image and put it\n    into the global 'img_handle', until 'thread_running' is set to False.\n    \"\"\"\n    while cam.thread_running:\n        _, cam.img_handle = cam.cap.read()\n        if cam.img_handle is None:\n            #logging.warning('Camera: cap.read() returns None...')\n            break",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "USB_GSTREAMER",
        "kind": 5,
        "importPath": "utils.camera",
        "description": "utils.camera",
        "peekOfCode": "USB_GSTREAMER = True\ndef add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--image', type=str, default=None,\n                        help='image file name, e.g. dog.jpg')\n    parser.add_argument('--video', type=str, default=None,\n                        help='video file name, e.g. traffic.mp4')\n    parser.add_argument('--video_looping', action='store_true',\n                        help='loop around the video file [False]')\n    parser.add_argument('--rtsp', type=str, default=None,",
        "detail": "utils.camera",
        "documentation": {}
    },
    {
        "label": "open_window",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def open_window(window_name, title, width=None, height=None):\n    \"\"\"Open the display window.\"\"\"\n    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n    cv2.setWindowTitle(window_name, title)\n    if width and height:\n        cv2.resizeWindow(window_name, width, height)\ndef show_help_text(img, help_text):\n    \"\"\"Draw help text on image.\"\"\"\n    cv2.putText(img, help_text, (11, 20), cv2.FONT_HERSHEY_PLAIN, 1.0,\n                (32, 32, 32), 4, cv2.LINE_AA)",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_help_text",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def show_help_text(img, help_text):\n    \"\"\"Draw help text on image.\"\"\"\n    cv2.putText(img, help_text, (11, 20), cv2.FONT_HERSHEY_PLAIN, 1.0,\n                (32, 32, 32), 4, cv2.LINE_AA)\n    cv2.putText(img, help_text, (10, 20), cv2.FONT_HERSHEY_PLAIN, 1.0,\n                (240, 240, 240), 1, cv2.LINE_AA)\n    return img\ndef show_fps(img, fps):\n    \"\"\"Draw fps number at top-left corner of the image.\"\"\"\n    font = cv2.FONT_HERSHEY_PLAIN",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "show_fps",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def show_fps(img, fps):\n    \"\"\"Draw fps number at top-left corner of the image.\"\"\"\n    font = cv2.FONT_HERSHEY_PLAIN\n    line = cv2.LINE_AA\n    fps_text = 'FPS: {:.2f}'.format(fps)\n    cv2.putText(img, fps_text, (11, 20), font, 1.0, (32, 32, 32), 4, line)\n    cv2.putText(img, fps_text, (10, 20), font, 1.0, (240, 240, 240), 1, line)\n    return img\ndef set_display(window_name, full_scrn):\n    \"\"\"Set disply window to either full screen or normal.\"\"\"",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "set_display",
        "kind": 2,
        "importPath": "utils.display",
        "description": "utils.display",
        "peekOfCode": "def set_display(window_name, full_scrn):\n    \"\"\"Set disply window to either full screen or normal.\"\"\"\n    if full_scrn:\n        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN,\n                              cv2.WINDOW_FULLSCREEN)\n    else:\n        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN,\n                              cv2.WINDOW_NORMAL)",
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "MjpegHandler",
        "kind": 6,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "class MjpegHandler(BaseHTTPRequestHandler):\n    \"\"\"A simple MJPEG handler which publishes images.\"\"\"\n    def _handle_mjpeg(self):\n        global _MJPEG_QUEUE\n        img = _MJPEG_QUEUE.get()\n        self.send_response(200)\n        self.send_header(\n            'Content-type',\n            'multipart/x-mixed-replace; boundary=--jpgboundary'\n        )",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "ThreadedHTTPServer",
        "kind": 6,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "class ThreadedHTTPServer(ThreadingMixIn, HTTPServer):\n    \"\"\"Handle HTTP requests in a separate thread.\"\"\"\n    # not used...\ndef run_server(server):\n    server.serve_forever()  # this exits when server.shutdown() is called\n    server.socket.shutdown(socket.SHUT_RDWR)\n    server.socket.close()\nclass MjpegServer(object):\n    def __init__(self, init_img=None, ip='', port=8080):\n        # initialize the queue with a dummy image",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "MjpegServer",
        "kind": 6,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "class MjpegServer(object):\n    def __init__(self, init_img=None, ip='', port=8080):\n        # initialize the queue with a dummy image\n        global _MJPEG_QUEUE\n        init_img = init_img if init_img else \\\n                   np.ones((480, 640, 3), np.uint8) * 255  # all white\n        _MJPEG_QUEUE.put(init_img)\n        # create the HTTP server and run it from the child thread\n        self.server = HTTPServer((ip, port), MjpegHandler)\n        self.run_thread = threading.Thread(",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "run_server",
        "kind": 2,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "def run_server(server):\n    server.serve_forever()  # this exits when server.shutdown() is called\n    server.socket.shutdown(socket.SHUT_RDWR)\n    server.socket.close()\nclass MjpegServer(object):\n    def __init__(self, init_img=None, ip='', port=8080):\n        # initialize the queue with a dummy image\n        global _MJPEG_QUEUE\n        init_img = init_img if init_img else \\\n                   np.ones((480, 640, 3), np.uint8) * 255  # all white",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "_MJPEG_QUEUE",
        "kind": 5,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "_MJPEG_QUEUE = queue.Queue(maxsize=2)\n_SLEEP_INTERVAL = 0.1  # update JPG roughly every 0.1 second\nclass MjpegHandler(BaseHTTPRequestHandler):\n    \"\"\"A simple MJPEG handler which publishes images.\"\"\"\n    def _handle_mjpeg(self):\n        global _MJPEG_QUEUE\n        img = _MJPEG_QUEUE.get()\n        self.send_response(200)\n        self.send_header(\n            'Content-type',",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "_SLEEP_INTERVAL",
        "kind": 5,
        "importPath": "utils.mjpeg",
        "description": "utils.mjpeg",
        "peekOfCode": "_SLEEP_INTERVAL = 0.1  # update JPG roughly every 0.1 second\nclass MjpegHandler(BaseHTTPRequestHandler):\n    \"\"\"A simple MJPEG handler which publishes images.\"\"\"\n    def _handle_mjpeg(self):\n        global _MJPEG_QUEUE\n        img = _MJPEG_QUEUE.get()\n        self.send_response(200)\n        self.send_header(\n            'Content-type',\n            'multipart/x-mixed-replace; boundary=--jpgboundary'",
        "detail": "utils.mjpeg",
        "documentation": {}
    },
    {
        "label": "TrtPNet",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtPNet(object):\n    \"\"\"TrtPNet\n    Refer to mtcnn/det1_relu.prototxt for calculation of input/output\n    dimmensions of TrtPNet, as well as input H offsets (for all scales).\n    The output H offsets are merely input offsets divided by stride (2).\n    \"\"\"\n    input_h_offsets  = (0, 216, 370, 478, 556, 610, 648, 676, 696)\n    output_h_offsets = (0, 108, 185, 239, 278, 305, 324, 338, 348)\n    max_n_scales = 9\n    def __init__(self, engine):",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "TrtRNet",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtRNet(object):\n    \"\"\"TrtRNet\n    # Arguments\n        engine: path to the TensorRT engine (det2) file\n    \"\"\"\n    def __init__(self, engine):\n        self.trtnet = pytrt.PyTrtMtcnn(engine,\n                                       (3, 24, 24),\n                                       (2, 1, 1),\n                                       (4, 1, 1))",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "TrtONet",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtONet(object):\n    \"\"\"TrtONet\n    # Arguments\n        engine: path to the TensorRT engine (det3) file\n    \"\"\"\n    def __init__(self, engine):\n        self.trtnet = pytrt.PyTrtMtcnn(engine,\n                                       (3, 48, 48),\n                                       (2, 1, 1),\n                                       (4, 1, 1),",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "TrtMtcnn",
        "kind": 6,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "class TrtMtcnn(object):\n    \"\"\"TrtMtcnn\"\"\"\n    def __init__(self):\n        self.pnet = TrtPNet('mtcnn/det1.engine')\n        self.rnet = TrtRNet('mtcnn/det2.engine')\n        self.onet = TrtONet('mtcnn/det3.engine')\n    def __del__(self):\n        self.onet.destroy()\n        self.rnet.destroy()\n        self.pnet.destroy()",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "convert_to_1x1",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def convert_to_1x1(boxes):\n    \"\"\"Convert detection boxes to 1:1 sizes\n    # Arguments\n        boxes: numpy array, shape (n,5), dtype=float32\n    # Returns\n        boxes_1x1\n    \"\"\"\n    boxes_1x1 = boxes.copy()\n    hh = boxes[:, 3] - boxes[:, 1] + 1.\n    ww = boxes[:, 2] - boxes[:, 0] + 1.",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "crop_img_with_padding",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def crop_img_with_padding(img, box, padding=0):\n    \"\"\"Crop a box from image, with out-of-boundary pixels padded\n    # Arguments\n        img: img as a numpy array, shape (H, W, 3)\n        box: numpy array, shape (5,) or (4,)\n        padding: integer value for padded pixels\n    # Returns\n        cropped_im: cropped image as a numpy array, shape (H, W, 3)\n    \"\"\"\n    img_h, img_w, _ = img.shape",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "nms",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def nms(boxes, threshold, type='Union'):\n    \"\"\"Non-Maximum Supression\n    # Arguments\n        boxes: numpy array [:, 0:5] of [x1, y1, x2, y2, score]'s\n        threshold: confidence/score threshold, e.g. 0.5\n        type: 'Union' or 'Min'\n    # Returns\n        A list of indices indicating the result of NMS\n    \"\"\"\n    if boxes.shape[0] == 0:",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "generate_pnet_bboxes",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def generate_pnet_bboxes(conf, reg, scale, t):\n    \"\"\"\n    # Arguments\n        conf: softmax score (face or not) of each grid\n        reg: regression values of x1, y1, x2, y2 coordinates.\n             The values are normalized to grid width (12) and\n             height (12).\n        scale: scale-down factor with respect to original image\n        t: confidence threshold\n    # Returns",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "generate_rnet_bboxes",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def generate_rnet_bboxes(conf, reg, pboxes, t):\n    \"\"\"\n    # Arguments\n        conf: softmax score (face or not) of each box\n        reg: regression values of x1, y1, x2, y2 coordinates.\n             The values are normalized to box width and height.\n        pboxes: input boxes to RNet\n        t: confidence threshold\n    # Returns\n        boxes: a numpy array of box coordinates and cooresponding",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "generate_onet_outputs",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def generate_onet_outputs(conf, reg_boxes, reg_marks, rboxes, t):\n    \"\"\"\n    # Arguments\n        conf: softmax score (face or not) of each box\n        reg_boxes: regression values of x1, y1, x2, y2\n                   The values are normalized to box width and height.\n        reg_marks: regression values of the 5 facial landmark points\n        rboxes: input boxes to ONet (already converted to 2x1)\n        t: confidence threshold\n    # Returns",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "clip_dets",
        "kind": 2,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "def clip_dets(dets, img_w, img_h):\n    \"\"\"Round and clip detection (x1, y1, ...) values.\n    Note we exclude the last value of 'dets' in computation since\n    it is 'conf'.\n    \"\"\"\n    dets[:, 0:-1] = np.fix(dets[:, 0:-1])\n    evens = np.arange(0, dets.shape[1]-1, 2)\n    odds  = np.arange(1, dets.shape[1]-1, 2)\n    dets[:, evens] = np.clip(dets[:, evens], 0., float(img_w-1))\n    dets[:, odds]  = np.clip(dets[:, odds], 0., float(img_h-1))",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "PIXEL_MEAN",
        "kind": 5,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "PIXEL_MEAN = 127.5\nPIXEL_SCALE = 0.0078125\ndef convert_to_1x1(boxes):\n    \"\"\"Convert detection boxes to 1:1 sizes\n    # Arguments\n        boxes: numpy array, shape (n,5), dtype=float32\n    # Returns\n        boxes_1x1\n    \"\"\"\n    boxes_1x1 = boxes.copy()",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "PIXEL_SCALE",
        "kind": 5,
        "importPath": "utils.mtcnn",
        "description": "utils.mtcnn",
        "peekOfCode": "PIXEL_SCALE = 0.0078125\ndef convert_to_1x1(boxes):\n    \"\"\"Convert detection boxes to 1:1 sizes\n    # Arguments\n        boxes: numpy array, shape (n,5), dtype=float32\n    # Returns\n        boxes_1x1\n    \"\"\"\n    boxes_1x1 = boxes.copy()\n    hh = boxes[:, 3] - boxes[:, 1] + 1.",
        "detail": "utils.mtcnn",
        "documentation": {}
    },
    {
        "label": "select_yellow_white",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def select_yellow_white(img_org):\n    #hsv_img = cv2.cvtColor(img_org, cv2.COLOR_RGB2HLS)\n    hsv_img = cv2.cvtColor(img_org, cv2.COLOR_BGR2HLS)\n    img_hsv = cv2.cvtColor(img_org, cv2.COLOR_BGR2HSV)\n    ## Gen lower mask (0-5) and upper mask (175-180) of RED\n    #these set works well\n    mask1 = cv2.inRange(img_hsv, (0,50,50), (10,255,255))\n    mask2 = cv2.inRange(img_hsv, (170,50,50), (180,255,255))\n    # mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n    # mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "perspective_transformation",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def perspective_transformation(img): \n    #IMAGE_H = 223\n    IMAGE_H = 300\n    IMAGE_W = 1280\n    src = np.float32([[0, IMAGE_H], [1207, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n    #dst = np.float32([[543, IMAGE_H], [711, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n    dst = np.float32([[569, IMAGE_H], [711, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n    #dst = np.float32([[0, IMAGE_H], [1280, IMAGE_H], [0, 0], [1280, 0]])\n    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n    img = img[550:(550+IMAGE_H), 0:IMAGE_W] #crop the image",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "get_vetices",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def get_vetices():\n    new = np.array([[(0, 570), (496, 173), (596, 168), (1278, 400),(1280,960),(0,960)]], dtype=np.int32) #for testing vid01~05 except 02\n    new = np.array([[(117, 955), (496, 473), (596, 468), (1278, 800),(1280,960)]], dtype=np.int32) # testing testingvid-04-truck.avi\n    #new = np.array([[(150, 960), (451, 620), (855, 620), (1280, 810),(1280,960)]], dtype=np.int32)\n    return new\ndef draw_dis_lines(img):\n    img = np.zeros_like(img)\n    #for speed estimation\n    cv2.line(img,(50,614),(1260,614),(0,127,255),3)\n    cv2.line(img,(50,684),(1260,684),(0,127,255),3)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "draw_dis_lines",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def draw_dis_lines(img):\n    img = np.zeros_like(img)\n    #for speed estimation\n    cv2.line(img,(50,614),(1260,614),(0,127,255),3)\n    cv2.line(img,(50,684),(1260,684),(0,127,255),3)\n    #cv2.line(img,(680,614),(680,684),(0,0,255),3)\n    #for \n    cv2.line(img,(640,960),(575,545),(255,255,255),4)  #mid point 640 960\n    cv2.line(img,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n    cv2.line(img,(586,570),(500,570),(255,255,0),4)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "region_of_interest2",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def region_of_interest2(image, vertices):\n    # defining a blank mask to start with\n    mask = np.zeros_like(image)\n    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n    if len(image.shape) > 2:\n        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n        ignore_mask_color = (255,) * channel_count\n    else:\n        ignore_mask_color = 255\n    # filling pixels inside the polygon defined by \"vertices\" with the fill color",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "filterout",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def filterout(image,vertices_polly):\n    zero = np.zeros_like(image)\n    cl = (255,255,255)\n    cv2.fillPoly(zero, vertices_polly, cl)  #BGR\n    filtered_image = cv2.bitwise_and(image, zero)\n    #filtered_image = cv2.bitwise_and(image, mask)\n    return filtered_image\n#god\ndef filterout2(image,vertice,mask):\n    zero = np.zeros_like(image)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "filterout2",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def filterout2(image,vertice,mask):\n    zero = np.zeros_like(image)\n    cl = (255,255,255)\n    cv2.fillPoly(zero, vertice, cl)  #BGR\n    #filtered_image = cv2.bitwise_and(image, zero)\n    filtered_image = cv2.bitwise_and(image, zero)\n    return filtered_image\ndef average_slope_intercept (image, lines):\n    left = []\n    right =[]",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "average_slope_intercep",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def average_slope_intercept (image, lines):\n    left = []\n    right =[]\n    lane = []\n    for line in lines :\n        x1, y1, x2, y2 = line.reshape(4)\n        parameters = np.polyfit((x1,x2),(y1,y2),1)\n        #print(\"parameterssssssssssssss\",parameters)\n        try:\n            slope, intercept = parameters",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "make_coordinates",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def make_coordinates(image, line_parameters):\n    slope, intercept = line_parameters\n    y1 = image.shape[0]\n    y2 = int(y1*(3/5)) #0.6 little bit too short to show the whole profile of vehicle to track\n    #y2 = int(y1*(0.5))\n    #y2 = int(y1*(1/5))  #stretch the line ->very long\n    x1 = int((y1-intercept)/slope)\n    x2 = int((y2-intercept)/slope)\n    return np.array([x1, y1, x2, y2])\n#append left or right lane when missing one  default:missing right lane",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "make_coordinates_append",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def make_coordinates_append(image, line_parameters,left = False):\n    slope, intercept = line_parameters\n    y1 = image.shape[0]\n    y2 = int(y1*(3/5)) #0.6 little bit too short to show the whole profile of vehicle to track\n    #y2 = int(y1*(0.5))\n    #y2 = int(y1*(1/5))  #stretch the line ->very long\n    x1 = int((y1-intercept)/slope)\n    x2 = int((y2-intercept)/slope)\n    apd = np.array([x1+1100, y1, x2+140, y2])\n    return np.array([x1+1100, y1, x2+140, y2]) if left == False else np.array([x1-1100, y1, x2-140, y2])",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "canny",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def canny(frame):\n    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    #reduce noise using gaussian filter \n    blur=cv2.GaussianBlur(gray, (5,5) , 0) #apply 5*5 kernal\n    #Canny edge detection cv2.Canny(image , low_threshold , high_threshold), threshold: \n    canny = cv2.Canny(blur , 50 , 150)\n    return canny\n#for lines without averaging it    \ndef draw_lines1(image , lines):\n    line_image = np.zeros_like(image)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "draw_lines1",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def draw_lines1(image , lines):\n    line_image = np.zeros_like(image)\n    if lines is not None :\n        #print(\"linessssssssss\",lines)\n        for line in lines :\n            #print(\"#####\",line)\n            x1 , y1 , x2 , y2 = line.reshape(4)\n            cv2.line(line_image, (int(x1),int(y1)), (int(x2),int(y2)), (0,255,0), 10)\n    return line_image\ndef draw_lines2(image , lines):",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "draw_lines2",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def draw_lines2(image , lines):\n    line_image = np.zeros_like(image)\n    #print(lines,\"lines in drawwwwwww\")\n    if lines is not None :\n        try:\n            for x1 , y1 , x2 , y2 in lines :\n            #cv2.line(line_image, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0), 10)\n                #print(x1,y1,x2,y2,\"draw arg.............................\")\n                if x1 + y1 + x2 + y2 > 100000000 :\n                    print(\"the value of lines are tooooo big ( in draw_lines2()  )\")",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "lane_detection",
        "kind": 2,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "def lane_detection(frame):\n    vertices_polly = np.array([[(0, 0), (0, 0), (0, 0), (0, 0)]], dtype=np.int32)\n    yellow_white = select_yellow_white(frame)\n    cannyresult = canny(yellow_white)\n    #cannyresult = canny(frame)\n    #get the right vertice automatically\n    vertice = get_vetices(frame)\n    cropped_image , mask = region_of_interest2(cannyresult,vertice)\n    lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n    #print(\"lines\\n\",lines)",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "framenum",
        "kind": 5,
        "importPath": "utils.project_lanedetection",
        "description": "utils.project_lanedetection",
        "peekOfCode": "framenum = -1\ndef lane_detection(frame):\n    vertices_polly = np.array([[(0, 0), (0, 0), (0, 0), (0, 0)]], dtype=np.int32)\n    yellow_white = select_yellow_white(frame)\n    cannyresult = canny(yellow_white)\n    #cannyresult = canny(frame)\n    #get the right vertice automatically\n    vertice = get_vetices(frame)\n    cropped_image , mask = region_of_interest2(cannyresult,vertice)\n    lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5",
        "detail": "utils.project_lanedetection",
        "documentation": {}
    },
    {
        "label": "TrtSSD",
        "kind": 6,
        "importPath": "utils.ssd",
        "description": "utils.ssd",
        "peekOfCode": "class TrtSSD(object):\n    \"\"\"TrtSSD class encapsulates things needed to run TRT SSD.\"\"\"\n    def _load_plugins(self):\n        if trt.__version__[0] < '7':\n            ctypes.CDLL(\"ssd/libflattenconcat.so\")\n        trt.init_libnvinfer_plugins(self.trt_logger, '')\n    def _load_engine(self):\n        TRTbin = 'ssd/TRT_%s.bin' % self.model\n        with open(TRTbin, 'rb') as f, trt.Runtime(self.trt_logger) as runtime:\n            return runtime.deserialize_cuda_engine(f.read())",
        "detail": "utils.ssd",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "kind": 2,
        "importPath": "utils.ssd_classes",
        "description": "utils.ssd_classes",
        "peekOfCode": "def get_cls_dict(model):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if model == 'coco':\n        cls_list = COCO_CLASSES_LIST\n    elif model == 'egohands':\n        cls_list = EGOHANDS_CLASSES_LIST\n    else:\n        raise ValueError('Bad model name')\n    return {i: n for i, n in enumerate(cls_list)}",
        "detail": "utils.ssd_classes",
        "documentation": {}
    },
    {
        "label": "COCO_CLASSES_LIST",
        "kind": 5,
        "importPath": "utils.ssd_classes",
        "description": "utils.ssd_classes",
        "peekOfCode": "COCO_CLASSES_LIST = [\n    'background',  # was 'unlabeled'\n    'person',\n    'bicycle',\n    'car',\n    'motorcycle',\n    'airplane',\n    'bus',\n    'train',\n    'truck',",
        "detail": "utils.ssd_classes",
        "documentation": {}
    },
    {
        "label": "EGOHANDS_CLASSES_LIST",
        "kind": 5,
        "importPath": "utils.ssd_classes",
        "description": "utils.ssd_classes",
        "peekOfCode": "EGOHANDS_CLASSES_LIST = [\n    'background',\n    'hand',\n]\ndef get_cls_dict(model):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if model == 'coco':\n        cls_list = COCO_CLASSES_LIST\n    elif model == 'egohands':\n        cls_list = EGOHANDS_CLASSES_LIST",
        "detail": "utils.ssd_classes",
        "documentation": {}
    },
    {
        "label": "TfSSD",
        "kind": 6,
        "importPath": "utils.ssd_tf",
        "description": "utils.ssd_tf",
        "peekOfCode": "class TfSSD(object):\n    \"\"\"TfSSD class encapsulates things needed to run TensorFlow SSD.\"\"\"\n    def __init__(self, model, input_shape):\n        self.model = model\n        self.input_shape = input_shape\n        # load detection graph\n        ssd_graph = tf.Graph()\n        with ssd_graph.as_default():\n            graph_def = tf.GraphDef()\n            with tf.gfile.GFile('ssd/%s.pb' % model, 'rb') as fid:",
        "detail": "utils.ssd_tf",
        "documentation": {}
    },
    {
        "label": "BBoxVisualization",
        "kind": 6,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "class BBoxVisualization():\n    \"\"\"BBoxVisualization class implements nice drawing of boudning boxes.\n    # Arguments\n      cls_dict: a dictionary used to translate class id to its name.\n    \"\"\"\n    def __init__(self, cls_dict):\n        self.cls_dict = cls_dict\n        self.colors = gen_colors(len(cls_dict))\n    def draw_bboxes(self, img, boxes, confs, clss):\n        \"\"\"Draw detected bounding boxes on the original image.\"\"\"",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "gen_colors",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.\n    \"\"\"\n    import random\n    import colorsys",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "draw_boxed_text",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def draw_boxed_text(img, text, topleft, color):\n    \"\"\"Draw a transluent boxed text in white, overlayed on top of a\n    colored patch surrounded by a black border. FONT, TEXT_SCALE,\n    TEXT_THICKNESS and ALPHA values are constants (fixed) as defined\n    on top.\n    # Arguments\n      img: the input image as a numpy array.\n      text: the text to be drawn.\n      topleft: XY coordinate of the topleft corner of the boxed text.\n      color: color of the patch, i.e. background of the text.",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "ALPHA",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "ALPHA = 0.5\nFONT = cv2.FONT_HERSHEY_PLAIN\nTEXT_SCALE = 1.0\nTEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "FONT",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "FONT = cv2.FONT_HERSHEY_PLAIN\nTEXT_SCALE = 1.0\nTEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "TEXT_SCALE",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "TEXT_SCALE = 1.0\nTEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "TEXT_THICKNESS",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "TEXT_THICKNESS = 1\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "BLACK",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "BLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.\n    \"\"\"",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "WHITE",
        "kind": 5,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "WHITE = (255, 255, 255)\ndef gen_colors(num_colors):\n    \"\"\"Generate different colors.\n    # Arguments\n      num_colors: total number of colors/classes.\n    # Output\n      bgrs: a list of (B, G, R) tuples which correspond to each of\n            the colors/classes.\n    \"\"\"\n    import random",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "get_cls_dict",
        "kind": 2,
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "peekOfCode": "def get_cls_dict(category_num):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if category_num == 80:\n        return {i: n for i, n in enumerate(COCO_CLASSES_LIST)}\n    else:\n        return {i: 'CLS%d' % i for i in range(category_num)}",
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "COCO_CLASSES_LIST",
        "kind": 5,
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "peekOfCode": "COCO_CLASSES_LIST = [\n    'person',\n    'bicycle',\n    'car',\n    'motorbike',\n    'aeroplane',\n    'bus',\n    'train',\n    'truck',\n    'boat',",
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "yolo_cls_to_ssd",
        "kind": 5,
        "importPath": "utils.yolo_classes",
        "description": "utils.yolo_classes",
        "peekOfCode": "yolo_cls_to_ssd = [\n   1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20,\n    21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n    41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n    59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79,\n    80, 81, 82, 84, 85, 86, 87, 88, 89, 90,\n]\ndef get_cls_dict(category_num):\n    \"\"\"Get the class ID to name translation dictionary.\"\"\"\n    if category_num == 80:",
        "detail": "utils.yolo_classes",
        "documentation": {}
    },
    {
        "label": "Tracker_tiny",
        "kind": 6,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "class Tracker_tiny():\n    def __init__(self, cfg):\n        self.cfg = cfg\n        # self.args = args\n\t#\n        self.deepsort = build_tracker(cfg, use_cuda=True)\n        #\n\t#---tensorrt----#\n        # ---tensorrt----#\n        #---input info for yolov3-416------#",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "HostDeviceMem",
        "kind": 6,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "class HostDeviceMem(object):\n    \"\"\"Simple helper data class that's a little nicer to use than a 2-tuple.\"\"\"\n    def __init__(self, host_mem, device_mem):\n        self.host = host_mem\n        self.device = device_mem\n    def __str__(self):\n        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n    def __repr__(self):\n        return self.__str__()\ndef allocate_buffers(engine):",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "TrtYOLO",
        "kind": 6,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "class TrtYOLO(object):\n    \"\"\"TrtYOLO class encapsulates things needed to run TRT YOLO.\"\"\"\n    def _load_engine(self):\n        TRTbin = 'yolo/%s.trt' % self.model\n        with open(TRTbin, 'rb') as f, trt.Runtime(self.trt_logger) as runtime:\n            return runtime.deserialize_cuda_engine(f.read())\n    def __init__(self, model, input_shape, category_num=80, letter_box=False,\n                 cuda_ctx=None):\n        \"\"\"Initialize TensorRT plugins, engine and conetxt.\"\"\"\n        self.model = model",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "allocate_buffers",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def allocate_buffers(engine):\n    \"\"\"Allocates all host/device in/out buffers required for an engine.\"\"\"\n    inputs = []\n    outputs = []\n    bindings = []\n    output_idx = 0\n    stream = cuda.Stream()\n    assert 3 <= len(engine) <= 4  # expect 1 input, plus 2 or 3 outpus\n    for binding in engine:\n        size = trt.volume(engine.get_binding_shape(binding)) * \\",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "do_inference",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n    \"\"\"do_inference (for TensorRT 6.x or lower)\n    This function is generalized for multiple inputs/outputs.\n    Inputs and outputs are expected to be lists of HostDeviceMem objects.\n    \"\"\"\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n    # Run inference.\n    context.execute_async(batch_size=batch_size,\n                          bindings=bindings,",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "do_inference_v2",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def do_inference_v2(context, bindings, inputs, outputs, stream):\n    \"\"\"do_inference_v2 (for TensorRT 7.0+)\n    This function is generalized for multiple inputs/outputs for full\n    dimension networks.\n    Inputs and outputs are expected to be lists of HostDeviceMem objects.\n    \"\"\"\n    start = time.time()\n    print(\"=> time: %.4f\" %(time.time()-start))\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "get_yolo_grid_sizes",
        "kind": 2,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "def get_yolo_grid_sizes(model_name, h, w):\n    \"\"\"Get grid sizes (w*h) for all yolo layers in the model.\"\"\"\n    if 'yolov3' in model_name:\n        if 'tiny' in model_name:\n            return [(h // 32) * (w // 32), (h // 16) * (w // 16)]\n        else:\n            return [(h // 32) * (w // 32), (h // 16) * (w // 16), (h // 8) * (w // 8)]\n    elif 'yolov4' in model_name:\n        if 'tiny' in model_name:\n            return [(h // 32) * (w // 32), (h // 16) * (w // 16)]",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "_platform",
        "kind": 5,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "_platform = platform.system().lower()\nif _platform.startswith('windows'):\n    plugin_name = 'libyolo_layer.dll'\nelse:\n    plugin_name = 'libyolo_layer.so'\nplugin_path = os.path.join('plugins', plugin_name)\ntry:\n    ctypes.cdll.LoadLibrary(plugin_path)\nexcept OSError as e:\n    # Provide a clearer error message depending on platform",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "plugin_path",
        "kind": 5,
        "importPath": "utils.yolo_with_plugins",
        "description": "utils.yolo_with_plugins",
        "peekOfCode": "plugin_path = os.path.join('plugins', plugin_name)\ntry:\n    ctypes.cdll.LoadLibrary(plugin_path)\nexcept OSError as e:\n    # Provide a clearer error message depending on platform\n    if _platform.startswith('windows'):\n        msg = (f\"ERROR: failed to load {plugin_path}.\\n\"\n               \"On Windows you need to build a TensorRT YOLO plugin DLL (e.g. libyolo_layer.dll) \"\n               \"compatible with your TensorRT version.\\n\"\n               \"Typical steps: install TensorRT, CUDA, Visual Studio Build Tools, then build the plugin with CMake/MSBuild.\\n\"",
        "detail": "utils.yolo_with_plugins",
        "documentation": {}
    },
    {
        "label": "VideoWriter",
        "kind": 6,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "class VideoWriter:\n    def __init__(self, width, height, args, fps=24):\n        # type: (str, int, int, int) -> None\n        assert args.output_file.endswith('.mp4'), 'please specify the (.mp4) at the end '\n        # self._name = name\n        # self._height = height\n        # self._width = width\n        self.args = args\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        self.__writer = cv2.VideoWriter(args.output_file, fourcc, fps, (width, height))",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "Camera",
        "kind": 6,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "class Camera():\n    \"\"\"Camera class which supports reading images from theses video sources:\n    1. Video file\n    2. USB webcam\n    3. Jetson onboard camera\n    \"\"\"\n    def __init__(self, args):\n        self.args = args\n        self.is_opened = False\n        self.use_thread = False",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "add_camera_args",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--file', dest='use_file',\n                        help='use a video file as input (remember to '\n                        'also set --filename)',\n                        action='store_true')\n    parser.add_argument('--image', dest='use_image',\n                        help='use an image file as input (remember to '\n                        'also set --filename)',\n                        action='store_true')",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "open_cam_usb",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def open_cam_usb(dev, width, height):\n    \"\"\"Open a USB webcam.\"\"\"\n    if USB_GSTREAMER:\n        gst_str = ('v4l2src device=/dev/video{} ! '\n                   'video/x-raw, width=(int){}, height=(int){} ! '\n                   'videoconvert ! appsink').format(dev, width, height)\n        return cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)\n    else:\n        return cv2.VideoCapture(dev)\ndef open_cam_onboard():",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "open_cam_onboard",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def open_cam_onboard():\n    \"\"\"Open the Jetson onboard camera.\"\"\"\n    gst_str = (\"nvarguscamerasrc ! \"\n        \"video/x-raw(memory:NVMM), \"\n        \"width=(int)1280, height=(int)720, \"\n        \"format=(string)NV12, framerate=(fraction)60/1 ! \"\n        \"nvvidconv flip-method=0 ! \"\n        \"video/x-raw, width=(int)1280, height=(int)720, format=(string)BGRx ! \"\n        \"videoconvert ! \"\n        \"video/x-raw, format=(string)BGR ! appsink\")",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "grab_img",
        "kind": 2,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "def grab_img(cam):\n    \"\"\"This 'grab_img' function is designed to be run in the sub-thread.\n    Once started, this thread continues to grab a new image and put it\n    into the global 'img_handle', until 'thread_running' is set to False.\n    \"\"\"\n    while cam.thread_running:\n        _, cam.img_handle = cam.cap.read()\n        if cam.img_handle is None:\n            logging.warning('grab_img(): cap.read() returns None...')\n            break",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "USB_GSTREAMER",
        "kind": 5,
        "importPath": "utils_deepsort.camera_setting",
        "description": "utils_deepsort.camera_setting",
        "peekOfCode": "USB_GSTREAMER = True\ndef add_camera_args(parser):\n    \"\"\"Add parser augument for camera options.\"\"\"\n    parser.add_argument('--file', dest='use_file',\n                        help='use a video file as input (remember to '\n                        'also set --filename)',\n                        action='store_true')\n    parser.add_argument('--image', dest='use_image',\n                        help='use an image file as input (remember to '\n                        'also set --filename)',",
        "detail": "utils_deepsort.camera_setting",
        "documentation": {}
    },
    {
        "label": "HostDeviceMem",
        "kind": 6,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "class HostDeviceMem(object):\n    def __init__(self, host_mem, device_mem):\n        self.host = host_mem\n        self.device = device_mem\n    def __str__(self):\n        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n    def __repr__(self):\n        return self.__str__()\n# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\ndef allocate_buffers(engine):",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "GiB",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def GiB(val):\n    return val * 1 << 30\ndef find_sample_data(description=\"Runs a TensorRT Python sample\", subfolder=\"\", find_files=[]):\n    '''\n    Parses sample arguments.\n    Args:\n        description (str): Description of the sample.\n        subfolder (str): The subfolder containing data relevant to this sample\n        find_files (str): A list of filenames to find. Each filename will be replaced with an absolute path.\n    Returns:",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "find_sample_data",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def find_sample_data(description=\"Runs a TensorRT Python sample\", subfolder=\"\", find_files=[]):\n    '''\n    Parses sample arguments.\n    Args:\n        description (str): Description of the sample.\n        subfolder (str): The subfolder containing data relevant to this sample\n        find_files (str): A list of filenames to find. Each filename will be replaced with an absolute path.\n    Returns:\n        str: Path of data directory.\n    Raises:",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "allocate_buffers",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def allocate_buffers(engine):\n    inputs = []\n    outputs = []\n    bindings = []\n    stream = cuda.Stream()\n    for binding in engine:\n        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n        dtype = trt.nptype(engine.get_binding_dtype(binding))\n        # Allocate host and device buffers\n        host_mem = cuda.pagelocked_empty(size, dtype)",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "do_inference",
        "kind": 2,
        "importPath": "utils_deepsort.common",
        "description": "utils_deepsort.common",
        "peekOfCode": "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n     start = time.time()\n     print(\"=> time: %.4f\" %(time.time()-start))\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n    # Run inference.\n    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n    # Transfer predictions back from the GPU.\n    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n    # Synchronize the stream",
        "detail": "utils_deepsort.common",
        "documentation": {}
    },
    {
        "label": "PreprocessYOLO",
        "kind": 6,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "class PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):\n        \"\"\"Initialize with the input resolution for YOLOv3, which will stay fixed in this sample.\n        Keyword arguments:\n        yolo_input_resolution -- two-dimensional tuple with the target network's (spatial)\n        input resolution in HW order\n        \"\"\"",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "PostprocessYOLO",
        "kind": 6,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "class PostprocessYOLO(object):\n    \"\"\"Class for post-processing the three outputs tensors from YOLOv3-608.\"\"\"\n    def __init__(self,\n                 yolo_masks,\n                 yolo_anchors,\n                 obj_threshold,\n                 nms_threshold,\n                 yolo_input_resolution):\n        \"\"\"Initialize with all values that will be kept when processing several frames.\n        Assuming 3 outputs of the network in the case of (large) YOLOv3.",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "load_label_categories",
        "kind": 2,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "def load_label_categories(label_file_path):\n    categories = [line.rstrip('\\n') for line in open(label_file_path)]\n    return categories\nLABEL_FILE_PATH = './configs/coco_labels.txt'\nALL_CATEGORIES = load_label_categories(LABEL_FILE_PATH)\n# Let's make sure that there are 80 classes, as expected for the COCO data set:\nCATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "LABEL_FILE_PATH",
        "kind": 5,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "LABEL_FILE_PATH = './configs/coco_labels.txt'\nALL_CATEGORIES = load_label_categories(LABEL_FILE_PATH)\n# Let's make sure that there are 80 classes, as expected for the COCO data set:\nCATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "ALL_CATEGORIES",
        "kind": 5,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "ALL_CATEGORIES = load_label_categories(LABEL_FILE_PATH)\n# Let's make sure that there are 80 classes, as expected for the COCO data set:\nCATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):\n        \"\"\"Initialize with the input resolution for YOLOv3, which will stay fixed in this sample.",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "CATEGORY_NUM",
        "kind": 5,
        "importPath": "utils_deepsort.data_processing",
        "description": "utils_deepsort.data_processing",
        "peekOfCode": "CATEGORY_NUM = len(ALL_CATEGORIES)\nassert CATEGORY_NUM == 80\nclass PreprocessYOLO(object):\n    \"\"\"A simple class for loading images with PIL and reshaping them to the specified\n    input resolution for YOLOv3-608.\n    \"\"\"\n    def __init__(self, yolo_input_resolution):\n        \"\"\"Initialize with the input resolution for YOLOv3, which will stay fixed in this sample.\n        Keyword arguments:\n        yolo_input_resolution -- two-dimensional tuple with the target network's (spatial)",
        "detail": "utils_deepsort.data_processing",
        "documentation": {}
    },
    {
        "label": "compute_color_for_labels",
        "kind": 2,
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "peekOfCode": "def compute_color_for_labels(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the class\n    \"\"\"\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\ndef draw_boxes(img, bbox, identities=None, offset=(0,0)):\n    for i,box in enumerate(bbox):\n        x1,y1,x2,y2 = [int(i) for i in box]\n        x1 += offset[0]",
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "kind": 2,
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "peekOfCode": "def draw_boxes(img, bbox, identities=None, offset=(0,0)):\n    for i,box in enumerate(bbox):\n        x1,y1,x2,y2 = [int(i) for i in box]\n        x1 += offset[0]\n        x2 += offset[0]\n        y1 += offset[1]\n        y2 += offset[1]\n        # box text and bar\n        id = int(identities[i]) if identities is not None else 0    \n        color = compute_color_for_labels(id)",
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "palette",
        "kind": 5,
        "importPath": "utils_deepsort.draw",
        "description": "utils_deepsort.draw",
        "peekOfCode": "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\ndef compute_color_for_labels(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the class\n    \"\"\"\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\ndef draw_boxes(img, bbox, identities=None, offset=(0,0)):\n    for i,box in enumerate(bbox):\n        x1,y1,x2,y2 = [int(i) for i in box]",
        "detail": "utils_deepsort.draw",
        "documentation": {}
    },
    {
        "label": "YamlParser",
        "kind": 6,
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "peekOfCode": "class YamlParser(edict):\n    \"\"\"\n    This is yaml parser based on EasyDict.\n    \"\"\"\n    def __init__(self, cfg_dict=None, config_file=None):\n        if cfg_dict is None:\n            cfg_dict = {}\n        if config_file is not None:\n            assert(os.path.isfile(config_file))\n            with open(config_file, 'r') as fo:",
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "get_config",
        "kind": 2,
        "importPath": "utils_deepsort.parser",
        "description": "utils_deepsort.parser",
        "peekOfCode": "def get_config(config_file=None):\n    return YamlParser(config_file=config_file)\nif __name__ == \"__main__\":\n    # cfg = YamlParser(config_file=\"../configs/yolov3.yaml\")\n    cfg.merge_from_file(\"../configs/deep_sort.yaml\")\n    import ipdb; ipdb.set_trace()",
        "detail": "utils_deepsort.parser",
        "documentation": {}
    },
    {
        "label": "OpenCVYolo",
        "kind": 6,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "class OpenCVYolo:\n\t\"\"\"Simple OpenCV DNN wrapper for YOLO Darknet models.\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the TensorRT TrtYOLO.detect used by this repo.\n\t\"\"\"\n\tdef __init__(self, cfg_path, weights_path, input_shape=(416,416)):\n\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n\t\tself.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "append_speed",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def append_speed(ids,deque_list):\n\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n\t\t#sys.exit()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "compute_xc_yc",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def compute_xc_yc(out):\n\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "dra",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "ez_show",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "Distance_finder",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "motion_cord",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "loop_and_detect",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def loop_and_detect(cam, detector, tracker, conf_th,vis):\n\t\"\"\"Continuously capture images from camera and do object detection.\n\t# Arguments\n\t\tcam: the camera instance (video source).\n\t\ttrt_yolo: the TRT YOLO object detector instance.\n\t\tconf_th: confidence/score threshold for object detection.\n\t\tvis: for visualization.\n\t\"\"\"\n\t# global img_final\n\tfull_scrn = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "def main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "WINDOW_NAME",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "WINDOW_NAME = 'ProjectDemo'\nclass OpenCVYolo:\n\t\"\"\"Simple OpenCV DNN wrapper for YOLO Darknet models.\n\tProvides a .detect(img, conf_th) method that returns boxes, scores, classes\n\twith the same shape/semantics as the TensorRT TrtYOLO.detect used by this repo.\n\t\"\"\"\n\tdef __init__(self, cfg_path, weights_path, input_shape=(416,416)):\n\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tself.net",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tself.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n\t\t# prefer CPU\n\t\tself.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n\t\tself.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n\t\tself.input_shape = input_shape\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\th, w = img.shape[:2]\n\t\tinp_w, inp_h = self.input_shape[1], self.input_shape[0]\n\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tself.input_shape",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tself.input_shape = input_shape\n\tdef detect(self, img, conf_th=0.3, letter_box=False):\n\t\th, w = img.shape[:2]\n\t\tinp_w, inp_h = self.input_shape[1], self.input_shape[0]\n\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)\n\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tblob",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tblob = cv2.dnn.blobFromImage(img, 1/255.0, (inp_w, inp_h), swapRB=True, crop=False)\n\t\tself.net.setInput(blob)\n\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tlayer_names",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tlayer_names = self.net.getLayerNames()\n\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tout_names",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tout_names = [layer_names[i[0]-1] if isinstance(i, (list, tuple, np.ndarray)) else layer_names[i-1]\n\t\t\t\t\t for i in self.net.getUnconnectedOutLayers()]\n\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\touts",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\touts = self.net.forward(out_names)\n\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tclass_ids",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tclass_ids = []\n\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tconfidences",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tconfidences = []\n\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tboxes = []\n\t\tfor out in outs:\n\t\t\tfor detection in out:\n\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tscores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tscores = detection[5:]\n\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tclass_id",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tclass_id = int(np.argmax(scores))\n\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tconfidence",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tconfidence = float(scores[class_id] * detection[4])\n\t\t\t\tif confidence > conf_th:\n\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcenter_x",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcenter_x = int(detection[0] * w)\n\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcenter_y",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcenter_y = int(detection[1] * h)\n\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tbw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tbw = int(detection[2] * w)\n\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tbh",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tbh = int(detection[3] * h)\n\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tx1 = int(center_x - bw / 2)\n\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ty1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\ty1 = int(center_y - bh / 2)\n\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tx2 = x1 + bw\n\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ty2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\ty2 = y1 + bh\n\t\t\t\t\tboxes.append([x1, y1, x2, y2])\n\t\t\t\t\tconfidences.append(confidence)\n\t\t\t\t\tclass_ids.append(class_id)\n\t\t# NMS\n\t\tif len(boxes) > 0:\n\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_th, 0.5)\n\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_boxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered_boxes = []\n\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_scores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered_scores = []\n\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered_classes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered_classes = []\n\t\t\tif isinstance(idxs, (list, tuple)):\n\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tidxs = idxs\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tidxs = idxs.flatten()\n\t\t\t\texcept Exception:\n\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tidxs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tidxs = [int(i) for i in idxs]\n\t\t\tfor i in idxs:\n\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\ti",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\ti = int(i)\n\t\t\t\tfiltered_boxes.append(boxes[i])\n\t\t\t\tfiltered_scores.append(confidences[i])\n\t\t\t\tfiltered_classes.append(class_ids[i])\n\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tboxes = np.array(filtered_boxes, dtype=np.int32)\n\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tscores = np.array(filtered_scores, dtype=np.float32)\n\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tclasses = np.array(filtered_classes, dtype=np.int32)\n\t\telse:\n\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tboxes = np.zeros((0,4), dtype=np.int32)\n\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tscores",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tscores = np.zeros((0,), dtype=np.float32)\n\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tclasses",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tclasses = np.zeros((0,), dtype=np.int32)\n\t\treturn boxes, scores, classes\ndef parse_args():\n\t\"\"\"Parse input arguments.\"\"\"\n\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdesc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdesc = ('Capture and display live camera video, while doing '\n\t\t\t\t\t'real-time object detection with TensorRT optimized '\n\t\t\t\t\t'YOLO model on Jetson')\n\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=True,",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tparser = argparse.ArgumentParser(description=desc)\n\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=True,\n\t\t\thelp=('[yolov3|yolov3-tiny|yolov3-spp|yolov4|yolov4-tiny]-'\n\t\t\t\t\t\t'[{dimension}], where dimension could be a single '\n\t\t\t\t\t\t'number (e.g. 288, 416, 608) or WxH (e.g. 416x256)'))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tparser = add_camera_args(parser)\n\tparser.add_argument(\n\t\t\t'-c', '--category_num', type=int, default=80,\n\t\t\thelp='number of object categories [80]')\n\tparser.add_argument(\n\t\t\t'-m', '--model', type=str, required=True,\n\t\t\thelp=('[yolov3|yolov3-tiny|yolov3-spp|yolov4|yolov4-tiny]-'\n\t\t\t\t\t\t'[{dimension}], where dimension could be a single '\n\t\t\t\t\t\t'number (e.g. 288, 416, 608) or WxH (e.g. 416x256)'))\n\tparser.add_argument(",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\targs = parser.parse_args()\n\treturn args\ndef append_speed(ids,deque_list):\n\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tspeed_list",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tspeed_list = []\n\tfor j in range(0 , len(deque_list[ids]) ):\n\t\tspeed_list.append((deque_list[ids][j]))\n\tif len(deque_list[ids])>10:\n\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n\t\t#sys.exit()\n#fix bbox issues",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tspd_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tspd_avg = np.average(speed_list,axis=0)\n\t\treturn spd_avg\n\telse:\n\t\treturn \"still appending\"\n\t\t#sys.exit()\n#fix bbox issues\ndef compute_xc_yc(out):\n\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tw = out[:,[2]] - out[:,[0]]\n\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\th = out[:,[3]] - out[:,[1]]\n\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\txmin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\txmin = out[:,[0]]\n\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tymin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tymin = out[:,[1]]\n\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\txc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\txc = w/2 + xmin\n\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tyc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tyc = h/2 + ymin \n\treturn xc,yc,w,h\ndef draw (pos,img):\n\tfor poss in pos :\n\t\t#print(\"before error in draw func\",poss)\n\t\tcv2.circle(img, poss, 4, (0, 255,255), -1)\n\t\tcv2.polylines(img,[np.int32(pos)], False, (0,255,255), 1)\ndef ez_show(img):\n\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\timg0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\timg0 = np.zeros_like(img)\n\tcv2.line(img0,(1000,960),(586,570),(255,255,0),3)  #shift 514 pixels\n\tcv2.line(img0,(586,570),(500,570),(255,255,0),4)\n\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tpol",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\tcv2.fillPoly(img0,pol, (0,255,0))\n\treturn img0\ndef Distance_finder(real_width, face_width_in_frame):\t\n\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tFocal_Length",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tFocal_Length = 958\n\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdistance",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdistance = (real_width * Focal_Length)/face_width_in_frame\n\treturn distance    \ndef motion_cord(starting_points,line_parameters):\n\t\tslope, intercept = line_parameters\n\t\tx1 , y1 = starting_points\n\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ty2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ty2 = y1 + 100\n\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)\n#    width = output[:,[2]] - output[:,[0]]\n#    height = output[:,[3]] - output[:,[1]]\n#    width = width/2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#y2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#y2 = y1 + 30 #extended line\n\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)\n#    width = output[:,[2]] - output[:,[0]]\n#    height = output[:,[3]] - output[:,[1]]\n#    width = width/2\n#    height = height/2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tx2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tx2 = int((y2-intercept)/(slope))\n\t\treturn x1, y1, x2, y2\n#def output_right_box (inputs,output):   \n#    id = output[:,[-1]]\n#    xc , yc = compute_xc_yc(inputs)\n#    width = output[:,[2]] - output[:,[0]]\n#    height = output[:,[3]] - output[:,[1]]\n#    width = width/2\n#    height = height/2\n#    xmin = xc - width",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tfull_scrn",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tfull_scrn = False\n\tfps = 0.0\n\ttic = time.time()\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tfps",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tfps = 0.0\n\ttic = time.time()\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ttic",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ttic = time.time()\n\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tf",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tf = [] \n\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tm",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tm = []\n\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tn",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tn = 0\n\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcls = \"\"\n\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tframenumber",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tframenumber = -1\n\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tspeed = \"\"\n\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tk",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tk = 0\n\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#tic",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#tic = 0\n\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ttime_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ttime_start = time_end = 0\n\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdis_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdis_start = dis_end = 0\n\t#create deque container\n\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tpts",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tpts = [deque(maxlen=30) for _ in range(100)]\n\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tpt",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tpt = [deque(maxlen=50) for _ in range(100)]\n\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#h_ls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#h_ls = [deque(maxlen=30) for _ in range(100)]\n\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tw_list",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tw_list = [deque(maxlen=30) for _ in range(100)]\n\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcar_spd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcar_spd = [deque(maxlen=30) for _ in range(50)]\n\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tmoto_spd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tmoto_spd = [deque(maxlen=30) for _ in range(50)]\n\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tunsafe_v = False\n\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdanger_v = False\n\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tused",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tused = False\n\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tlanedetection",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tlanedetection = True #False\n\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tputtext_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tputtext_car = False\n\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tputtext_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tputtext_moto = False\n\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tbad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tbad = False\n\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tmotion_predict",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tmotion_predict = False\n\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdrw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdrw = False\n\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tunsafe_v = False\n\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tdanger_v = False\n\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tavg_spd_moto = \"still appending\"\n\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tavg_spd_car = \"still appending\"\n\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tx_dir",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tx_dir = []\n\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ty_dir",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ty_dir = []\n\t#save output video\n\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#width",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5) \n\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#height",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#size",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#size = (width, height)\n\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tfourcc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#out",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#out = cv2.VideoWriter('output_testingvid03.avi', fourcc, 10.0, (640,  480))\n\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#out2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#out2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tout",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tout = cv2.VideoWriter('line_vis.avi', fourcc, 20.0, (1280,960))\n\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tout1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tout1 = cv2.VideoWriter('final_res.avi', fourcc, 20.0, (1280,  960))\n\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tout2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tout2 = cv2.VideoWriter('combo.avi', fourcc, 20.0, (1280,960))\n\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t#out1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t#out1 = cv2.VideoWriter('deepsort_out4.avi', fourcc, 20.0, (1280,  960))\n\t##\n\twhile True:\n\t\tframenumber+=1\n\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#mylcd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#mylcd = I2C_LCD_driver.lcd()\n\t\t#if cv2.getWindowProperty(WINDOW_NAME, 0) < 0:\n\t\t\t#  break\n\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak\n\t\timg = cv2.resize(img, (1280, 960))\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg = cam.read()\n\t\tif img is None:\n\t\t\tbreak\n\t\timg = cv2.resize(img, (1280, 960))\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg = cv2.resize(img, (1280, 960))\n\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttim = framenumber/20 \n\t\t#cv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tpol",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg = img.astype('uint8')\n\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\toriginal_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\toriginal_image = img\n\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = img\n\t\tcv2.putText(img_better_look, f\"time {tim}s\",  (1100, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr \n\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#input_cropped",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#input_cropped = frame[550:(550+IMAGE_H), 0:IMAGE_W]\n\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tadd_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tadd_trans = np.zeros_like(img)\n\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#add_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#add_trans = add_trans[:,:,0] #force one channel \n\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_trans = perspective_transformation(img)\n\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_trans = select_yellow_white(img_trans)\n\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_trans = canny(img_trans)\n\t\t'''\n\t\tlanedetection\n\t\t==============\n\t\tfiltering out not interested region \n\t\t'''\n\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#yellow_white",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#yellow_white = select_yellow_white(img)\n\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#cannyresult",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#cannyresult = canny(yellow_white)\n\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#frame_for_dis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#frame_for_dis = draw_dis_lines(frame)\n\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcannyresult",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcannyresult = canny(img)\n\t\t#get the right vertice automatically\n\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tvertice",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tvertice = get_vetices()\n\t\tcropped_image , mask = region_of_interest2(cannyresult,vertice)\n\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tlines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tlines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)  #minLineLength=40, maxLineGap=5\n\t\t#print(\"lines\\n\",lines)\n\t\tif lines is not None :\n\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tlines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tlines = np.reshape(lines, [len(lines),4]) #lines will be None sometimes\n\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#avg_lines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#avg_lines = average_slope_intercept(frame,lines)\n\t\t\tavg_lane, left , right = average_slope_intercept(img,lines)\n\t\t\t#print(len(avg_lane)) #if len(avg_lane)==1 ->only left or right if len(avg_lane)==2 ->both left and right\n\t\t\t#fix road disappear issue ->works well\n\t\t\tif len(avg_lane)==2:\n\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tleft_avg_lines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tleft_avg_lines = avg_lane[[0]]\n\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2\n\t\t\telif left == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2\n\t\t\telif right == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tright_avg_lines",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tright_avg_lines = avg_lane[[1]]\n\t\t\t\tfor x1 , y1 , x2 , y2 in left_avg_lines :\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2  \n\t\t\t\tfor x1 , y1 , x2 , y2 in right_avg_lines :\n\t\t\t\t\txr1 , yr1 ,xr2 ,yr2 = x1 , y1 , x2 , y2\n\t\t\telif left == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:\n\t\t\t\t\txl1 , yl1 ,xl2 ,yl2 = x1 , y1 , x2 , y2\n\t\t\telif right == True:\n\t\t\t\tfor x1 , y1 , x2 , y2 in avg_lane:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#vertices_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#vertices_polly = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32)\n\t\t\t\tif xr1 - xl1 < 900:\n\t\t\t\t\txr1 = xl1 + 1100\n\t\t\t\tif (xr2+5)-(xl2-5) < 130:\n\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\txr1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\txr1 = xl1 + 1100\n\t\t\t\tif (xr2+5)-(xl2-5) < 130:\n\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\txl2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\txl2 = xr2 + 10 +150\n\t\t\t\tif (xr2+5) < (xl2-5) :\n\t\t\t\t\txl2 , xr2 = xr2 + 10 , xl2 - 10 \n\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:\n\t\t\tprint(\"default avg_lines(not detecting lanes)\")\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tvertices_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tvertices_polly = np.array([[(xl1, yl1), (xl2-5, yl2-80), (xr2+5, yr2-80), (xr1, yr1)]], dtype=np.int32) #extend trapezoid\n\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:\n\t\t\tprint(\"default avg_lines(not detecting lanes)\")\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n                                 [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tvertices_polly_unextd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tvertices_polly_unextd = np.array([[(xl1, yl1), (xl2, yl2), (xr2, yr2), (xr1, yr1)]], dtype=np.int32) #unextend trapezoid\n\t\t\texcept (NameError,OverflowError):\n\t\t\t\tprint(\"xl1 is not defined ->only one side of line works\")\n\t\telse:\n\t\t\tprint(\"default avg_lines(not detecting lanes)\")\n\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n                                 [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tavg_lane",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tavg_lane = np.array([[0 ,572 ,479 ,205],   #0 572 ; 479  205 ; 641 193 ; 1268 481\n                                 [1268 ,481 ,641 ,193]])\n\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tvertices_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tvertices_polly = None\n\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_zero",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_zero = np.zeros_like(img)\n\t\timg0 =np.zeros_like(img) \n\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcolor_polly",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcolor_polly =  (0,255,0) #BGR\n\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tline_image_not_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tline_image_not_avg = draw_lines1(img0, lines)\n\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tline_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tline_image = draw_lines2(img, avg_lane)\n\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tline_visualize",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tline_visualize = cv2.addWeighted(img_better_look,1,line_image,1,1)\n\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#line_visualize",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#line_visualize = cv2.addWeighted(line_image_not_avg,1,line_visualize,1,1)\n\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tgod",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tgod = filterout2(img,vertice,mask)\n\t\t#print(vertices_polly)\n\t\ttry:\n\t\t\t#cv2.fillPoly(line_image, vertices_polly, color_polly)\n\t\t\tcv2.fillPoly(img_zero, vertices_polly_unextd, (0,255,0))\n\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered = filterout(img,vertices_polly)\n\t\t\t#print(\"vertices polly :\\n\",vertices_polly)\n\t\t\tif lanedetection == True:\n\t\t\t\timg=filtered #img = filtered\n\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#img = god\n\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#img = img   #not filtering\n\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#god",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#god = filterout2(frame,mask)\n\t\texcept NameError:\n\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#filtered",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#filtered = original_image \n\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfiltered",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfiltered = god\n\t\t\tprint(\"vertices polly is not defined\")\n\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tnormal_result",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tnormal_result = cv2.addWeighted(img,1,img_zero,1,1)\n\t\t#print(\"vertices polly :\",vertices_polly)\n\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcombo_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcombo_image = cv2.addWeighted(img, 1, line_image, 1, 1)\n\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#combo_image",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#combo_image = cv2.addWeighted(combo_image, 1, line_image_not_avg, 1, 1) #addWeighted function cant add two srcs\n\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_notavg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_notavg = cv2.addWeighted(img, 1, line_image_not_avg, 1, 1)\n\t\t#allowing safety zone to draw on ->or the color of safety zone will be too dark        \n\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tim0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tim0 = np.zeros_like(img)      \n\t\tif unsafe_v == False and danger_v == False:\n\t\t\tcv2.putText(img_better_look, f\"safe\", (800, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)  #bgr\n\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#img0 = np.zeros_like(img_better_look)\n\t\t\tcv2.fillPoly(im0,pol, (0,255,0))\n\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''\n\t\tyolov4 + Tensorrt\n\t\t'''\n\t\tboxes, confs, clss = detector.detect(img, conf_th)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#img_better_look = cv2.addWeighted(img0,0.7,img_better_look,1,1)\n\t\t\t#speed estimate zone\n\t\t\t#cv2.line(img_better_look,(50,530),(1260,530),(0,127,255),3)\n\t\t\t#cv2.line(img_better_look,(50,560),(1260,560),(0,127,255),3)\n\t\t'''\n\t\tyolov4 + Tensorrt\n\t\t'''\n\t\tboxes, confs, clss = detector.detect(img, conf_th)\n\t\t#yolo_init = boxes\n\t\t#img0 = ez_show(img)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#yolo_init",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#yolo_init = boxes\n\t\t#img0 = ez_show(img)\n\t\t#img0 = cv2.addWeighted(img0,0.7,img,1,1)\n\t\t'''\n\t\tobject tracking by DeepSort\n\t\t'''\n\t\t#compute width and height of bboxs\n\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img0 = ez_show(img)\n\t\t#img0 = cv2.addWeighted(img0,0.7,img,1,1)\n\t\t'''\n\t\tobject tracking by DeepSort\n\t\t'''\n\t\t#compute width and height of bboxs\n\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img0",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img0 = cv2.addWeighted(img0,0.7,img,1,1)\n\t\t'''\n\t\tobject tracking by DeepSort\n\t\t'''\n\t\t#compute width and height of bboxs\n\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\toutput",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\toutput = boxes\n\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")\n\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tw = output[:,[2]] - output[:,[0]]\n\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")\n\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\th = output[:,[3]] - output[:,[1]]\n\t\txc , yc , w , h = compute_xc_yc(output)\n\t\t#print(xc,yc,\"center\")\n\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tboxes",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tboxes = np.concatenate((xc,yc,w,h),axis=1)\n\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\toutputs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\toutputs = tracker.run(img, boxes, confs)\n\t\t#print('boxes_changed\\n',boxes,'confs\\n',confs,'clss',clss,\"\\n############\")\n\t\t#print(\"         deepsort bboxs:            \\n \",outputs)\n\t\t#for tensorrt_yolo\n\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#img_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#img_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = vis.draw_bboxes(img_better_look, output, confs, clss) \n\t\tif len(clss)==1:\n\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tclss",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tclss = int(clss)\n\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tcls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tcls = vis.cls_dict.get(clss)\n\t\telse:\n\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tcls",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tcls = \"\"\n\t\t\t#print(\"class      :\",cls)\n\t\t#print(\"the type of class :\\n\",type(clss),\"class :\",clss)\n\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :\n\t\t\t#print(xc,\"xc\")\n\t\t\t#outputs.astype(int)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t#f",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t#f = []\n\t\t'''\n\t\tsafety zone geometry setting\n\t\t'''\n\t\tif len(outputs) > 0 :\n\t\t\t#print(xc,\"xc\")\n\t\t\t#outputs.astype(int)\n\t\t\t#print(\"before x1 y1......\",outputs)\n\t\t\tfor x1,y1,x2,y2,ids in outputs:\n\t\t\t\txmin = x1",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txmin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\txmin = x1\n\t\t\t\tymin = y2\n\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tymin",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tymin = y2\n\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tw = x2 - x1 #w\n\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\th = y2 - y1 #h\n\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\txc = w/2 + x1 #xmin = x1\n\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tyc = h/2 + y1 #ymin = y2\n\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\txc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\txc = int(xc)\n\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tyc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tyc = int(yc)\n\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tw = int(w)\n\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\th = int(h)\n\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tlow_mid",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tlow_mid = (xc,y2)\n\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tlow_left",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tlow_left = (x1,y2)\n\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tcenter",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tcenter = (xc,yc,h)\n\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#cent",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#cent = (xc,yc)\n\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tw_tim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tw_tim = (w,tim,cls)\n\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#xc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#xc = np.array(xc[0,0],dtype = np.int32) \n\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t#yc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t#yc = np.array(yc[0,0],dtype = np.int32)\n\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tx_res_yc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tx_res_yc = 1.062*yc - 20 \n\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")\n\t\t\t\tprint(\"w_list:\\n\",w_list,\"\\n\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tx_res_y",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tx_res_y = 1.062*y2 - 20\n\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")\n\t\t\t\tprint(\"w_list:\\n\",w_list,\"\\n\")\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tpol",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\tpol = np.array([[(224, 960), (500, 570), (586, 570),(1000, 960)]], dtype=np.int32)  \n\t\t\t\t#pts[ids].append(center)\n\t\t\t\tprint(\"id\",ids,\"w_tim\",w_tim)\n\t\t\t\tpt[ids].append(low_left)\n\t\t\t\t#h_ls[ids].append(h)\n\t\t\t\tw_list[ids].append(w_tim)\n\t\t\t\t#print(\"pt:\\n\",pt,\"\\n\")\n\t\t\t\tprint(\"w_list:\\n\",w_list,\"\\n\")\n\t\t\t\t#print(\"the ids now :\",ids,\"\\n\")\n\t\t\t\tfor j in range(0, len(pt[ids])): #start with 1",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#cent",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#cent = (pts[ids][j][0] , pts[ids][j][1])      \n\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))\n\t\t\t\t\tif abs(pt[ids][j][1] - pt[ids][j-1][1]) < 10 :\n\t\t\t\t\t\t#print(\"in abs!!!!!!\",(pt[ids][j-1]) , (pt[ids][j]))\n\t\t\t\t\t\tcv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\tif len(pt[ids]) > 5:\n\t\t\t\t\t\tif j%5 == 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#cent",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#cent = (pts[ids][j-1] , pts[ids][j])\n\t\t\t\t\t#cv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\t#greatest > curr\n\t\t\t\t\t#print(\"len(pt[ids])\",len(pt[ids]))\n\t\t\t\t\tif abs(pt[ids][j][1] - pt[ids][j-1][1]) < 10 :\n\t\t\t\t\t\t#print(\"in abs!!!!!!\",(pt[ids][j-1]) , (pt[ids][j]))\n\t\t\t\t\t\tcv2.line(img_better_look,(pt[ids][j-1]) , (pt[ids][j]),(0,255,255),3)\n\t\t\t\t\tif len(pt[ids]) > 5:\n\t\t\t\t\t\tif j%5 == 0:\n\t\t\t\t\t\t\t#motion = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#motion",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#motion = True\n\t\t\t\t\t\t\t#x_dir_avg = np.average(x_dir)\n\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#x_dir_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#x_dir_avg = np.average(x_dir)\n\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#y_dir_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#y_dir_avg = np.average(y_dir)\n\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#parameters_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#parameters_avg = np.polyfit(x_dir_avg, y_dir_avg, 1)\n\t\t\t\t\t\t\t#cv2.line(img_better_look,(pts[ids][j-1][0],pts[ids][j-1][1]),(pts[ids][j][0],pts[ids][j][1]),(255,255,255),3)\n\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tx_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tx_dirr = (pt[ids][0][0] , pt[ids][j][0])\n\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\ty_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][j][1])\n\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\t#if pt[ids][0][0] == pt[ids][j][0] :\n\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t#x_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t#x_dirr = (pt[ids][0][0] , pt[ids][0][0]+2)\n\t\t\t\t\t\t\t\t#x direction has same value\n\t\t\t\t\t\t\tif pt[ids][0][1] == pt[ids][j][1] :\n\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\ty_dirr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\ty_dirr = (pt[ids][0][1] , pt[ids][0][1]+5)\n\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tparameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tparameters = np.polyfit(x_dirr, y_dirr, 1)\n\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdrw = True\n\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t\tprint(\"x dirr y dirr\",x_dirr,y_dirr)\n\t\t\t\tif drw == True:\n\t\t\t\t\tx1 ,y1 ,x2 ,y2 = motion_cord((x1,y2) , parameters)\n\t\t\t\t\t#print(\"x1 y1 x2 y2\",parameters,x1,y1,x2,y2)\n\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tx_res_y2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tx_res_y2 = 1.062*y2 - 20\n\t\t\t\t\tcv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdrw",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdrw = False\n\t\t\t\t\tif x_res_y2 > x2 and y2 > 570 :\n\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tmotion_predict",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tmotion_predict = True\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motion True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,255,255), 2)  #bgr\n\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t#parameters = np.polyfit(x_dir, y_dir, 1)\n\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#parameters",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t#parameters = np.polyfit((pts[ids][j][0]), (pts[ids][j][1]),1)\n\t\t\t\t\t\t#print(\"(pts[ids][j][0] :\",(pts[ids][j][0]))\n\t\t\t\t\t\t#x1 ,y1 ,x2 ,y2 = motion_cord((pts[ids][j][0], pts[ids][j][1] + (pts[ids][j][2]//2)) , parameters)\n\t\t\t\t\t\t#cv2.line(add_trans,(x1,y1),(x2,y2),(255,0,255),1)\n\t\t\t\t\t\t#cv2.line(img_better_look,(x1,y1),(x2,y2),(255,0,255),3)\n\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#trans = perspective_transformation(add_trans)\n\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#x1,y1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#x1,y1 = pts[ids][j-1]\n\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#x2,y2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#x2,y2 = pts[ids][j]\n\t\t\t\t\t#cv2.line(trans,(x1,(y1*300//960)), (x2,(y2*300//960)),(0,255,255),3)\n\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):\n\t\t\t\t\t#print(\"len(w_list[ids]) :\",len(w_list[ids]),\"; i :\",i)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img_trans",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img_trans = cv2.addWeighted(img_trans,1,trans,1,1) \n\t\t\t\t'''\n\t\t\t\tspeed estimation \n\t\t\t\t==============\n\t\t\t\testimate speed using deque method\n\t\t\t\t'''\n\t\t\t\tfor i in range(0, len(w_list[ids])):\n\t\t\t\t\t#print(\"len(w_list[ids]) :\",len(w_list[ids]),\"; i :\",i)\n\t\t\t\t\t#print(\"k in for loop\",k)\n\t\t\t\t\t#i+=2",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\twidth_curr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\twidth_curr = w_list[ids][i][0]\n\t\t\t\t\tif i%5 ==0 and k+1 <= i and len(w_list[ids]) > 5:  #sample every 3 points\n\t\t\t\t\t\t#print(\"k in if statement\",k)\n\t\t\t\t\t\twidth_1 = (w_list[ids][k-1][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_1 = (w_list[ids][k-1][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_2 = (w_list[ids][k-5][0])  #far\n\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t#width_curr",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t#width_curr = (w_list[ids][i][0])\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_passed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_passed = abs((w_list[ids][k-1][1]) - (w_list[ids][k-5][1]))\n\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tname = (w_list[ids][k-1][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tname = (w_list[ids][k-5][2])\n\t\t\t\t\t\tprint(\"time passed :\",time_passed,\" time1 \",(w_list[ids][k-1][1]),\" time2 \",(w_list[ids][k-5][1]),)\n\t\t\t\t\t\tprint(\"width difference :\",abs(width_1-width_2))\n\t\t\t\t\t\tif time_passed > 0:\n\t\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_car2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_car1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_car =  Distance_finder(210,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_diff_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tcar_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\t\t#print(avg_spd_car)\n\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {int(car_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {int(car_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike\n\t\t\t\t\t\t\tif name == \"motorbike\" or name ==\"\":\n\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tputtext_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"average car speed {avg_spd}   km/h\",  (50, 150), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#print(\"car speed\",car_spd)\n\t\t\t\t\t\t\t\t#print(\"car speed cord  :\",car_spd[ids],\"average speed :\",avg_spd_car)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {int(car_speed)}   km/h\",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#no class found ->usually motorbike\n\t\t\t\t\t\t\tif name == \"motorbike\" or name ==\"\":\n\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_moto = Distance_finder(85,width_curr)/100\n\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tdis_diff_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tmoto_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)}  km/h\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\t\t# print(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tavg_spd",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tavg_spd = int(avg_spd_moto)\n\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tputtext_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tputtext_moto = True \n\t\t\t\t\t#when w_list is short   \n\t\t\t\t\telif len(w_list[ids]) == 5:\n\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_1 = (w_list[ids][4][0])  #near wider\n\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\twidth_2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\twidth_2 = (w_list[ids][0][0])  #far\n\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_passed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_passed = abs((w_list[ids][4][1]) - (w_list[ids][0][1]))\n\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tname = (w_list[ids][3][2])\n\t\t\t\t\t\tif name == \"\" :\n\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tname",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tname = (w_list[ids][1][2])\n\t\t\t\t\t\tif name == \"car\":\n\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_car2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_car2 = Distance_finder(210,width_2)/100\n\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_car1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_car1 = Distance_finder(210,width_1)/100\n\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_diff_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_diff_car = abs(dis_car2 - dis_car1)\n\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tcar_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tcar_speed = (dis_diff_car/time_passed)*3600/1000\n\t\t\t\t\t\t\tcar_spd[ids].append(car_speed)\n\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tavg_spd_car = append_speed(ids,car_spd)\n\t\t\t\t\t\t\tif avg_spd_car != \"still appending\":\n\t\t\t\t\t\t\t\tprint(avg_spd_car)\n\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_car = int(avg_spd_car)\n\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tputtext_car",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tputtext_car = True\n\t\t\t\t\t\tif name == \"motorbike\":\n\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_moto1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_moto1 = Distance_finder(85,width_1)/100\n\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_moto2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_moto2 = Distance_finder(85,width_2)/100\n\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tdis_diff_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tdis_diff_moto = abs(dis_moto2 - dis_moto1)\n\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tmoto_speed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tmoto_speed = (dis_diff_moto/time_passed)*3600/1000\n\t\t\t\t\t\t\tmoto_spd[ids].append(moto_speed)\n\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tavg_spd_moto = append_speed(ids,moto_spd)\n\t\t\t\t\t\t\tif avg_spd_moto != \"still appending\":\n\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tavg_spd_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tavg_spd_moto = int(avg_spd_moto)\n\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tputtext_moto",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tputtext_moto = True      \n\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#k",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#k = 3*i\n\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tk",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tk = i\n\t\t\t\t'''\n\t\t\t\tplot speed information\n\t\t\t\t'''\n\t\t\t\tif puttext_car == True and  avg_spd_car != \"still appending\" and car_speed != 0 and avg_spd_car != 0:\n\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 1.25 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcar_imptim_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcar_imptim_avg = round(dis_car/(avg_spd_car*1000/3600),2)               \n\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tcar_imptim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tcar_imptim = round(dis_car/(car_speed*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"average car speed {avg_spd_car} km/h Collision time {car_imptim_avg} s\",  (50, 90), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,0,255), 2)  #bgr\n\t\t\t\t\tcv2.putText(img_better_look, f\"car speed {int(car_speed)} km/h  Collision time {car_imptim}s  \",  (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,0,255), 2)  #bgr\n\t\t\t\t\tif car_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\tif car_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\tif puttext_moto == True and  avg_spd_moto != \"still appending\" and moto_speed !=0 and avg_spd_moto !=0:\n\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tmoto_imptim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tmoto_imptim = round(dis_moto/(moto_speed*1000/3600),2)\n\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tmoto_imptim_avg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tmoto_imptim_avg = round(dis_moto/(avg_spd_moto*1000/3600),2)\n\t\t\t\t\tcv2.putText(img_better_look, f\"motorbike speed {int(moto_speed)} km/h Collision time {int(moto_imptim)} s\",  (50, 140), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr    \n\t\t\t\t\tcv2.putText(img_better_look, f\"avg motorbike speed {int(avg_spd_moto)} km/h Collision time {int(moto_imptim_avg)} s\",  (50, 180), cv2.FONT_HERSHEY_COMPLEX, 0.65, (255,255,0), 2)  #bgr \n\t\t\t\t\tif moto_imptim_avg < 1.25 and motion_predict == True:\n\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = True\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tif moto_imptim_avg < 0.75 and motion_predict == True:\n\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = True\n\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tunsafe_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tunsafe_v = False\n\t\t\t\t\telse:\n\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t#560",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdanger_v",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdanger_v = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"danger True\", (700, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)  #bgr\n\t\t\t\t\t#speed estimation ends here       \n\t\t\t\tif cls == \"car\":\n\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = Distance_finder(210,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr\n\t\t\t\t\t#560\n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_start = dis\n\t\t\t\t\t#\n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tused",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tprint(\"time",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tprint(\"time = 0\") \n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\tif speed < 0:\n\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tspeed = \"calculating speed\"\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"time start {time_start}  time end {time_end}\",  (100, 500), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400 ), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tbad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"time start {time_start}  time end {time_end}\",  (100, 500), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400 ), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\t#f.insert(0,(xc,yc))\n\t\t\t\t\t#print(\"car center lsit :  \",f)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\tif bad ==True :\n\t\t\t\t\t\tprint(\"\")\n\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"time start {time_start}  time end {time_end}\",  (100, 500), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"car speed {speed} km/hr \",  (50,400 ), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,255,255), 2)\n\t\t\t\t\t#f.insert(0,(xc,yc))\n\t\t\t\t\t#print(\"car center lsit :  \",f)\n\t\t\t\tif cls == \"motorbike\":",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = Distance_finder(85,w)//100\n\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tprint(\"distance\",dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr \n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis                           \n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdis = int(dis)\n\t\t\t\t\tprint(\"distance\",dis)\n\t\t\t\t\tcv2.putText(img_better_look, f\"Distance {dis} m\", (xc-6, yc-6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)  #bgr \n\t\t\t\t\tif yc > 530 and yc <540:\n\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis                           \n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_start = tim\n\t\t\t\t\t\tdis_start = dis                           \n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_start",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_start = dis                           \n\t\t\t\t\tif yc > 560 and yc < 570:\n\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tused",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tused = True\n\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttime_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\ttime_end = tim\n\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tdis_end",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\tdis_end = dis\n\t\t\t\t\t\tif used == True:\n\t\t\t\t\t\t\tif time_end-time_start == 0:\n\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tprint(\"time",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tprint(\"time = 0\")\n\t\t\t\t\t\t\telse: \n\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tbad",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tbad = True\n\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :\n\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\t\tspeed = ((dis_start-dis_end)/(time_end-time_start))*3600/1000\n\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr\n\t\t\t\t\tif bad == True :\n\t\t\t\t\t\tprint(\"debuging speed\",speed)\n\t\t\t\t\t\tif speed < 0 :\n\t\t\t\t\t\t\tprint(\"speed is negative\")\n\t\t\t\t\t\telse :\n\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr                           ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tspeed",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t\t\tspeed = int(speed)\n\t\t\t\t\t\t\tcv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"distance start {dis_start}  distance end {dis_end}\",  (100, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)  #bgr                           \n\t\t\t\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"time start {time_start}  time end {time_end}\",  (100, 500), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)  #bgr\n\t\t\t\t\t\t\t#cv2.putText(img_better_look, f\"motorcycle speed {speed} km/hr \",  (50,300 ), cv2.FONT_HERSHEY_COMPLEX, 0.65, (0,255,255), 2)   \n\t\t\t\t\t\t\t#m.insert(0,(xc,yc))\n\t\t\t\t\t\t\t#print(\"motorbike center list:  \",m)\n\t\t\t\t'''\n\t\t\t\tsafety zone\n\t\t\t\t=============",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#unsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#unsafe = True\n\t\t\t\t\tprint(\"satis1\")\n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img1 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img1",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img1 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img1,0.7,img,1,1)\n\t\t\t\t'''             \n\t\t\t\tif ymin > 570 and xmin < 586 and danger == False: #straight behind\n\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tunsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tunsafe = True\n\t\t\t\t\tprint(\"satis2\")                                   \n\t\t\t\t\tcv2.putText(img_better_look, f\"Unsafe\", (700, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,255), 2)  #bgr\n\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img2",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img2 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (255,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:\n\t\t\t\t\t#mylcd.lcd_display_string(\"dangerous!\",  2,3)\n\t\t\t\t\t#buzz(unsafe_v)\n\t\t\t\t\tprint(\"satis3\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img2,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\t#dangerous         \n\t\t\t\t#if x_res_yc > xc and yc > 570 or danger_v == True and unsafe == False:\n\t\t\t\tif danger_v == True: #and unsafe == False:\n\t\t\t\t\t#mylcd.lcd_display_string(\"dangerous!\",  2,3)\n\t\t\t\t\t#buzz(unsafe_v)\n\t\t\t\t\tprint(\"satis3\")\n\t\t\t\t\t#danger = True #dangerous\n\t\t\t\t\t#unsafe = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#danger",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#danger = True #dangerous\n\t\t\t\t\t#unsafe = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"dangerous!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr\n\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#unsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#unsafe = False\n\t\t\t\t\tcv2.putText(img_better_look, f\"dangerous!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr\n\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img3",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img3 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img3,0.7,img,1,1)\n\t\t\t\t'''\n\t\t\t\telif yc > 570 and xc < 586:\n\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdanger",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tdanger = True\n\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tunsafe",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\tunsafe = False\n\t\t\t\t\tprint(\"satis4\")\n\t\t\t\t\tcv2.putText(img_better_look, f\" danger!!\", (800, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2)  #bgr                          \n\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img4",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img4 = np.zeros_like(img_better_look)\n\t\t\t\t\tcv2.fillPoly(im0,pol, (0,0,255))\n\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t#img",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t\t\t#img = cv2.addWeighted(img4,0.7,img,1,1)\n\t\t\t\t\t'''\n\t\tif len(outputs) > 0:\n\t\t\t#print(\"outputs after output right box\",outputs)\n\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tbbox_xyxy",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tbbox_xyxy = outputs[:, :4]\n\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tidentities",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tidentities = outputs[:, -1]\n\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\timg_final",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\timg_final = draw_boxes(img_better_look, bbox_xyxy, identities)\n\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\t#img_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\t#img_better_look = show_fps(img_better_look, fps)\n\t\t###################################\n\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = show_fps(img_better_look, fps)\n\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)\n\t\t####",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timgx",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timgx = img0\n\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)\n\t\t####\n\t\t#cv2.imshow(\"normal lanedetection without extended\",normal_result)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\treal_result",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\treal_result = cv2.addWeighted(img_better_look,0.7,img,1,1) #view lanedetection filtering\n\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)\n\t\t####\n\t\t#cv2.imshow(\"normal lanedetection without extended\",normal_result)\n\t\t#cv2.imshow(\"combo img\",combo_image)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\timg_better_look",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\timg_better_look = cv2.addWeighted(im0,1,img_better_look,1,1) # \n\t\tout.write(line_visualize)\n\t\tout1.write(img_better_look)\n\t\tout2.write(combo_image)\n\t\t#show result\n\t\t#cv2.imshow(WINDOW_NAME, img)\n\t\t####\n\t\t#cv2.imshow(\"normal lanedetection without extended\",normal_result)\n\t\t#cv2.imshow(\"combo img\",combo_image)\n\t\t#cv2.imshow(\" img\",img_notavg) ",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttoc",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttoc = time.time()\n\t\tcurr_fps = 1.0 / (toc - tic)\n\t\t# calculate an exponentially decaying average of fps number\n\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tcurr_fps",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tcurr_fps = 1.0 / (toc - tic)\n\t\t# calculate an exponentially decaying average of fps number\n\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tfps",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tfps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttic",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttic = toc\n\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()\n\t########",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tkey",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tkey = cv2.waitKey(1)\n\t\tif key == 27:  # ESC key: quit program\n\t\t\tbreak\n\t\telif key == ord('F') or key == ord('f'):  # Toggle fullscreen\n\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\t\tfull_scrn",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\t\tfull_scrn = not full_scrn\n\t\t\tset_display(WINDOW_NAME, full_scrn)\ndef main():\n\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\targs = parse_args()\n\t########\n\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):\n\t\t\traise SystemExit('ERROR: file (yolo/%s.trt) not found!' % args.model)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcfg",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcfg = get_config()\n\tcfg.merge_from_file(args.config_deepsort)    \n\t########\n\tif args.category_num <= 0:\n\t\traise SystemExit('ERROR: bad category_num (%d)!' % args.category_num)\n\tif not args.use_opencv:\n\t\tif not os.path.isfile('yolo/%s.trt' % args.model):\n\t\t\traise SystemExit('ERROR: file (yolo/%s.trt) not found!' % args.model)\n\tcam = Camera(args)\n\tif not cam.isOpened():",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcam",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcam = Camera(args)\n\tif not cam.isOpened():\n\t\traise SystemExit('ERROR: failed to open camera!')\n\t########    \n\ttracker = Tracker_tiny(cfg) \n\t########\n\tcls_dict = get_cls_dict(args.category_num)\n\tyolo_dim = args.model.split('-')[-1]\n\tif 'x' in yolo_dim:\n\t\tdim_split = yolo_dim.split('x')",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\ttracker",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\ttracker = Tracker_tiny(cfg) \n\t########\n\tcls_dict = get_cls_dict(args.category_num)\n\tyolo_dim = args.model.split('-')[-1]\n\tif 'x' in yolo_dim:\n\t\tdim_split = yolo_dim.split('x')\n\t\tif len(dim_split) != 2:\n\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\telse:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tcls_dict",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tcls_dict = get_cls_dict(args.category_num)\n\tyolo_dim = args.model.split('-')[-1]\n\tif 'x' in yolo_dim:\n\t\tdim_split = yolo_dim.split('x')\n\t\tif len(dim_split) != 2:\n\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\telse:\n\t\th = w = int(yolo_dim)\n\tif h % 32 != 0 or w % 32 != 0:",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tyolo_dim",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tyolo_dim = args.model.split('-')[-1]\n\tif 'x' in yolo_dim:\n\t\tdim_split = yolo_dim.split('x')\n\t\tif len(dim_split) != 2:\n\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\telse:\n\t\th = w = int(yolo_dim)\n\tif h % 32 != 0 or w % 32 != 0:\n\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tdim_split",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tdim_split = yolo_dim.split('x')\n\t\tif len(dim_split) != 2:\n\t\t\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\t\tw, h = int(dim_split[0]), int(dim_split[1])\n\telse:\n\t\th = w = int(yolo_dim)\n\tif h % 32 != 0 or w % 32 != 0:\n\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\tif args.use_opencv:\n\t\t# Use OpenCV DNN fallback on CPU",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\th",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\th = w = int(yolo_dim)\n\tif h % 32 != 0 or w % 32 != 0:\n\t\traise SystemExit('ERROR: bad yolo_dim (%s)!' % yolo_dim)\n\tif args.use_opencv:\n\t\t# Use OpenCV DNN fallback on CPU\n\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tdetector = OpenCVYolo(args.yolo_cfg, args.yolo_weights, input_shape=(h, w))\n\telse:\n\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\ttrt_yolo",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\ttrt_yolo = TrtYOLO(args.model, (h, w), args.category_num, args.letter_box)\n\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\t\tdetector",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\t\tdetector = trt_yolo\n\t#open_window(WINDOW_NAME, 'Camera TensorRT YOLO Demo',cam.img_width, cam.img_height)\n\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    },
    {
        "label": "\tvis",
        "kind": 5,
        "importPath": "trt_deepsort_ver2",
        "description": "trt_deepsort_ver2",
        "peekOfCode": "\tvis = BBoxVisualization(cls_dict)\n\tloop_and_detect(cam, detector, tracker, conf_th=0.3, vis=vis)\n\tcam.release()\n\tcv2.destroyAllWindows()\nif __name__ == '__main__':\n\tmain()",
        "detail": "trt_deepsort_ver2",
        "documentation": {}
    }
]